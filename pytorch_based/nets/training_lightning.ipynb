{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#### standard library ####\n",
    "##########################\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "from typing import List, Tuple, Dict, Any, Union, Optional, Callable\n",
    "import shutil\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "###################\n",
    "#### 3rd party ####\n",
    "###################\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import GradScaler, autocast #amp = automatic mixed precision\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "######################\n",
    "#### my own files ####\n",
    "######################\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "from utils.utils import print_name, print_shape\n",
    "from rocket import Rocket, RocketFeatures\n",
    "from ridge_loocv import fit_ridge_LOOCV\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    data_dir = \"/home/nikita/Code/zephyrox/Data/Ford/\"\n",
    "    logs_dir = \"/home/nikita/Code/zephyrox/Data/Ford/logs/\"\n",
    "    \n",
    "    # Device and random seed\n",
    "    device = 'cpu' # if torch.cuda.is_available() else 'cpu'\n",
    "    seed = 42\n",
    "    \n",
    "    # Number of epochs, number of folds\n",
    "    batch_size = 64\n",
    "    epochs = 30\n",
    "    n_folds = 5\n",
    "\n",
    "    # Learning rate, optimizer, and cosine scheduler\n",
    "    lr = 1e-4\n",
    "    lr_min = 1e-6\n",
    "    weight_decay = 1e-3\n",
    "    gradient_clip_val = 10.0\n",
    "    optimizer = torch.optim.AdamW # AdamW, Adam\n",
    "\n",
    "    # model params\n",
    "    n_kernels = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒ± Seed Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (binary) Time Series Classication Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the different datasets\n",
    "from aeon.datasets.tsc_datasets import multivariate, univariate, univariate_equal_length\n",
    "from aeon.datasets import load_classification\n",
    "\n",
    "def get_aeon_dataset(\n",
    "        dataset_name:str,\n",
    "        ):\n",
    "    \"\"\"Loads a dataset from the UCR/UEA archive using \n",
    "    the aeon library.\n",
    "\n",
    "    Args:\n",
    "        dataset_name (str): Name of the dataset\n",
    "\n",
    "    Returns:\n",
    "        Tuple: 4-tuple of the form (X_train, y_train, X_test, y_test)\n",
    "    \"\"\"\n",
    "    X_train, y_train = load_classification(dataset_name, split=\"train\")\n",
    "    X_test, y_test = load_classification(dataset_name, split=\"test\")\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = get_aeon_dataset(\"FaceDetection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTSCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocketBinaryClassification(L.LightningModule):\n",
    "    def __init__(self, D, T, n_kernels):\n",
    "        super().__init__()\n",
    "        self.model = Rocket(D, T, n_kernels, 1)\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, labels = batch\n",
    "        logits = self.model(X).squeeze()\n",
    "        loss = self.loss(logits, labels)\n",
    "\n",
    "        # log things\n",
    "        acc = (self.sigmoid(logits).round() == labels).float().mean()\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, labels = batch\n",
    "        logits = self.model(X).squeeze()\n",
    "        loss = self.loss(logits, labels)\n",
    "\n",
    "        # log things\n",
    "        acc = (self.sigmoid(logits).round() == labels).float().mean()\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = CFG.optimizer(\n",
    "                self.model.parameters(),  #TODO remove linear\n",
    "                lr=CFG.lr,\n",
    "                weight_decay=CFG.weight_decay\n",
    "            )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, \n",
    "                T_max=CFG.epochs, \n",
    "                eta_min=CFG.lr_min\n",
    "            )\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_test, y_test):\n",
    "    N, D, T = X_train.shape\n",
    "\n",
    "    #create DataLoaders for train and val\n",
    "    train_dataset = MTSCDataset(X_train, y_train)\n",
    "    test_dataset = MTSCDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, CFG.batch_size, shuffle=True, num_workers=1)\n",
    "    test_loader = DataLoader(test_dataset, CFG.batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "    model = RocketBinaryClassification(D, T, CFG.n_kernels)\n",
    "    model.model.init_biases(torch.from_numpy(train_dataset.X[0:1]))\n",
    "    model = model.to(CFG.device)\n",
    "    \n",
    "    trainer = L.Trainer(\n",
    "            accelerator=\"gpu\" if CFG.device == \"cuda\" else \"cpu\",\n",
    "            max_epochs=CFG.epochs,\n",
    "            gradient_clip_val=CFG.gradient_clip_val,\n",
    "            num_sanity_val_steps=0,\n",
    "        )\n",
    "    trainer.fit(model, train_loader, test_loader)\n",
    "\n",
    "train_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
