{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "import numpy as np\n",
    "import aeon\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from aeon.datasets.tsc_datasets import univariate_equal_length, multivariate_equal_length\n",
    "univariate_equal_length = sorted(list(univariate_equal_length))\n",
    "multivariate_equal_length = sorted(list(multivariate_equal_length))\n",
    "from aeon.datasets import load_classification\n",
    "from sklearn.linear_model import RidgeCV, RidgeClassifierCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.utils import print_name, print_shape\n",
    "from preprocessing.stream_transforms import normalize_mean_std_traindata, normalize_streams, augment_time, add_basepoint_zero\n",
    "from random_sig_fourier import SigTensorisedRandProj\n",
    "from signature import SigTransform, LogSigTransform\n",
    "from features.base import TimeseriesFeatureExtractor, TabularTimeseriesFeatures, RandomGuesser\n",
    "from randomized_sig import RandomizedSignature\n",
    "from rocket_wrappers import RocketWrapper, MiniRocketWrapper, MultiRocketWrapper\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 create rocket features\n",
    "\n",
    "#2 create multirocket features\n",
    "\n",
    "#3 apply multirocket features to a different time series mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################\n",
    "# #######          Dataset Code         #######\n",
    "# #############################################\n",
    "\n",
    "# def get_aeon_dataset(\n",
    "#         dataset_name:str, \n",
    "#         extract_path = \"/home/nikita/hdd/Data/MTSC/\",\n",
    "#         device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         ):\n",
    "#     \"\"\"Loads a dataset from the UCR/UEA archive using \n",
    "#     the aeon library.\n",
    "\n",
    "#     Args:\n",
    "#         dataset_name (str): Name of the dataset\n",
    "\n",
    "#     Returns:\n",
    "#         Tuple: 4-tuple of the form (X_train, y_train, X_test, y_test)\n",
    "#     \"\"\"\n",
    "#     X_train, y_train = load_classification(dataset_name, split=\"train\", extract_path=extract_path)\n",
    "#     X_test, y_test = load_classification(dataset_name, split=\"test\", extract_path=extract_path)\n",
    "#     X_train = torch.from_numpy(X_train.transpose(0,2,1)).to(device)\n",
    "#     X_test = torch.from_numpy(X_test.transpose(0,2,1)).to(device)\n",
    "#     return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: EthanolConcentration\n",
      "torch.Size([261, 1751, 3]) X_train \n",
      "\n",
      "torch.Size([263, 1751, 3]) X_test \n",
      "\n",
      "\n",
      "Dataset: FaceDetection\n",
      "torch.Size([5890, 62, 144]) X_train \n",
      "\n",
      "torch.Size([3524, 62, 144]) X_test \n",
      "\n",
      "\n",
      "Dataset: Handwriting\n",
      "torch.Size([150, 152, 3]) X_train \n",
      "\n",
      "torch.Size([850, 152, 3]) X_test \n",
      "\n",
      "\n",
      "Dataset: Heartbeat\n",
      "torch.Size([204, 405, 61]) X_train \n",
      "\n",
      "torch.Size([205, 405, 61]) X_test \n",
      "\n",
      "\n",
      "Dataset: PEMS-SF\n",
      "torch.Size([267, 144, 963]) X_train \n",
      "\n",
      "torch.Size([173, 144, 963]) X_test \n",
      "\n",
      "\n",
      "Dataset: SelfRegulationSCP1\n",
      "torch.Size([268, 896, 6]) X_train \n",
      "\n",
      "torch.Size([293, 896, 6]) X_test \n",
      "\n",
      "\n",
      "Dataset: SelfRegulationSCP2\n",
      "torch.Size([200, 1152, 7]) X_train \n",
      "\n",
      "torch.Size([180, 1152, 7]) X_test \n",
      "\n",
      "\n",
      "Dataset: UWaveGestureLibrary\n",
      "torch.Size([120, 315, 3]) X_train \n",
      "\n",
      "torch.Size([320, 315, 3]) X_test \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# used_by_paper = [\n",
    "#     \"EthanolConcentration\",\n",
    "#     \"FaceDetection\",\n",
    "#     \"Handwriting\",\n",
    "#     \"Heartbeat\",\n",
    "#     #\"JapaneseVowels\", #unequal length\n",
    "#     \"PEMS-SF\",\n",
    "#     \"SelfRegulationSCP1\",\n",
    "#     \"SelfRegulationSCP2\",\n",
    "#     #\"SpokenArabicDigits\", #unequal length\n",
    "#     \"UWaveGestureLibrary\",\n",
    "# ]\n",
    "\n",
    "# def testMTSC():\n",
    "#     for dataset_name in used_by_paper:\n",
    "#         print(f\"\\nDataset: {dataset_name}\")\n",
    "#         X_train, y_train, X_test, y_test = get_aeon_dataset(dataset_name)\n",
    "#         print_shape(X_train)\n",
    "#         print_shape(X_test)\n",
    "\n",
    "# testMTSC()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
