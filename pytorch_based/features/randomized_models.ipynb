{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'normalize_mean_std_traindata' from 'preprocessing.stream_transforms' (/home/nikita/Code/zephyrox/pytorch_based/preprocessing/stream_transforms.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrocket\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Rocket, RocketFeatures\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mridge_loocv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fit_ridge_LOOCV\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstream_transforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize_mean_std_traindata, normalize_streams, augment_time, add_basepoint_zero\n\u001b[1;32m     26\u001b[0m np\u001b[38;5;241m.\u001b[39mset_printoptions(precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m) \u001b[38;5;66;03m# Print options\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'normalize_mean_std_traindata' from 'preprocessing.stream_transforms' (/home/nikita/Code/zephyrox/pytorch_based/preprocessing/stream_transforms.py)"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "import numpy as np\n",
    "import aeon\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import pandas as pd\n",
    "from aeon.datasets.tser_datasets import tser_soton\n",
    "from aeon.datasets import load_regression\n",
    "from aeon.regression.sklearn import RotationForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from aeon.transformations.collection.convolution_based import Rocket, MultiRocketMultivariate, MiniRocketMultivariate\n",
    "\n",
    "from utils.utils import print_name, print_shape\n",
    "from rocket import Rocket, RocketFeatures\n",
    "from ridge_loocv import fit_ridge_LOOCV\n",
    "from preprocessing.stream_transforms import normalize_mean_std_traindata, normalize_streams, augment_time, add_basepoint_zero\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "N,T,D = 7,5,3\n",
    "X = torch.randn(N, T, D)\n",
    "\n",
    "split_X = torch.split(X, 2, dim=0)\n",
    "print(split_X[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#######          Dataset Code         #######\n",
    "#############################################\n",
    "\n",
    "def get_aeon_dataset(\n",
    "        dataset_name:str, \n",
    "        #extract_path = \"/rds/general/user/nz423/home/Data/TSER/\"\n",
    "        extract_path = \"/home/nikita/hdd/Data/TSER/\"\n",
    "        ):\n",
    "    \"\"\"Loads a dataset from the UCR/UEA archive using \n",
    "    the aeon library.\n",
    "\n",
    "    Args:\n",
    "        dataset_name (str): Name of the dataset\n",
    "\n",
    "    Returns:\n",
    "        Tuple: 4-tuple of the form (X_train, y_train, X_test, y_test)\n",
    "    \"\"\"\n",
    "    X_train, y_train = load_regression(dataset_name, split=\"train\", extract_path=extract_path)\n",
    "    X_test, y_test = load_regression(dataset_name, split=\"test\", extract_path=extract_path)\n",
    "\n",
    "    return X_train.transpose(0,2,1), y_train, X_test.transpose(0,2,1), y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "####  Linear Model (Ridge)  ######\n",
    "##################################\n",
    "\n",
    "def train_linear_classifier(feat_train_X, feat_test_X, train_y, test_y, clf=RidgeCV(alphas=np.logspace(-3, 3, 20))):\n",
    "    # train ridge regression      \n",
    "    clf.fit(feat_train_X, train_y)\n",
    "\n",
    "    # predict\n",
    "    pred = clf.predict(feat_test_X)\n",
    "    test_rmse = root_mean_squared_error(test_y, pred)\n",
    "    train_rmse = root_mean_squared_error(train_y, clf.predict(feat_train_X))\n",
    "    alpha = 0 if not hasattr(clf, 'alpha_') else clf.alpha_\n",
    "    return train_rmse, test_rmse, alpha\n",
    "\n",
    "\n",
    "def train_and_test_sigbased(\n",
    "        train_X, train_y, test_X, test_y,\n",
    "        transformer:TimeseriesFeatureTransformer,\n",
    "        apply_augmentation:bool=True,\n",
    "        normalize_features:bool=True,\n",
    "    ):\n",
    "    # augment data\n",
    "    train_X = lax.stop_gradient(jnp.array(train_X))\n",
    "    test_X  = lax.stop_gradient(jnp.array(test_X))\n",
    "    if apply_augmentation:\n",
    "        train_X = add_basepoint_zero(train_X)\n",
    "        train_X = augment_time(train_X)\n",
    "        test_X  = add_basepoint_zero(test_X)\n",
    "        test_X  = augment_time(test_X)\n",
    "\n",
    "    # fit transformer\n",
    "    t0 = time.time()\n",
    "    transformer.fit(train_X)\n",
    "    feat_train_X = np.array(transformer.transform(train_X))\n",
    "    feat_test_X = np.array(transformer.transform(test_X))\n",
    "    if normalize_features:\n",
    "        feat_train_X, feat_test_X = normalize_mean_std_traindata(feat_train_X, feat_test_X)\n",
    "    t1 = time.time()\n",
    "\n",
    "    # feed into linear classifier\n",
    "    res_ridge = train_linear_classifier(\n",
    "        t0, t1, feat_train_X, feat_test_X, train_y, test_y)\n",
    "    res_rotforest = train_linear_classifier(\n",
    "        t0, t1, feat_train_X, feat_test_X, train_y, test_y, RotationForestRegressor(n_estimators=100, n_jobs=trees_n_jobs))\n",
    "    \n",
    "    return res_ridge, res_rotforest\n",
    "\n",
    "\n",
    "def train_and_test_ROCKETS(\n",
    "        train_X, train_y, test_X, test_y,\n",
    "        transformer,\n",
    "    ):\n",
    "    # augment data\n",
    "    train_X = np.array(train_X).transpose(0,2,1)\n",
    "    test_X  = np.array(test_X).transpose(0,2,1)\n",
    "\n",
    "    # fit transformer\n",
    "    t0 = time.time()\n",
    "    transformer.fit(train_X)\n",
    "    feat_train_X = np.array(transformer.transform(train_X))\n",
    "    feat_test_X = np.array(transformer.transform(test_X))\n",
    "    feat_train_X, feat_test_X = normalize_mean_std_traindata(feat_train_X, feat_test_X)\n",
    "    t1 = time.time()\n",
    "\n",
    "    # feed into linear classifier\n",
    "    res_ridge = train_linear_classifier(\n",
    "        t0, t1, feat_train_X, feat_test_X, train_y, test_y)\n",
    "    res_rotforest = train_linear_classifier(\n",
    "        t0, t1, feat_train_X, feat_test_X, train_y, test_y, RotationForestRegressor(n_estimators=100, n_jobs=trees_n_jobs))\n",
    "    \n",
    "    return res_ridge, res_rotforest\n",
    "\n",
    "\n",
    "def run_all_experiments(X_train, y_train, X_test, y_test):\n",
    "    prng_key = jax.random.PRNGKey(999)\n",
    "    max_batch = 32\n",
    "    trunc_level = 4\n",
    "    n_features = 1000\n",
    "\n",
    "    jax_models = [\n",
    "        [\"Random Guesser\", RandomGuesser(prng_key, max_batch=max_batch)],\n",
    "        [\"Tabular\", TabularTimeseriesFeatures(max_batch)],\n",
    "        [\"Sig\", SigTransform(trunc_level, max_batch)],\n",
    "        [\"Log Sig\", LogSigTransform(trunc_level, max_batch)],\n",
    "        [\"Randomized Signature\", RandomizedSignature(\n",
    "            prng_key,\n",
    "            n_features,\n",
    "            max_batch=10,\n",
    "            )],\n",
    "        [\"TRP\", SigVanillaTensorizedRandProj(\n",
    "            prng_key,\n",
    "            n_features,\n",
    "            trunc_level,\n",
    "            max_batch,\n",
    "            concat_levels=False,\n",
    "            )],\n",
    "        [\"RBF TRP\", SigRBFTensorizedRandProj(\n",
    "            prng_key,\n",
    "            n_features,\n",
    "            trunc_level,\n",
    "            rbf_dimension = 800,\n",
    "            max_batch = max_batch,\n",
    "            concat_levels=False,\n",
    "            )],\n",
    "        [\"concat TRP\", SigVanillaTensorizedRandProj(\n",
    "            prng_key,\n",
    "            n_features // (trunc_level-1),\n",
    "            trunc_level,\n",
    "            max_batch,\n",
    "            )],\n",
    "        [\"concat RBF TRP\", SigRBFTensorizedRandProj(\n",
    "            prng_key,\n",
    "            n_features // (trunc_level-1),\n",
    "            trunc_level,\n",
    "            rbf_dimension = 800,\n",
    "            max_batch = max_batch,\n",
    "            )],\n",
    "        \n",
    "        ]\n",
    "\n",
    "    numpy_seed = 99\n",
    "    rocket_models = [\n",
    "        [\"Rocket\", Rocket(n_features//2, random_state=numpy_seed)],\n",
    "        [\"MiniRocket\", MiniRocketMultivariate(n_features, random_state=numpy_seed)],\n",
    "        [\"MultiRocket\", MultiRocketMultivariate(n_features//4, random_state=numpy_seed)],\n",
    "        ]\n",
    "    \n",
    "    # Run experiments\n",
    "    model_names = [name for (name, _) in jax_models+rocket_models]\n",
    "    results_ridge = []\n",
    "    results_rotforest = []\n",
    "    #jax\n",
    "    for name, model in jax_models:\n",
    "        res_ridge, res_rotforest = train_and_test_sigbased(\n",
    "            X_train, y_train, X_test, y_test, model\n",
    "            )\n",
    "        results_ridge.append(res_ridge)\n",
    "        results_rotforest.append(res_rotforest)\n",
    "        \n",
    "    #numpy\n",
    "    for name, model in rocket_models:\n",
    "        res_ridge, res_rotforest = train_and_test_ROCKETS(\n",
    "            X_train, y_train, X_test, y_test, model\n",
    "            )\n",
    "        results_ridge.append(res_ridge)\n",
    "        results_rotforest.append(res_rotforest)\n",
    "    \n",
    "    return model_names, results_ridge, results_rotforest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def do_experiments(datasets: List[str]):\n",
    "#     experiments = {}\n",
    "#     experiments_metadata = {}\n",
    "#     failed = {}\n",
    "#     for dataset_name in tqdm(datasets):\n",
    "#         t0 = time.time()\n",
    "#         try:\n",
    "#             print(dataset_name)\n",
    "#             X_train, y_train, X_test, y_test = get_aeon_dataset(dataset_name)\n",
    "#             X_train, X_test = normalize_streams(X_train, X_test, max_T=1000)\n",
    "#             y_train, y_test = normalize_mean_std_traindata(y_train, y_test)\n",
    "#             N_train = X_train.shape[0]\n",
    "#             N_test = X_test.shape[0]\n",
    "#             T = X_train.shape[1]\n",
    "#             D = X_train.shape[2]\n",
    "#             if N_train > 2000 or D > 20:\n",
    "#                 continue\n",
    "#             results = run_all_experiments(\n",
    "#                 X_train, y_train, X_test, y_test\n",
    "#                 )\n",
    "#             experiments_metadata[dataset_name] = {\n",
    "#                 \"N_train\": N_train,\n",
    "#                 \"N_test\": N_test,\n",
    "#                 \"T\": T,\n",
    "#                 \"D\": D,\n",
    "#             }\n",
    "#             experiments[dataset_name] = results\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error: {e}\")\n",
    "#             failed[dataset_name] = e\n",
    "#         print(\"Elapsed time\", time.time()-t0)\n",
    "#     return experiments, experiments_metadata, failed\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     d_res, d_meta, d_failed = do_experiments(list(tser_soton))\n",
    "    \n",
    "#     # Define the attributes and methods\n",
    "#     attributes = [\"RMSE_train\", \"RMSE_test\", \"time_transform\", \"time_fit\", \"alpha\"]\n",
    "#     methods = [\"ridge\", \"rotforest\"]\n",
    "    \n",
    "#     # Extract model_names from d_res\n",
    "#     model_names = next(iter(d_res.values()))[0]\n",
    "\n",
    "#     # Create and save DataFrames for each attribute and method\n",
    "#     for attribute in attributes:\n",
    "#         for method in methods:\n",
    "#             df = pd.DataFrame(columns=model_names)\n",
    "#             for dataset_name, (model_names, results_ridge, results_rotforest) in d_res.items():\n",
    "#                 if method == \"ridge\":\n",
    "#                     results = results_ridge\n",
    "#                 elif method == \"rotforest\":\n",
    "#                     results = results_rotforest\n",
    "\n",
    "#                 values = [res[attributes.index(attribute)] for res in results]\n",
    "#                 df.loc[dataset_name] = values\n",
    "\n",
    "#             # Save the DataFrame\n",
    "#             print(df)\n",
    "#             df.to_pickle(f\"TESR_{attribute}_{method}_results.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
