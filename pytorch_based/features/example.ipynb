{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Set, Any, Optional, Tuple, Literal, Callable\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from kernels.static_kernels import LinearKernel, RBFKernel\n",
    "from kernels.sig_trunc import TruncSigKernel\n",
    "\n",
    "from features.random_fourier import RBF_RandomFourierFeatures\n",
    "from features.random_sig_fourier import SigTensorisedRandProj\n",
    "from features.random_warping_series import RandomWarpingSeries\n",
    "from features.signature import sig, logsig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #######################\n",
    "# ######### RWS #########\n",
    "# #######################\n",
    "\n",
    "def RWS_test():\n",
    "    # Setup and parameters\n",
    "    N = 3\n",
    "    N2 = 2\n",
    "    T = 70\n",
    "    d = 2\n",
    "    dtype = torch.float32\n",
    "    #torch.manual_seed(3)\n",
    "    X = torch.randn(N, T, d, dtype=dtype).to(\"cuda\").detach()\n",
    "    Y = torch.randn(N2,T, d, dtype=dtype).to(\"cuda\").detach()\n",
    "    n_features = 20\n",
    "    D_min=2\n",
    "    D_max=5\n",
    "    sigma=1\n",
    "\n",
    "    # RWS\n",
    "    rws = RandomWarpingSeries(n_features, D_min, D_max, sigma, LinearKernel(scale=1/d/T))\n",
    "    rws.fit(X)\n",
    "    feat_X = rws.transform(X)\n",
    "    feat_Y = rws.transform(Y)\n",
    "    K_rws = 1 + feat_X @ feat_Y.T\n",
    "    print(feat_X)\n",
    "    print(feat_X.shape)\n",
    "    print(K_rws)\n",
    "\n",
    "RWS_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#### Lib signatory wrapper ####\n",
    "###############################\n",
    "\n",
    "def test_signatory():\n",
    "    N,T,d = 1, 30, 2\n",
    "    trunc_level = 3\n",
    "    X = torch.randn(N, T, d)\n",
    "    sigs = sig(X, trunc_level) # potential unknown bug. Says imput is not 3D, but it clearly is.\n",
    "    logsigs = logsig(X, trunc_level)\n",
    "    print(\"sigs\", sigs.shape, sigs)\n",
    "    print(\"logsigs\", logsigs.shape, logsigs)\n",
    "\n",
    "# test_signatory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#### Linear TRP-RFSF features  vs  Vanilla Sig kernel ####\n",
    "##########################################################\n",
    "\n",
    "def LINEAR_trp_vs_kernel():\n",
    "    #parameters\n",
    "    N = 3\n",
    "    N2 = 2\n",
    "    T = 20\n",
    "    d = 2\n",
    "    trunc_level = 5\n",
    "    n_features = 100\n",
    "    dtype = torch.float32\n",
    "    #torch.manual_seed(3)\n",
    "    X = torch.randn(N, T, d, dtype=dtype).to(\"cuda\").detach() / np.sqrt(d)\n",
    "    Y = torch.randn(N2,T, d, dtype=dtype).to(\"cuda\").detach() / np.sqrt(d)\n",
    "\n",
    "    #exact sig kernel\n",
    "    sigker = TruncSigKernel(LinearKernel(), normalize=False, trunc_level=trunc_level, geo_order=1, max_batch=50000)\n",
    "    K = sigker(X,Y)\n",
    "    print(\"exact\\n\", K)\n",
    "\n",
    "    #trp\n",
    "    MC_iter = 10000\n",
    "    res = []\n",
    "    for i in tqdm(range(MC_iter)):\n",
    "        trp = SigTensorisedRandProj(trunc_level, n_features, only_last=True, method=\"linear\")\n",
    "        trp.fit(X)\n",
    "        feat_X = trp.transform(X)\n",
    "        feat_Y = trp.transform(Y)\n",
    "        K_trp = 1 + feat_X @ feat_Y.T\n",
    "        res.append(K_trp)\n",
    "    res = torch.stack(res)\n",
    "    example = res[0]\n",
    "    mean = res.mean(dim=0)\n",
    "    print(\"mean\\n\", mean)\n",
    "    print(\"example\\n\", example)\n",
    "\n",
    "LINEAR_trp_vs_kernel()\n",
    "# exact\n",
    "#  tensor([[ 4627.0444, -5744.9629],\n",
    "#         [ 9709.9150, -7802.3965],\n",
    "#         [-1727.5579,  2563.8979]], device='cuda:0')\n",
    "# 100%|██████████| 10000/10000 [00:15<00:00, 641.01it/s] # n_features = 500, trunc_level = 5\n",
    "# mean\n",
    "#  tensor([[ 4624.3896, -5737.0781],\n",
    "#         [ 9733.1250, -7796.5479],\n",
    "#         [-1733.9088,  2575.4778]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#### Gaussian TRP-RFSF features  vs  SigRBF kernel ####\n",
    "#######################################################\n",
    "\n",
    "def GAUSSIAN_trp_vs_kernel():\n",
    "    #parameters\n",
    "    N = 3\n",
    "    N2 = 2\n",
    "    T = 20\n",
    "    d = 2\n",
    "    trunc_level = 5\n",
    "    n_features = 500\n",
    "    sigma = 1.0\n",
    "    dtype = torch.float32\n",
    "    #torch.manual_seed(3)\n",
    "    X = torch.randn(N, T, d, dtype=dtype).to(\"cuda\").detach() / np.sqrt(d)\n",
    "    Y = torch.randn(N2,T, d, dtype=dtype).to(\"cuda\").detach() / np.sqrt(d)\n",
    "\n",
    "    #exact sig kernel\n",
    "    sigker = TruncSigKernel(RBFKernel(sigma=sigma), normalize=False, trunc_level=trunc_level, geo_order=1, max_batch=50000)\n",
    "    K = sigker(X,Y)\n",
    "    print(\"exact\\n\", K)\n",
    "\n",
    "    #trp\n",
    "    MC_iter = 10000\n",
    "    res = []\n",
    "    for i in tqdm(range(MC_iter)):\n",
    "        trp = SigTensorisedRandProj(trunc_level, n_features, only_last=True, method=\"RBF\", sigma_rbf=sigma)\n",
    "        trp.fit(X)\n",
    "        feat_X = trp.transform(X)\n",
    "        feat_Y = trp.transform(Y)\n",
    "        K_trp = 1 + feat_X @ feat_Y.T\n",
    "        res.append(K_trp)\n",
    "    res = torch.stack(res)\n",
    "    example = res[0]\n",
    "    mean = res.mean(dim=0)\n",
    "    print(\"mean\\n\", mean)\n",
    "    print(\"example\\n\", example)\n",
    "\n",
    "GAUSSIAN_trp_vs_kernel()\n",
    "# GAUSSIAN_trp_vs_kernel()\n",
    "# # exact\n",
    "# #  tensor([[ -8.7953, -30.1428],\n",
    "# #         [ -4.1622,  -4.5515],\n",
    "# #         [-25.4650,  42.8830]], device='cuda:0')\n",
    "# # 100%|██████████| 10000/10000 [05:55<00:00, 28.10it/s] # n_features=5000, trunc_level=5\n",
    "# # mean\n",
    "# #  tensor([[ -9.9236, -30.5771],\n",
    "# #         [ -4.4291,  -4.5940],\n",
    "# #         [-25.3243,  43.3625]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K\n",
      " tensor([[0.4836, 0.5957],\n",
      "        [0.4566, 0.4028],\n",
      "        [0.2332, 0.2142]], device='cuda:0', dtype=torch.float64)\n",
      "K_rff\n",
      " tensor([[0.4835, 0.5957],\n",
      "        [0.4568, 0.4027],\n",
      "        [0.2331, 0.2142]], device='cuda:0', dtype=torch.float64)\n",
      "diff\n",
      " tensor([[ 1.3046e-04,  2.6550e-05],\n",
      "        [-1.3180e-04,  7.4476e-05],\n",
      "        [ 1.5004e-04,  3.9122e-05]], device='cuda:0', dtype=torch.float64)\n",
      "diffmean\n",
      " tensor(9.2075e-05, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "#### Test RBF_RandomFourierFeatures vs exact RBF kernel ####\n",
    "############################################################\n",
    "def rff_vs_exact_RBFKernel():\n",
    "    N=3\n",
    "    N2= 2\n",
    "    d = 10\n",
    "    sigma=1\n",
    "    dtype = torch.float64\n",
    "    # torch.manual_seed(1)\n",
    "    X = torch.randn(N, d, dtype=dtype).to(\"cuda\") /np.sqrt(d)\n",
    "    Y = torch.randn(N2, d, dtype=dtype).to(\"cuda\") / np.sqrt(d)\n",
    "\n",
    "    # Exact RBF kernel\n",
    "    k = RBFKernel(sigma=sigma)\n",
    "    K = k(X, Y)\n",
    "\n",
    "    # Approximate RBF kernel using RBF_RandomFourierFeatures\n",
    "    N_MC = 10000\n",
    "    res = []\n",
    "    for i in range(N_MC):\n",
    "        RFF = RBF_RandomFourierFeatures(n_features=1000,\n",
    "                                        sigma=sigma,\n",
    "                                        method=\"cos(x)sin(x)\",\n",
    "                                        # method = \"cos(x + b)\",\n",
    "                                        )\n",
    "        RFF.fit(X)\n",
    "        feat_X = RFF.transform(X)\n",
    "        feat_Y = RFF.transform(Y)\n",
    "        K_rff = feat_X @ feat_Y.T\n",
    "        res.append(K_rff)\n",
    "    K_rff = torch.mean(torch.stack(res), dim=0)\n",
    "\n",
    "    print(\"K\\n\",K)\n",
    "    print(\"K_rff\\n\",K_rff)\n",
    "    print(\"diff\\n\", K-K_rff)\n",
    "    print(\"diffmean\\n\", torch.mean(abs(K-K_rff)))\n",
    "    # the RFF approach cant reproduce results smaller than 1e-5 for some reason\n",
    "    \n",
    "rff_vs_exact_RBFKernel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
