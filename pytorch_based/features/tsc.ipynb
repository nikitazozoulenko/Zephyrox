{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikita/Code/zephyrox/.conda/lib/python3.10/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "import numpy as np\n",
    "import aeon\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from aeon.datasets.tsc_datasets import univariate_equal_length, multivariate_equal_length\n",
    "univariate_equal_length = sorted(list(univariate_equal_length))\n",
    "multivariate_equal_length = sorted(list(multivariate_equal_length))\n",
    "from aeon.datasets import load_classification\n",
    "from sklearn.linear_model import RidgeCV, RidgeClassifierCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.utils import print_name, print_shape\n",
    "from preprocessing.stream_transforms import normalize_mean_std_traindata, normalize_streams, augment_time, add_basepoint_zero\n",
    "from random_sig_fourier import SigTensorisedRandProj\n",
    "from signature import SigTransform, LogSigTransform\n",
    "from features.base import TimeseriesFeatureExtractor, TabularTimeseriesFeatures, RandomGuesser\n",
    "from randomized_sig import RandomizedSignature\n",
    "from rocket_wrappers import RocketWrapper, MiniRocketWrapper, MultiRocketWrapper\n",
    "from pytorch_based.features.multirocket import MultiRocketOwn\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#######          Dataset Code         #######\n",
    "#############################################\n",
    "\n",
    "def get_aeon_dataset(\n",
    "        dataset_name:str, \n",
    "        extract_path = \"/home/nikita/hdd/Data/TSC/\",\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        ):\n",
    "    \"\"\"Loads a dataset from the UCR/UEA archive using \n",
    "    the aeon library.\n",
    "\n",
    "    Args:\n",
    "        dataset_name (str): Name of the dataset\n",
    "\n",
    "    Returns:\n",
    "        Tuple: 4-tuple of the form (X_train, y_train, X_test, y_test)\n",
    "    \"\"\"\n",
    "    X_train, y_train = load_classification(dataset_name, split=\"train\", extract_path=extract_path)\n",
    "    X_test, y_test = load_classification(dataset_name, split=\"test\", extract_path=extract_path)\n",
    "    X_train = torch.from_numpy(X_train.transpose(0,2,1)).to(device).float().detach()\n",
    "    X_test = torch.from_numpy(X_test.transpose(0,2,1)).to(device).float().detach()\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_get_data(idx: int = 17):\n",
    "#     name = univariate_equal_length[idx]\n",
    "#     X_train, y_train, X_test, y_test = get_aeon_dataset(name, device=\"cpu\")\n",
    "#     print(\"Dataset:\", name)\n",
    "#     print(\"idx:\", idx)\n",
    "#     print(\"X_train\", X_train.shape)\n",
    "#     print(\"X_test\", X_test.shape)\n",
    "\n",
    "# for i in range(20):\n",
    "#     test_get_data(i)\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "####  Linear Model (Ridge)  ######\n",
    "##################################\n",
    "\n",
    "def train_and_test_linear(\n",
    "        train_X, train_y, test_X, test_y,\n",
    "        feat_extractor: TimeseriesFeatureExtractor,\n",
    "        apply_augmentation:bool=True,\n",
    "        normalize_features:bool=True,\n",
    "        clf=RidgeClassifierCV(alphas=np.logspace(-1, 5, 20))\n",
    "    ):\n",
    "    # augment data\n",
    "    print(train_X.shape)\n",
    "    if apply_augmentation:\n",
    "        train_X, test_X = normalize_mean_std_traindata(train_X, test_X)\n",
    "        train_X = add_basepoint_zero(train_X)\n",
    "        train_X = augment_time(train_X)\n",
    "        test_X = add_basepoint_zero(test_X)\n",
    "        test_X = augment_time(test_X)\n",
    "\n",
    "    # fit transformer\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        feat_extractor.fit(train_X)\n",
    "        feat_train_X = feat_extractor.transform(train_X).cpu().numpy()\n",
    "        feat_test_X = feat_extractor.transform(test_X).cpu().numpy()\n",
    "        print(\"feat_train_X\", feat_train_X.shape)\n",
    "        if normalize_features:\n",
    "            feat_train_X, feat_test_X = normalize_mean_std_traindata(feat_train_X, feat_test_X)\n",
    "\n",
    "\n",
    "    # feed into linear classifier\n",
    "    t1 = time.time()\n",
    "    clf.fit(feat_train_X, train_y)\n",
    "    t2 = time.time()\n",
    "\n",
    "    # predict\n",
    "    pred = clf.predict(feat_test_X)\n",
    "    test_acc = accuracy_score(test_y, pred)\n",
    "    train_acc = accuracy_score(train_y, clf.predict(feat_train_X))\n",
    "    alpha = clf.alpha_ if hasattr(clf, 'alpha_') else None\n",
    "    return train_acc, test_acc, alpha, t1-t0, t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_allModels_singleDataset(X_train, y_train, X_test, y_test):\n",
    "    max_batch = 32\n",
    "    trunc_level = 4\n",
    "    n_features = 1344\n",
    "    n_rocket_features = 20000\n",
    "\n",
    "    models = [\n",
    "        [\"Random Guesser\", RandomGuesser()],\n",
    "        [\"Tabular\", TabularTimeseriesFeatures()],\n",
    "        # # [\"Sig\", SigTransform(trunc_level, max_batch)],\n",
    "        # # [\"Log Sig\", LogSigTransform(trunc_level, max_batch)],\n",
    "        # [\"Randomized Signature\", RandomizedSignature(\n",
    "        #     n_features,\n",
    "        #     activation = \"tanh\",\n",
    "        #     max_batch=10,\n",
    "        #     )],\n",
    "        # [\"TRP\", SigTensorisedRandProj(\n",
    "        #     trunc_level,\n",
    "        #     n_features,\n",
    "        #     only_last=True,\n",
    "        #     method=\"linear\",\n",
    "        #     max_batch=max_batch,\n",
    "        #     )],\n",
    "        # [\"TRP rbf\", SigTensorisedRandProj(\n",
    "        #     trunc_level,\n",
    "        #     n_features,\n",
    "        #     only_last=True,\n",
    "        #     method=\"RBF\",\n",
    "        #     sigma_rbf=1.0,\n",
    "        #     max_batch=max_batch,\n",
    "        #     )],\n",
    "        # [\"concat TRP\", SigTensorisedRandProj(\n",
    "        #     trunc_level,\n",
    "        #     n_features // (trunc_level-1),\n",
    "        #     only_last=False,\n",
    "        #     method=\"linear\",\n",
    "        #     max_batch=max_batch,\n",
    "        #     )],\n",
    "        # [\"concat TRP rbf\", SigTensorisedRandProj(\n",
    "        #     trunc_level,\n",
    "        #     n_features // (trunc_level-1),\n",
    "        #     only_last=False,\n",
    "        #     method=\"RBF\",\n",
    "        #     sigma_rbf=1.0,\n",
    "        #     max_batch=max_batch,\n",
    "            # )],\n",
    "        # [\"Rocket\", RocketWrapper(\n",
    "        #     n_rocket_features\n",
    "        #     )],\n",
    "        [\"MiniRocket\", MiniRocketWrapper(\n",
    "            n_rocket_features\n",
    "            )],\n",
    "        [\"MultiRocket\", MultiRocketWrapper(\n",
    "            n_rocket_features\n",
    "            )],\n",
    "        [\"MyOwnMultiRocket\", MultiRocketOwn(\n",
    "            n_rocket_features,\n",
    "            max_batch=32,\n",
    "            )],\n",
    "        ]\n",
    "\n",
    "    # Run experiments\n",
    "    model_names = [name for (name, _) in models]\n",
    "    results_ridge = []\n",
    "    for name, model in models:\n",
    "        print(\"name\", name)\n",
    "        result = train_and_test_linear(\n",
    "            X_train, y_train, X_test, y_test, model\n",
    "            )\n",
    "        results_ridge.append(result)\n",
    "        print()\n",
    "    \n",
    "    return model_names, results_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dataset(dataset_name:str):\n",
    "    X_train, y_train, X_test, y_test = get_aeon_dataset(dataset_name)\n",
    "    X_train, X_test = normalize_streams(X_train, X_test, max_T=1000)\n",
    "    model_names, results_ridge = run_allModels_singleDataset(X_train, y_train, X_test, y_test)\n",
    "    return model_names, results_ridge\n",
    "\n",
    "#model_names, results_ridge = run_dataset(univariate_equal_length[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 100\n",
      "torch.Size([2, 100])\n",
      "torch.Size([2, 84])\n",
      "torch.Size([2, 672])\n",
      "torch.Size([2, 100])\n",
      "\n",
      "n_features: 500\n",
      "torch.Size([2, 500])\n",
      "torch.Size([2, 420])\n",
      "torch.Size([2, 672])\n",
      "torch.Size([2, 500])\n",
      "\n",
      "n_features: 1000\n",
      "torch.Size([2, 1000])\n",
      "torch.Size([2, 924])\n",
      "torch.Size([2, 672])\n",
      "torch.Size([2, 1000])\n",
      "\n",
      "n_features: 2000\n",
      "torch.Size([2, 2000])\n",
      "torch.Size([2, 1932])\n",
      "torch.Size([2, 1344])\n",
      "torch.Size([2, 2000])\n",
      "\n",
      "n_features: 1344\n",
      "torch.Size([2, 1344])\n",
      "torch.Size([2, 1344])\n",
      "torch.Size([2, 1344])\n",
      "torch.Size([2, 1340])\n",
      "\n",
      "n_features: 4000\n",
      "torch.Size([2, 4000])\n",
      "torch.Size([2, 3948])\n",
      "torch.Size([2, 3360])\n",
      "torch.Size([2, 4000])\n",
      "\n",
      "n_features: 6000\n",
      "torch.Size([2, 6000])\n",
      "torch.Size([2, 5964])\n",
      "torch.Size([2, 5376])\n",
      "torch.Size([2, 6000])\n",
      "\n",
      "n_features: 8000\n",
      "torch.Size([2, 8000])\n",
      "torch.Size([2, 7980])\n",
      "torch.Size([2, 7392])\n",
      "torch.Size([2, 8000])\n",
      "\n",
      "n_features: 10000\n",
      "torch.Size([2, 10000])\n",
      "torch.Size([2, 9996])\n",
      "torch.Size([2, 9408])\n",
      "torch.Size([2, 10000])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rocket_wrappers import RocketWrapper, MiniRocketWrapper, MultiRocketWrapper\n",
    "\n",
    "for n_features in [100, 500, 1000, 2000, 1344, 4000, 6000, 8000, 10000]:\n",
    "    rocket = RocketWrapper(n_features)\n",
    "    mini_rocket = MiniRocketWrapper(n_features)\n",
    "    multi_rocket = MultiRocketWrapper(n_features)\n",
    "    own = MultiRocketOwn(n_features)\n",
    "    \n",
    "    print(\"n_features:\", n_features)\n",
    "    \n",
    "    # Generate random input\n",
    "    input_shape = (2, 150, 1)  # N T D\n",
    "    X = torch.randn(input_shape)\n",
    "    \n",
    "    # Fit to random input\n",
    "    print(rocket.fit_transform(X).shape)\n",
    "    print(mini_rocket.fit_transform(X).shape)\n",
    "    print(multi_rocket.fit_transform(X).shape)\n",
    "    print(own.fit_transform(X).shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_allModels_allData(datasets: List[str]):\n",
    "    #run experiments\n",
    "    experiments = {}\n",
    "    failed = {}\n",
    "    for dataset_name in tqdm(datasets):\n",
    "        t0 = time.time()\n",
    "        # try:\n",
    "        print(dataset_name)\n",
    "        X_train, y_train, X_test, y_test = get_aeon_dataset(dataset_name)\n",
    "        X_train, X_test = normalize_streams(X_train, X_test, max_T=1000)\n",
    "        N_train = X_train.shape[0]\n",
    "        N_test = X_test.shape[0]\n",
    "        T = X_train.shape[1]\n",
    "        D = X_train.shape[2]\n",
    "        if N_train<=2000 and D<=20:\n",
    "            results = run_allModels_singleDataset(\n",
    "                X_train, y_train, X_test, y_test\n",
    "                )\n",
    "            experiments[dataset_name] = results\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Error: {e}\")\n",
    "        #     failed[dataset_name] = e\n",
    "        print(\"Elapsed time\", time.time()-t0)\n",
    "    \n",
    "    #parse results\n",
    "    # Define the attributes and methods\n",
    "    attributes = [\"ACC_train\", \"ACC_test\", \"alpha\", \"time_transform\", \"time_fit\"]\n",
    "    \n",
    "    # Extract model_names from d_res\n",
    "    model_names = next(iter(experiments.values()))[0]\n",
    "\n",
    "    # Create and save DataFrames for each attribute and method\n",
    "    for attribute in attributes:\n",
    "        df = pd.DataFrame(columns=model_names)\n",
    "        for dataset_name, (model_names, results_ridge) in experiments.items():\n",
    "            values = [res[attributes.index(attribute)] for res in results_ridge]\n",
    "            df.loc[dataset_name] = values\n",
    "\n",
    "        # Save the DataFrame\n",
    "        print(df)\n",
    "        df.to_pickle(f\"TSC_{attribute}_results.pkl\")\n",
    "\n",
    "    return experiments, failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACSF1\n",
      "name Random Guesser\n",
      "torch.Size([100, 730, 1])\n",
      "feat_train_X (100, 2)\n",
      "\n",
      "name Tabular\n",
      "torch.Size([100, 730, 1])\n",
      "feat_train_X (100, 1462)\n",
      "\n",
      "name MiniRocket\n",
      "torch.Size([100, 730, 1])\n",
      "feat_train_X (100, 19992)\n",
      "\n",
      "name MultiRocket\n",
      "torch.Size([100, 730, 1])\n",
      "feat_train_X (100, 19488)\n",
      "\n",
      "name MyOwnMultiRocket\n",
      "torch.Size([100, 730, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:08<02:37,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_train_X (100, 19992)\n",
      "\n",
      "Elapsed time 8.282074928283691\n",
      "Adiac\n",
      "name Random Guesser\n",
      "torch.Size([390, 176, 1])\n",
      "feat_train_X (390, 2)\n",
      "\n",
      "name Tabular\n",
      "torch.Size([390, 176, 1])\n",
      "feat_train_X (390, 354)\n",
      "\n",
      "name MiniRocket\n",
      "torch.Size([390, 176, 1])\n",
      "feat_train_X (390, 19992)\n",
      "\n",
      "name MultiRocket\n",
      "torch.Size([390, 176, 1])\n",
      "feat_train_X (390, 19488)\n",
      "\n",
      "name MyOwnMultiRocket\n",
      "torch.Size([390, 176, 1])\n",
      "feat_train_X (390, 20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:16<02:26,  8.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 7.9974000453948975\n",
      "ArrowHead\n",
      "name Random Guesser\n",
      "torch.Size([36, 251, 1])\n",
      "feat_train_X (36, 2)\n",
      "\n",
      "name Tabular\n",
      "torch.Size([36, 251, 1])\n",
      "feat_train_X (36, 504)\n",
      "\n",
      "name MiniRocket\n",
      "torch.Size([36, 251, 1])\n",
      "feat_train_X (36, 19992)\n",
      "\n",
      "name MultiRocket\n",
      "torch.Size([36, 251, 1])\n",
      "feat_train_X (36, 19488)\n",
      "\n",
      "name MyOwnMultiRocket\n",
      "torch.Size([36, 251, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:19<01:40,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_train_X (36, 20000)\n",
      "\n",
      "Elapsed time 3.3520665168762207\n",
      "BME\n",
      "name Random Guesser\n",
      "torch.Size([30, 128, 1])\n",
      "feat_train_X (30, 2)\n",
      "\n",
      "name Tabular\n",
      "torch.Size([30, 128, 1])\n",
      "feat_train_X (30, 258)\n",
      "\n",
      "name MiniRocket\n",
      "torch.Size([30, 128, 1])\n",
      "feat_train_X (30, 19992)\n",
      "\n",
      "name MultiRocket\n",
      "torch.Size([30, 128, 1])\n",
      "feat_train_X (30, 19488)\n",
      "\n",
      "name MyOwnMultiRocket\n",
      "torch.Size([30, 128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:21<01:08,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_train_X (30, 20000)\n",
      "\n",
      "Elapsed time 1.7426190376281738\n",
      "Beef\n",
      "name Random Guesser\n",
      "torch.Size([30, 470, 1])\n",
      "feat_train_X (30, 2)\n",
      "\n",
      "name Tabular\n",
      "torch.Size([30, 470, 1])\n",
      "feat_train_X (30, 942)\n",
      "\n",
      "name MiniRocket\n",
      "torch.Size([30, 470, 1])\n",
      "feat_train_X (30, 19992)\n",
      "\n",
      "name MultiRocket\n",
      "torch.Size([30, 470, 1])\n",
      "feat_train_X (30, 19488)\n",
      "\n",
      "name MyOwnMultiRocket\n",
      "torch.Size([30, 470, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:22<00:49,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_train_X (30, 19992)\n",
      "\n",
      "Elapsed time 1.6031842231750488\n",
      "BeetleFly\n",
      "name Random Guesser\n",
      "torch.Size([20, 512, 1])\n",
      "feat_train_X (20, 2)\n",
      "\n",
      "name Tabular\n",
      "torch.Size([20, 512, 1])\n",
      "feat_train_X (20, 1026)\n",
      "\n",
      "name MiniRocket\n",
      "torch.Size([20, 512, 1])\n",
      "feat_train_X (20, 19992)\n",
      "\n",
      "name MultiRocket\n",
      "torch.Size([20, 512, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:24<00:36,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_train_X (20, 19488)\n",
      "\n",
      "name MyOwnMultiRocket\n",
      "torch.Size([20, 512, 1])\n",
      "feat_train_X (20, 19992)\n",
      "\n",
      "Elapsed time 1.251401662826538\n",
      "BirdChicken\n",
      "name Random Guesser\n",
      "torch.Size([20, 512, 1])\n",
      "feat_train_X (20, 2)\n",
      "\n",
      "name Tabular\n",
      "torch.Size([20, 512, 1])\n",
      "feat_train_X (20, 1026)\n",
      "\n",
      "name MiniRocket\n",
      "torch.Size([20, 512, 1])\n",
      "feat_train_X (20, 19992)\n",
      "\n",
      "name MultiRocket\n",
      "torch.Size([20, 512, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:25<00:28,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_train_X (20, 19488)\n",
      "\n",
      "name MyOwnMultiRocket\n",
      "torch.Size([20, 512, 1])\n",
      "feat_train_X (20, 19992)\n",
      "\n",
      "Elapsed time 1.2300481796264648\n",
      "CBF\n",
      "name Random Guesser\n",
      "torch.Size([30, 128, 1])\n",
      "feat_train_X (30, 2)\n",
      "\n",
      "name Tabular\n",
      "torch.Size([30, 128, 1])\n",
      "feat_train_X (30, 258)\n",
      "\n",
      "name MiniRocket\n",
      "torch.Size([30, 128, 1])\n",
      "feat_train_X (30, 19992)\n",
      "\n",
      "name MultiRocket\n",
      "torch.Size([30, 128, 1])\n",
      "feat_train_X (30, 19488)\n",
      "\n",
      "name MyOwnMultiRocket\n",
      "torch.Size([30, 128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:33<00:48,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_train_X (30, 20000)\n",
      "\n",
      "Elapsed time 7.965376377105713\n",
      "Car\n",
      "name Random Guesser\n",
      "torch.Size([60, 577, 1])\n",
      "feat_train_X (60, 2)\n",
      "\n",
      "name Tabular\n",
      "torch.Size([60, 577, 1])\n",
      "feat_train_X (60, 1156)\n",
      "\n",
      "name MiniRocket\n",
      "torch.Size([60, 577, 1])\n",
      "feat_train_X (60, 19992)\n",
      "\n",
      "name MultiRocket\n",
      "torch.Size([60, 577, 1])\n",
      "feat_train_X (60, 19488)\n",
      "\n",
      "name MyOwnMultiRocket\n",
      "torch.Size([60, 577, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:36<00:40,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_train_X (60, 19992)\n",
      "\n",
      "Elapsed time 3.006862163543701\n",
      "Chinatown\n",
      "name Random Guesser\n",
      "torch.Size([20, 24, 1])\n",
      "feat_train_X (20, 2)\n",
      "\n",
      "name Tabular\n",
      "torch.Size([20, 24, 1])\n",
      "feat_train_X (20, 50)\n",
      "\n",
      "name MiniRocket\n",
      "torch.Size([20, 24, 1])\n",
      "feat_train_X (20, 19992)\n",
      "\n",
      "name MultiRocket\n",
      "torch.Size([20, 24, 1])\n",
      "feat_train_X (20, 19488)\n",
      "\n",
      "name MyOwnMultiRocket\n",
      "torch.Size([20, 24, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:37<00:29,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_train_X (20, 20000)\n",
      "\n",
      "Elapsed time 1.367276668548584\n",
      "ChlorineConcentration\n",
      "name Random Guesser\n",
      "torch.Size([467, 166, 1])\n",
      "feat_train_X (467, 2)\n",
      "\n",
      "name Tabular\n",
      "torch.Size([467, 166, 1])\n",
      "feat_train_X (467, 334)\n",
      "\n",
      "name MiniRocket\n",
      "torch.Size([467, 166, 1])\n",
      "feat_train_X (467, 19992)\n",
      "\n",
      "name MultiRocket\n",
      "torch.Size([467, 166, 1])\n",
      "feat_train_X (467, 19488)\n",
      "\n",
      "name MyOwnMultiRocket\n",
      "torch.Size([467, 166, 1])\n",
      "feat_train_X (467, 20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [01:30<02:44, 18.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time 52.965463399887085\n",
      "CinCECGTorso\n",
      "name Random Guesser\n",
      "torch.Size([40, 819, 1])\n",
      "feat_train_X (40, 2)\n",
      "\n",
      "name Tabular\n",
      "torch.Size([40, 819, 1])\n",
      "feat_train_X (40, 1640)\n",
      "\n",
      "name MiniRocket\n",
      "torch.Size([40, 819, 1])\n",
      "feat_train_X (40, 19992)\n",
      "\n",
      "name MultiRocket\n",
      "torch.Size([40, 819, 1])\n",
      "feat_train_X (40, 19488)\n",
      "\n",
      "name MyOwnMultiRocket\n",
      "torch.Size([40, 819, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [02:09<01:45, 11.73s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.91 GiB of which 997.06 MiB is free. Including non-PyTorch memory, this process has 6.57 GiB memory in use. Of the allocated memory 4.90 GiB is allocated by PyTorch, and 1.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m used_by_paper \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEthanolConcentration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#\"FaceDetection\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m#\"UWaveGestureLibrary\",\u001b[39;00m\n\u001b[1;32m     12\u001b[0m ]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# run_allModels_allData(used_by_paper)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#run_allModels_allData(used_by_paper)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mrun_allModels_allData\u001b[49m\u001b[43m(\u001b[49m\u001b[43munivariate_equal_length\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m, in \u001b[0;36mrun_allModels_allData\u001b[0;34m(datasets)\u001b[0m\n\u001b[1;32m     14\u001b[0m D \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m N_train\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m D\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m:\n\u001b[0;32m---> 16\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_allModels_singleDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     experiments[dataset_name] \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# except Exception as e:\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     print(f\"Error: {e}\")\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     failed[dataset_name] = e\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 67\u001b[0m, in \u001b[0;36mrun_allModels_singleDataset\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[0;32m---> 67\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_test_linear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     results_ridge\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m, in \u001b[0;36mtrain_and_test_linear\u001b[0;34m(train_X, train_y, test_X, test_y, feat_extractor, apply_augmentation, normalize_features, clf)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     24\u001b[0m     feat_extractor\u001b[38;5;241m.\u001b[39mfit(train_X)\n\u001b[0;32m---> 25\u001b[0m     feat_train_X \u001b[38;5;241m=\u001b[39m \u001b[43mfeat_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     26\u001b[0m     feat_test_X \u001b[38;5;241m=\u001b[39m feat_extractor\u001b[38;5;241m.\u001b[39mtransform(test_X)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeat_train_X\u001b[39m\u001b[38;5;124m\"\u001b[39m, feat_train_X\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/Code/zephyrox/pytorch_based/features/base.py:59\u001b[0m, in \u001b[0;36mTimeseriesFeatureExtractor.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform the input time series data into features. Splits the\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03mdata into sub-batches if necessary based on 'self.max_batch'.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    (Tensor): Feature vectors of shape (N, ...)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m split_X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_batch, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[0;32m---> 59\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batched_transform(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m split_X],\n\u001b[1;32m     60\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     61\u001b[0m     )\n",
      "File \u001b[0;32m~/Code/zephyrox/pytorch_based/features/base.py:59\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform the input time series data into features. Splits the\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03mdata into sub-batches if necessary based on 'self.max_batch'.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    (Tensor): Feature vectors of shape (N, ...)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m split_X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_batch, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[0;32m---> 59\u001b[0m     [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batched_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m split_X],\n\u001b[1;32m     60\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     61\u001b[0m     )\n",
      "File \u001b[0;32m~/Code/zephyrox/pytorch_based/features/multirocket.py:127\u001b[0m, in \u001b[0;36mMultiRocketOwn._batched_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_batched_transform\u001b[39m(\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    125\u001b[0m         X:Tensor,\n\u001b[1;32m    126\u001b[0m     ):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/zephyrox/.conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/zephyrox/pytorch_based/features/multirocket.py:105\u001b[0m, in \u001b[0;36mMultiRocketFeatures.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    103\u001b[0m x \u001b[38;5;241m=\u001b[39m [conv(x) \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs]\n\u001b[1;32m    104\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 105\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mfour_multirocket_pooling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Code/zephyrox/pytorch_based/features/multirocket.py:41\u001b[0m, in \u001b[0;36mfour_multirocket_pooling\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     39\u001b[0m cumsum \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcumsum(pos[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     40\u001b[0m te \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m*\u001b[39mcumsum\n\u001b[0;32m---> 41\u001b[0m te_cummax \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcummax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mte\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     42\u001b[0m lspv \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(te_cummax\u001b[38;5;241m.\u001b[39mdiff(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m/\u001b[39mT\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mconcat([ppv, mpv, mipv, lspv], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.91 GiB of which 997.06 MiB is free. Including non-PyTorch memory, this process has 6.57 GiB memory in use. Of the allocated memory 4.90 GiB is allocated by PyTorch, and 1.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "used_by_paper = [\n",
    "    \"EthanolConcentration\",\n",
    "    #\"FaceDetection\",\n",
    "    #\"Handwriting\",\n",
    "    \"Heartbeat\",\n",
    "    #\"JapaneseVowels\", #unequal length\n",
    "    #\"PEMS-SF\",\n",
    "    #\"SelfRegulationSCP1\",\n",
    "    #\"SelfRegulationSCP2\",\n",
    "    #\"SpokenArabicDigits\", #unequal length\n",
    "    #\"UWaveGestureLibrary\",\n",
    "]\n",
    "\n",
    "\n",
    "# run_allModels_allData(used_by_paper)\n",
    "#run_allModels_allData(used_by_paper)\n",
    "run_allModels_allData(univariate_equal_length[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the attributes and methods\n",
    "attributes = [\"ACC_train\", \"ACC_test\", \"time_transform\", \"time_fit\", \"alpha\"]\n",
    "#data_dir = \"https://github.com/nikitazozoulenko/zephyrox/raw/main/Data/TSER/\"\n",
    "data_dir = \"\"\n",
    "# Load and store the DataFrames for each attribute and method\n",
    "dfs = {}\n",
    "for attribute in attributes:\n",
    "    filename = f\"TSC_{attribute}_results.pkl\"\n",
    "    print(data_dir+filename)\n",
    "    df = pd.read_pickle(data_dir + filename)\n",
    "    dfs[attribute] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"alpha\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"ACC_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"ACC_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"time_transform\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
