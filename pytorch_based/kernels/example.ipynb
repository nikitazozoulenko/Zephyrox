{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Set, Any, Optional, Tuple, Literal, Callable\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import os\n",
    "import sys\n",
    "import tslearn\n",
    "import tslearn.metrics\n",
    "import timeit\n",
    "import iisignature\n",
    "\n",
    "from abstract_base import TimeSeriesKernel, StaticKernel\n",
    "from static_kernels import LinearKernel, RBFKernel, PolyKernel\n",
    "from integral import StaticIntegralKernel\n",
    "from sig_trunc import TruncSigKernel\n",
    "from gak import GlobalAlignmentKernel, sigma_gak\n",
    "from flattened_static import FlattenedStaticKernel\n",
    "from reservoir import ReservoirKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau tensor(0.2829, device='cuda:0')\n",
      "gram\n",
      " tensor([[5.1026, 5.3574],\n",
      "        [6.7520, 6.2966],\n",
      "        [6.1606, 5.6091]], device='cuda:0')\n",
      "naive\n",
      " tensor([[5.1026, 5.3574],\n",
      "        [6.7520, 6.2966],\n",
      "        [6.1606, 5.6091]], device='cuda:0')\n",
      "naive2\n",
      " tensor([[5.1026, 5.3574],\n",
      "        [6.7520, 6.2966],\n",
      "        [6.1606, 5.6091]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "##### Volterra Reservoir Kernel #####\n",
    "#####################################\n",
    "\n",
    "def naive_gram(X, Y, tau, gamma):\n",
    "    X = torch.flip(X, dims=[1])\n",
    "    Y = torch.flip(Y, dims=[1])\n",
    "    N, T, d = X.shape\n",
    "    N2, T, d = Y.shape\n",
    "    lin_ker = LinearKernel()\n",
    "    state_space_gram = lin_ker(X, Y) #shape N1 N2 T\n",
    "    prod = gamma**2 / (1 - tau**2 * state_space_gram)\n",
    "\n",
    "    gram = torch.zeros(N, N2, dtype=X.dtype, device=X.device)\n",
    "    for i in range(N):\n",
    "        for j in range(N2):\n",
    "            outer = 0\n",
    "            for t in range(T):\n",
    "                inner = 1\n",
    "                for s in range(t+1):\n",
    "                    inner *= prod[i, j, s]\n",
    "                outer += inner\n",
    "            gram[i, j] = 1 + outer\n",
    "    return gram\n",
    "\n",
    "\n",
    "def naive_gram2(X, Y, tau, gamma):\n",
    "    X = torch.flip(X, dims=[1])\n",
    "    Y = torch.flip(Y, dims=[1])\n",
    "    N, T, d = X.shape\n",
    "    N2, T, d = Y.shape\n",
    "    lin_ker = LinearKernel()\n",
    "    state_space_gram = lin_ker(X, Y) #shape N1 N2 T\n",
    "    prod = gamma**2 / (1 - tau**2 * state_space_gram)\n",
    "\n",
    "    gram = torch.zeros(N, N2, dtype=X.dtype, device=X.device)\n",
    "    gram = gram + 1/(1-gamma**2)\n",
    "    for t in range(T):\n",
    "        gram = 1 + prod[:,:,T-1-t] * gram\n",
    "    return gram\n",
    "\n",
    "\n",
    "\n",
    "def volterra_reservoir_kernel_test():\n",
    "    N = 3\n",
    "    N2 = 2\n",
    "    T = 70\n",
    "    d = 2\n",
    "    dtype = torch.float32\n",
    "    torch.manual_seed(3)\n",
    "    X = torch.randn(N, T, d, dtype=dtype).to(\"cuda\").detach()\n",
    "    Y = torch.randn(N2,T, d, dtype=dtype).to(\"cuda\").detach()\n",
    "    tau = 0.9 / torch.maximum(X.abs().max(), Y.abs().max())\n",
    "    print(\"tau\", tau)\n",
    "    gamma = 0.9\n",
    "\n",
    "    ker = ReservoirKernel(tau=tau, gamma=gamma)\n",
    "    gram = ker(X, Y)\n",
    "    print(\"gram\\n\", gram)\n",
    "    naive = naive_gram(X, Y, tau, gamma)\n",
    "    print(\"naive\\n\", naive)\n",
    "    naive2 = naive_gram2(X, Y, tau, gamma)\n",
    "    print(\"naive2\\n\", naive2)\n",
    "volterra_reservoir_kernel_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.5397, 0.6101, 0.4831, 0.5128, 0.6126, 0.6808, 0.5659],\n",
      "        [0.5397, 1.0000, 0.6964, 0.3003, 0.5562, 0.4147, 0.5552, 0.6372],\n",
      "        [0.6101, 0.6964, 1.0000, 0.4397, 0.4925, 0.4835, 0.7042, 0.7311],\n",
      "        [0.4831, 0.3003, 0.4397, 1.0000, 0.4666, 0.5981, 0.6449, 0.6898],\n",
      "        [0.5128, 0.5562, 0.4925, 0.4666, 1.0000, 0.5421, 0.6075, 0.6294],\n",
      "        [0.6126, 0.4147, 0.4835, 0.5981, 0.5421, 1.0000, 0.7800, 0.5428],\n",
      "        [0.6808, 0.5552, 0.7042, 0.6449, 0.6075, 0.7800, 1.0000, 0.7322],\n",
      "        [0.5659, 0.6372, 0.7311, 0.6898, 0.6294, 0.5428, 0.7322, 1.0000]])\n",
      "tensor([[1.0000, 0.5397, 0.6101, 0.4831, 0.5128, 0.6126, 0.6808, 0.5659],\n",
      "        [0.5397, 1.0000, 0.6964, 0.3003, 0.5562, 0.4147, 0.5552, 0.6372],\n",
      "        [0.6101, 0.6964, 1.0000, 0.4397, 0.4925, 0.4835, 0.7042, 0.7311],\n",
      "        [0.4831, 0.3003, 0.4397, 1.0000, 0.4666, 0.5981, 0.6449, 0.6898],\n",
      "        [0.5128, 0.5562, 0.4925, 0.4666, 1.0000, 0.5421, 0.6075, 0.6294],\n",
      "        [0.6126, 0.4147, 0.4835, 0.5981, 0.5421, 1.0000, 0.7800, 0.5428],\n",
      "        [0.6808, 0.5552, 0.7042, 0.6449, 0.6075, 0.7800, 1.0000, 0.7322],\n",
      "        [0.5659, 0.6372, 0.7311, 0.6898, 0.6294, 0.5428, 0.7322, 1.0000]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.7870e-08, dtype=torch.float64)\n",
      "Execution time of function 1: 3.06996690199594\n",
      "Execution time of function 3: 2.6005864489998203\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#### Test GAK ####\n",
    "N= 8\n",
    "N2= 20\n",
    "T, d = 20, 2\n",
    "torch.manual_seed(0)\n",
    "X = torch.randn(N,  T, d, dtype=torch.float64).to(\"cuda\") / d\n",
    "Y = torch.randn(N2, T, d, dtype=torch.float64).to(\"cuda\") / d\n",
    "\n",
    "sigma = tslearn.metrics.sigma_gak(X)\n",
    "gak = tslearn.metrics.cdist_gak\n",
    "mine = GlobalAlignmentKernel(RBFKernel(sigma=sigma), normalize=True, max_batch=50000)\n",
    "\n",
    "out = gak(X, X, sigma=sigma)\n",
    "print(out)\n",
    "\n",
    "out3 = mine(X, X)\n",
    "print(out3)\n",
    "print(torch.mean(torch.abs(out.cpu() - out3.cpu())))\n",
    "\n",
    "def function1():\n",
    "    gak(X, Y, sigma=sigma)\n",
    "\n",
    "def function3():\n",
    "    with torch.no_grad():\n",
    "        mine(X, Y)\n",
    "\n",
    "# Measure the execution time of function 1\n",
    "execution_time1 = timeit.timeit(function1, number=1)\n",
    "print(\"Execution time of function 1:\", execution_time1)\n",
    "# Measure the execution time of function 3\n",
    "execution_time3 = timeit.timeit(function3, number=1)\n",
    "print(\"Execution time of function 3:\", execution_time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sig_trunc.TruncSigKernel object at 0x7f2a14227e50>\n",
      "torch.Size([3, 3, 6])\n",
      "torch.Size([3, 4, 6])\n",
      "torch.Size([1, 1, 6])\n",
      "torch.Size([1, 1, 6])\n",
      "torch.Size([1, 4, 6])\n",
      "torch.Size([3, 1, 6])\n",
      "\n",
      "<sig_trunc.TruncSigKernel object at 0x7f2a14227e50>\n",
      "torch.Size([3, 6])\n",
      "torch.Size([4, 6])\n",
      "torch.Size([3, 6])\n",
      "torch.Size([1, 6])\n",
      "torch.Size([1, 6])\n",
      "\n",
      "<integral.StaticIntegralKernel object at 0x7f2a14260990>\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([3, 1])\n",
      "\n",
      "<integral.StaticIntegralKernel object at 0x7f2a14260990>\n",
      "torch.Size([3])\n",
      "torch.Size([4])\n",
      "torch.Size([3])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "\n",
      "<gak.GlobalAlignmentKernel object at 0x7f2a1423bed0>\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([3, 1])\n",
      "\n",
      "<gak.GlobalAlignmentKernel object at 0x7f2a1423bed0>\n",
      "torch.Size([3])\n",
      "torch.Size([4])\n",
      "torch.Size([3])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "\n",
      "<flattened_static.FlattenedStaticKernel object at 0x7f2a1439f450>\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([3, 1])\n",
      "\n",
      "<flattened_static.FlattenedStaticKernel object at 0x7f2a1439f450>\n",
      "torch.Size([3])\n",
      "torch.Size([4])\n",
      "torch.Size([3])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "\n",
      "<reservoir.ReservoirKernel object at 0x7f2a7eef3450>\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([3, 1])\n",
      "\n",
      "<reservoir.ReservoirKernel object at 0x7f2a7eef3450>\n",
      "torch.Size([3])\n",
      "torch.Size([4])\n",
      "torch.Size([3])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### test dimensions of TimeSeriesKernels ####\n",
    "\n",
    "N=3\n",
    "N2=4\n",
    "T, d = 7, 5\n",
    "X = torch.randn(N, T, d) / d**0.5\n",
    "Y = torch.randn(N2, T, d) / d**0.5\n",
    "inputs = [\n",
    "    (X, X),\n",
    "    (X, Y),\n",
    "    (X[0], X[0]),\n",
    "    (X[0], Y[0]),\n",
    "    (X[0], Y),\n",
    "    (X, Y[0]),\n",
    "]\n",
    "diag_inputs = [\n",
    "    (X, X),\n",
    "    (Y, Y),\n",
    "    (X[:min(N,N2)], Y[:min(N,N2)]),\n",
    "    (X[0], X[0]),\n",
    "    (X[0], Y[0]),\n",
    "]\n",
    "def test_kernel(ker: TimeSeriesKernel, inputs, diag=False):\n",
    "    print(ker)\n",
    "    for X, Y in inputs:\n",
    "        out = ker(X, Y, diag, normalize=False)\n",
    "        out_normalize = ker(X, Y, diag, normalize=True)\n",
    "        # print(out, \"out\")\n",
    "        # print(out_normalize, \"out, normalize\")\n",
    "        print(out.shape)\n",
    "    print()\n",
    "\n",
    "\n",
    "sigker = TruncSigKernel(static_kernel=RBFKernel(), \n",
    "                        trunc_level=6, \n",
    "                        geo_order=1,\n",
    "                        only_last=False,)\n",
    "test_kernel(sigker, inputs)\n",
    "test_kernel(sigker, diag_inputs, True)\n",
    "\n",
    "intker = StaticIntegralKernel(static_kernel=RBFKernel())\n",
    "test_kernel(intker, inputs)\n",
    "test_kernel(intker, diag_inputs, True)\n",
    "\n",
    "gak = GlobalAlignmentKernel(static_kernel=RBFKernel(sigma=sigma_gak(X)))\n",
    "test_kernel(gak, inputs)\n",
    "test_kernel(gak, diag_inputs, True)\n",
    "\n",
    "flat = FlattenedStaticKernel(static_kernel=LinearKernel())\n",
    "test_kernel(flat, inputs)\n",
    "test_kernel(flat, diag_inputs, True)\n",
    "\n",
    "res = ReservoirKernel(tau= 0.1, gamma=0.9)\n",
    "test_kernel(res, inputs)\n",
    "test_kernel(res, diag_inputs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mine tensor([[ 0.3805, -0.1749],\n",
      "        [ 1.0562,  1.1173]], device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "iisig [[ 0.38050659 -0.17487614]\n",
      " [ 1.05622317  1.1172864 ]]\n",
      "4.0245584642661925e-15\n"
     ]
    }
   ],
   "source": [
    "#Test that iisig gives the same result as mine\n",
    "\n",
    "# Number of signature levels to use.\n",
    "normalize=False\n",
    "trunc_level = 5\n",
    "geo_order = 5\n",
    "N=2\n",
    "N2= 2\n",
    "T, d = 20, 2\n",
    "torch.manual_seed(0)\n",
    "X = torch.randn(N, T, d, dtype=torch.float64).to(\"cuda\") / d\n",
    "Y = torch.randn(N2, T, d, dtype=torch.float64).to(\"cuda\") / d\n",
    "X_np = X.cpu().numpy()\n",
    "Y_np = Y.cpu().numpy()\n",
    "\n",
    "mine = TruncSigKernel(LinearKernel(scale=1), \n",
    "                      normalize=normalize, \n",
    "                      trunc_level=trunc_level, \n",
    "                      geo_order=geo_order, \n",
    "                      max_batch=50000)\n",
    "\n",
    "#test\n",
    "out2 = mine(X, Y)\n",
    "featuresX = iisignature.sig(X_np, trunc_level)\n",
    "featuresY = iisignature.sig(Y_np, trunc_level)\n",
    "out3 = 1+np.dot(featuresX, featuresY.T)\n",
    "print(\"\\nmine\", out2)\n",
    "print(\"\\niisig\", out3)\n",
    "print(np.mean(np.abs(out2.cpu().numpy() - out3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
