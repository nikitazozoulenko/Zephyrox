{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, tensor\n",
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "#from aeon.regression.sklearn import RotationForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from preprocessing.stream_transforms import normalize_mean_std_traindata, normalize_streams, augment_time, add_basepoint_zero\n",
    "from utils.utils import print_name, print_shape\n",
    "from models import ResNet, NeuralEulerODE, RidgeCVModule, E2EResNet\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import FittableModule, create_layer, ResidualBlock\n",
    "\n",
    "class StagewiseRandFeatBoostRegression(FittableModule):\n",
    "    def __init__(self, \n",
    "                 generator: torch.Generator, \n",
    "                 hidden_dim: int = 128, \n",
    "                 bottleneck_dim: int = 128,\n",
    "                 out_dim: int = 1,\n",
    "                 n_layers: int = 5,\n",
    "                 activation: nn.Module = nn.Tanh(),\n",
    "\n",
    "                 #TODO \n",
    "                 upscale_type = \"SWIM\", # \"dense\", identity\n",
    "                 second_in_resblock = \"identity\",\n",
    "                 ):\n",
    "        super(StagewiseRandFeatBoostRegression, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bottleneck_dim = bottleneck_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.activation = activation\n",
    "\n",
    "        # TODO\n",
    "        self.upscale_type = upscale_type\n",
    "        self.second_in_resblock = second_in_resblock\n",
    "\n",
    "        #create \n",
    "\n",
    "        # self.upscale = create_layer(generator, upscale_type, in_dim, hidden_size, activation)\n",
    "        # self.layers = []\n",
    "        # self.deltas = []\n",
    "        # self.regressors = []\n",
    "        # self.reg = None\n",
    "\n",
    "\n",
    "    def fit(self, X: Tensor, y: Tensor):\n",
    "\n",
    "\n",
    "        # Create regressor W_0\n",
    "        regressor = RidgeCVModule()\n",
    "        regressor.fit(X, y)\n",
    "        self.regressors.append(regressor)\n",
    "\n",
    "        # Layerwise boosting\n",
    "        for t in range(self.n_layers):\n",
    "            X0 = X\n",
    "\n",
    "            # Step 1: Create random feature layer   \n",
    "            layer = create_layer(self.generator, \"SWIM\", self.hidden_dim, self.bottleneck_dim, self.activation)\n",
    "            X, y = layer.fit(X, y)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "            # Step 2: Obtain activation gradient and learn Delta\n",
    "            # X shape (N, D)\n",
    "            # y shape (N, p)\n",
    "            # W shape (D, p)\n",
    "            # r shape (D, p)\n",
    "\n",
    "            SW, U = np.linalg.eigh(W.T @ W)\n",
    "            SX, V = np.linalg.eigh(x.T @ x)\n",
    "            Delta = (U.T @ W.T @ r.T @ x @ V) / (N*lambda_reg + SW[:, None]*SX[None, :])\n",
    "            Delta = U @ Delta @ V.T\n",
    "\n",
    "            # Step 3: Learn top level classifier\n",
    "\n",
    "\n",
    "        return self(X0), y\n",
    "\n",
    "\n",
    "    def forward(self, X: Tensor) -> Tensor:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models import FittableModule, create_layer, ResidualBlock\n",
    "\n",
    "# class RandFeatBoostRegression(FittableModule):\n",
    "#     def __init__(self, \n",
    "#                  generator: torch.Generator, \n",
    "#                  in_dim: int = 1,\n",
    "#                  hidden_size: int = 128, \n",
    "#                  out_dim: int = 1,\n",
    "#                  n_blocks: int = 5,\n",
    "#                  activation: nn.Module = nn.Tanh(),\n",
    "#                  adam_lr: float = 1e-3,\n",
    "#                  boost_lr: float = 1.0,\n",
    "#                  epochs: int = 50,\n",
    "#                  batch_size: int = 64,\n",
    "#                  upscale_type = \"SWIM\", # \"dense\", identity\n",
    "#                  second_in_resblock = \"identity\",\n",
    "#                  ):\n",
    "#         super(RandFeatBoostRegression, self).__init__()\n",
    "#         self.generator = generator\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.out_dim = out_dim\n",
    "#         self.n_blocks = n_blocks\n",
    "#         self.activation = activation\n",
    "#         self.adam_lr = adam_lr\n",
    "#         self.boost_lr = boost_lr\n",
    "#         self.epochs = epochs\n",
    "#         self.batch_size = batch_size\n",
    "#         self.upscale_type = upscale_type\n",
    "#         self.second_in_resblock = second_in_resblock\n",
    "\n",
    "#         self.upscale = create_layer(generator, upscale_type, in_dim, hidden_size, activation)\n",
    "#         self.layers = []\n",
    "#         self.deltas = []\n",
    "#         self.regressors = []\n",
    "#         self.reg = None\n",
    "\n",
    "\n",
    "#     def fit(self, X: Tensor, y: Tensor):\n",
    "#         device = X.device\n",
    "#         X0 = X\n",
    "#         X, y = self.upscale.fit(X, y)\n",
    "\n",
    "#         # Create a CPU generator for DataLoader\n",
    "#         data_loader_generator = torch.Generator(device='cpu')\n",
    "#         data_loader_generator.manual_seed(self.generator.initial_seed())\n",
    "\n",
    "#         # Layerwise boosting\n",
    "#         for t in range(self.n_blocks):\n",
    "#             layer = ResidualBlock(self.generator, self.hidden_size, self.hidden_size, self.upscale_type, self.second_in_resblock, self.activation)\n",
    "#             layer.fit(X, y)\n",
    "\n",
    "#             # Create top classifier\n",
    "#             reg = RidgeCVModule()\n",
    "\n",
    "\n",
    "#             #DELTA = nn.Parameter(torch.zeros(1, self.hidden_size, device=device))\n",
    "#             DELTA = nn.Parameter(torch.zeros(1, 1, device=device))\n",
    "#             if t > 0:\n",
    "#                 classifier.weight.data = self.classifiers[-1].weight.data.clone()\n",
    "#                 classifier.bias.data = self.classifiers[-1].bias.data.clone()\n",
    "\n",
    "#             #data loader\n",
    "#             dataset = torch.utils.data.TensorDataset(X, y)\n",
    "#             loader = torch.utils.data.DataLoader(\n",
    "#                 dataset, \n",
    "#                 batch_size=self.batch_size, \n",
    "#                 shuffle=True, \n",
    "#                 generator=data_loader_generator\n",
    "#             )\n",
    "\n",
    "#             #learn top level classifier and boost\n",
    "#             params = list(classifier.parameters()) + [DELTA]\n",
    "#             self.optimizer = torch.optim.Adam(params, lr=self.adam_lr, weight_decay=1e-5)\n",
    "#             for epoch in tqdm(range(self.epochs)):\n",
    "#                 for batch_X, batch_y in loader:\n",
    "#                     self.optimizer.zero_grad()\n",
    "\n",
    "#                     #forward pass\n",
    "#                     FofX = layer(batch_X) - batch_X # due to how i programmed ResidualBlock...\n",
    "#                     outputs = classifier(batch_X + DELTA * FofX)\n",
    "\n",
    "#                     #loss and backprop\n",
    "#                     loss = self.loss_fn(outputs, batch_y)\n",
    "#                     loss.backward()\n",
    "#                     self.optimizer.step()\n",
    "            \n",
    "#             #after convergence, update layers, deltas, and X\n",
    "#             self.layers.append(layer)\n",
    "#             self.deltas.append(DELTA)\n",
    "#             self.classifiers.append(classifier)\n",
    "#             with torch.no_grad():\n",
    "#                 X = X + self.boost_lr * DELTA * (layer(X)-X)\n",
    "\n",
    "#         self.classifier = classifier\n",
    "#         return self(X0), y\n",
    "\n",
    "\n",
    "#     def forward(self, X: Tensor) -> Tensor:\n",
    "#         X = self.upscale(X)\n",
    "#         for layer, DELTA in zip(self.layers, self.deltas):\n",
    "#             FofX = layer(X) - X\n",
    "#             X = X + self.boost_lr * DELTA * FofX\n",
    "#         return self.classifier(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/35 Processed dataset 44956: abalone\n",
      " 2/35 Processed dataset 44957: airfoil_self_noise\n",
      " 3/35 Processed dataset 44958: auction_verification\n",
      " 4/35 Processed dataset 44959: concrete_compressive_strength\n",
      " 5/35 Processed dataset 44963: physiochemical_protein\n",
      " 6/35 Processed dataset 44964: superconductivity\n",
      " 7/35 Processed dataset 44965: geographical_origin_of_music\n",
      " 8/35 Processed dataset 44966: solar_flare\n",
      " 9/35 Processed dataset 44969: naval_propulsion_plant\n",
      " 10/35 Processed dataset 44971: white_wine\n",
      " 11/35 Processed dataset 44972: red_wine\n",
      " 12/35 Processed dataset 44973: grid_stability\n",
      " 13/35 Processed dataset 44974: video_transcoding\n",
      " 14/35 Processed dataset 44975: wave_energy\n",
      " 15/35 Processed dataset 44976: sarcos\n",
      " 16/35 Processed dataset 44977: california_housing\n",
      " 17/35 Processed dataset 44978: cpu_activity\n",
      " 18/35 Processed dataset 44979: diamonds\n",
      " 19/35 Processed dataset 44980: kin8nm\n",
      " 20/35 Processed dataset 44981: pumadyn32nh\n",
      " 21/35 Processed dataset 44983: miami_housing\n",
      " 22/35 Processed dataset 44984: cps88wages\n",
      " 23/35 Processed dataset 44987: socmob\n",
      " 24/35 Processed dataset 44989: kings_county\n",
      " 25/35 Processed dataset 44990: brazilian_houses\n",
      " 26/35 Processed dataset 44992: fps_benchmark\n",
      " 27/35 Processed dataset 44993: health_insurance\n",
      " 28/35 Processed dataset 45012: fifa\n",
      " 29/35 Processed dataset 41021: Moneyball\n",
      " 30/35 Processed dataset 44960: energy_efficiency\n",
      " 31/35 Processed dataset 44962: forest_fires\n",
      " 32/35 Processed dataset 44967: student_performance_por\n",
      " 33/35 Processed dataset 44970: QSAR_fish_toxicity\n",
      " 34/35 Processed dataset 44994: cars\n",
      " 35/35 Processed dataset 45402: space_ga\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>n_features</th>\n",
       "      <th>%_unique_y</th>\n",
       "      <th>n_unique_y</th>\n",
       "      <th>has_categorical</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44973</th>\n",
       "      <td>grid_stability</td>\n",
       "      <td>10000</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44975</th>\n",
       "      <td>wave_energy</td>\n",
       "      <td>72000</td>\n",
       "      <td>49</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>71993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44980</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8192</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>8191</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44981</th>\n",
       "      <td>pumadyn32nh</td>\n",
       "      <td>8192</td>\n",
       "      <td>33</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>8191</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45402</th>\n",
       "      <td>space_ga</td>\n",
       "      <td>3107</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999356</td>\n",
       "      <td>3105</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44958</th>\n",
       "      <td>auction_verification</td>\n",
       "      <td>2043</td>\n",
       "      <td>8</td>\n",
       "      <td>0.998042</td>\n",
       "      <td>2039</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44994</th>\n",
       "      <td>cars</td>\n",
       "      <td>804</td>\n",
       "      <td>18</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>798</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44957</th>\n",
       "      <td>airfoil_self_noise</td>\n",
       "      <td>1503</td>\n",
       "      <td>6</td>\n",
       "      <td>0.968729</td>\n",
       "      <td>1456</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44970</th>\n",
       "      <td>QSAR_fish_toxicity</td>\n",
       "      <td>908</td>\n",
       "      <td>7</td>\n",
       "      <td>0.910793</td>\n",
       "      <td>827</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44959</th>\n",
       "      <td>concrete_compressive_strength</td>\n",
       "      <td>1030</td>\n",
       "      <td>9</td>\n",
       "      <td>0.910680</td>\n",
       "      <td>938</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44960</th>\n",
       "      <td>energy_efficiency</td>\n",
       "      <td>768</td>\n",
       "      <td>9</td>\n",
       "      <td>0.764323</td>\n",
       "      <td>587</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44990</th>\n",
       "      <td>brazilian_houses</td>\n",
       "      <td>10692</td>\n",
       "      <td>10</td>\n",
       "      <td>0.537879</td>\n",
       "      <td>5751</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44962</th>\n",
       "      <td>forest_fires</td>\n",
       "      <td>517</td>\n",
       "      <td>13</td>\n",
       "      <td>0.485493</td>\n",
       "      <td>251</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44963</th>\n",
       "      <td>physiochemical_protein</td>\n",
       "      <td>45730</td>\n",
       "      <td>10</td>\n",
       "      <td>0.347759</td>\n",
       "      <td>15903</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44987</th>\n",
       "      <td>socmob</td>\n",
       "      <td>1156</td>\n",
       "      <td>6</td>\n",
       "      <td>0.312284</td>\n",
       "      <td>361</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41021</th>\n",
       "      <td>Moneyball</td>\n",
       "      <td>1232</td>\n",
       "      <td>15</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>374</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44976</th>\n",
       "      <td>sarcos</td>\n",
       "      <td>48933</td>\n",
       "      <td>22</td>\n",
       "      <td>0.233258</td>\n",
       "      <td>11414</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44979</th>\n",
       "      <td>diamonds</td>\n",
       "      <td>53940</td>\n",
       "      <td>10</td>\n",
       "      <td>0.215091</td>\n",
       "      <td>11602</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44984</th>\n",
       "      <td>cps88wages</td>\n",
       "      <td>28155</td>\n",
       "      <td>7</td>\n",
       "      <td>0.212040</td>\n",
       "      <td>5970</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44989</th>\n",
       "      <td>kings_county</td>\n",
       "      <td>21613</td>\n",
       "      <td>22</td>\n",
       "      <td>0.186369</td>\n",
       "      <td>4028</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44977</th>\n",
       "      <td>california_housing</td>\n",
       "      <td>20640</td>\n",
       "      <td>9</td>\n",
       "      <td>0.186143</td>\n",
       "      <td>3842</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44974</th>\n",
       "      <td>video_transcoding</td>\n",
       "      <td>68784</td>\n",
       "      <td>19</td>\n",
       "      <td>0.159339</td>\n",
       "      <td>10960</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44983</th>\n",
       "      <td>miami_housing</td>\n",
       "      <td>13932</td>\n",
       "      <td>16</td>\n",
       "      <td>0.151522</td>\n",
       "      <td>2111</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44964</th>\n",
       "      <td>superconductivity</td>\n",
       "      <td>21263</td>\n",
       "      <td>82</td>\n",
       "      <td>0.141419</td>\n",
       "      <td>3007</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44992</th>\n",
       "      <td>fps_benchmark</td>\n",
       "      <td>24624</td>\n",
       "      <td>44</td>\n",
       "      <td>0.108634</td>\n",
       "      <td>2675</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44965</th>\n",
       "      <td>geographical_origin_of_music</td>\n",
       "      <td>1059</td>\n",
       "      <td>117</td>\n",
       "      <td>0.029273</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44967</th>\n",
       "      <td>student_performance_por</td>\n",
       "      <td>649</td>\n",
       "      <td>31</td>\n",
       "      <td>0.026194</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44966</th>\n",
       "      <td>solar_flare</td>\n",
       "      <td>1066</td>\n",
       "      <td>11</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45012</th>\n",
       "      <td>fifa</td>\n",
       "      <td>19178</td>\n",
       "      <td>29</td>\n",
       "      <td>0.006935</td>\n",
       "      <td>133</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44978</th>\n",
       "      <td>cpu_activity</td>\n",
       "      <td>8192</td>\n",
       "      <td>22</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>56</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44956</th>\n",
       "      <td>abalone</td>\n",
       "      <td>4177</td>\n",
       "      <td>9</td>\n",
       "      <td>0.006703</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44969</th>\n",
       "      <td>naval_propulsion_plant</td>\n",
       "      <td>11934</td>\n",
       "      <td>15</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44972</th>\n",
       "      <td>red_wine</td>\n",
       "      <td>1599</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44993</th>\n",
       "      <td>health_insurance</td>\n",
       "      <td>22272</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>75</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44971</th>\n",
       "      <td>white_wine</td>\n",
       "      <td>4898</td>\n",
       "      <td>12</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     name  n_obs  n_features  %_unique_y  \\\n",
       "dataset_id                                                                 \n",
       "44973                      grid_stability  10000          13    1.000000   \n",
       "44975                         wave_energy  72000          49    0.999903   \n",
       "44980                              kin8nm   8192           9    0.999878   \n",
       "44981                         pumadyn32nh   8192          33    0.999878   \n",
       "45402                            space_ga   3107           7    0.999356   \n",
       "44958                auction_verification   2043           8    0.998042   \n",
       "44994                                cars    804          18    0.992537   \n",
       "44957                  airfoil_self_noise   1503           6    0.968729   \n",
       "44970                  QSAR_fish_toxicity    908           7    0.910793   \n",
       "44959       concrete_compressive_strength   1030           9    0.910680   \n",
       "44960                   energy_efficiency    768           9    0.764323   \n",
       "44990                    brazilian_houses  10692          10    0.537879   \n",
       "44962                        forest_fires    517          13    0.485493   \n",
       "44963              physiochemical_protein  45730          10    0.347759   \n",
       "44987                              socmob   1156           6    0.312284   \n",
       "41021                           Moneyball   1232          15    0.303571   \n",
       "44976                              sarcos  48933          22    0.233258   \n",
       "44979                            diamonds  53940          10    0.215091   \n",
       "44984                          cps88wages  28155           7    0.212040   \n",
       "44989                        kings_county  21613          22    0.186369   \n",
       "44977                  california_housing  20640           9    0.186143   \n",
       "44974                   video_transcoding  68784          19    0.159339   \n",
       "44983                       miami_housing  13932          16    0.151522   \n",
       "44964                   superconductivity  21263          82    0.141419   \n",
       "44992                       fps_benchmark  24624          44    0.108634   \n",
       "44965        geographical_origin_of_music   1059         117    0.029273   \n",
       "44967             student_performance_por    649          31    0.026194   \n",
       "44966                         solar_flare   1066          11    0.007505   \n",
       "45012                                fifa  19178          29    0.006935   \n",
       "44978                        cpu_activity   8192          22    0.006836   \n",
       "44956                             abalone   4177           9    0.006703   \n",
       "44969              naval_propulsion_plant  11934          15    0.004274   \n",
       "44972                            red_wine   1599          12    0.003752   \n",
       "44993                    health_insurance  22272          12    0.003367   \n",
       "44971                          white_wine   4898          12    0.001429   \n",
       "\n",
       "            n_unique_y  has_categorical  \n",
       "dataset_id                               \n",
       "44973            10000            False  \n",
       "44975            71993            False  \n",
       "44980             8191            False  \n",
       "44981             8191            False  \n",
       "45402             3105            False  \n",
       "44958             2039             True  \n",
       "44994              798            False  \n",
       "44957             1456            False  \n",
       "44970              827            False  \n",
       "44959              938            False  \n",
       "44960              587            False  \n",
       "44990             5751             True  \n",
       "44962              251             True  \n",
       "44963            15903            False  \n",
       "44987              361             True  \n",
       "41021              374             True  \n",
       "44976            11414            False  \n",
       "44979            11602             True  \n",
       "44984             5970             True  \n",
       "44989             4028             True  \n",
       "44977             3842            False  \n",
       "44974            10960             True  \n",
       "44983             2111            False  \n",
       "44964             3007            False  \n",
       "44992             2675             True  \n",
       "44965               31            False  \n",
       "44967               17             True  \n",
       "44966                8             True  \n",
       "45012              133             True  \n",
       "44978               56            False  \n",
       "44956               28             True  \n",
       "44969               51            False  \n",
       "44972                6            False  \n",
       "44993               75             True  \n",
       "44971                7            False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the collection with ID 353\n",
    "collection = openml.study.get_suite(353)\n",
    "dataset_ids = collection.data\n",
    "metadata_list = []\n",
    "\n",
    "# Fetch and process each dataset\n",
    "for i, dataset_id in enumerate(dataset_ids):\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        target=dataset.default_target_attribute\n",
    "    )\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)[..., None]\n",
    "    \n",
    "    # Determine if the dataset has categorical features\n",
    "    has_categorical = any(categorical_indicator)\n",
    "    \n",
    "    # Extract the required metadata\n",
    "    metadata = {\n",
    "        'dataset_id': dataset.id,\n",
    "        'name': dataset.name,\n",
    "        'n_obs': int(dataset.qualities['NumberOfInstances']),\n",
    "        'n_features': int(dataset.qualities['NumberOfFeatures']),\n",
    "        '%_unique_y': len(np.unique(y))/len(y),\n",
    "        'n_unique_y': len(np.unique(y)),\n",
    "        'has_categorical': has_categorical\n",
    "    }\n",
    "    \n",
    "    metadata_list.append(metadata)\n",
    "    print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset.id}: {dataset.name}\")\n",
    "\n",
    "# Create a DataFrame from the metadata list\n",
    "df_metadata = pd.DataFrame(metadata_list).sort_values('%_unique_y', ascending=False).set_index(\"dataset_id\")\n",
    "df_metadata.sort_values('%_unique_y', ascending=True)\n",
    "\n",
    "# Display the metadata DataFrame\n",
    "df_metadata.loc[44962, \"has_categorical\"] = True\n",
    "df_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_openml_dataset(dataset_id, \n",
    "                        normalize_X:bool = True,\n",
    "                        normalize_y:bool = True,\n",
    "                        train_test_size:float = 0.7,\n",
    "                        split_seed:int = 0,\n",
    "                        device=\"cpu\",\n",
    "                        ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # Fetch dataset from OpenML by its ID\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    df, _, categorical_indicator, attribute_names = dataset.get_data()\n",
    "    df.dropna(inplace=True)\n",
    "    y = np.array(df.pop(dataset.default_target_attribute))[..., None]\n",
    "    X = np.array(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_test_size, random_state=split_seed)\n",
    "\n",
    "    #normalize\n",
    "    if normalize_X:\n",
    "        X_train, X_test = normalize_mean_std_traindata(X_train, X_test)\n",
    "        X_train = np.clip(X_train, -3, 3)\n",
    "        X_test = np.clip(X_test, -3, 3)\n",
    "    if normalize_y:\n",
    "        y_train, y_test = normalize_mean_std_traindata(y_train, y_test)\n",
    "\n",
    "    return (torch.tensor(X_train.astype(np.float32), requires_grad=False, device=device),\n",
    "            torch.tensor(X_test.astype(np.float32), requires_grad=False, device=device),\n",
    "            torch.tensor(y_train.astype(np.float32), requires_grad=False, device=device),\n",
    "            torch.tensor(y_test.astype(np.float32), requires_grad=False, device=device))\n",
    "\n",
    "#dataset_id = 44971  # Replace with the dataset ID you want\n",
    "dataset_id = 44971 #44970\n",
    "X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id, False, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import matplotlib.pyplot as plt\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# def get_activation(name, activations):\n",
    "#     def hook(model, input, output):\n",
    "#         activations[name] = output.detach()\n",
    "#     return hook\n",
    "\n",
    "\n",
    "# def register_hooks(model, activations):\n",
    "#     for name, layer in model.named_modules():\n",
    "#         print(name)\n",
    "#         if \".dense\" not in name:\n",
    "#             layer.register_forward_hook(get_activation(name, activations))\n",
    "\n",
    "\n",
    "\n",
    "# def neuron_distribution_for_each_layer(X_train, y_train, X_test):\n",
    "#     D = X_train.shape[1]\n",
    "#     n_layers = 2\n",
    "#     g1 = torch.Generator().manual_seed(0)\n",
    "#     model = SampledEulerODE(g1, D, 10*D, n_layers, upsample_module='sampled', sampling_method='gradient')\n",
    "#     #model = SampledResNet(g1, D, 10*D, 10*D, n_layers, upsample_module='sampled', sampling_method='gradient')\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     activations = {}\n",
    "#     register_hooks(model, activations)\n",
    "    \n",
    "#     # Forward pass\n",
    "#     model(X_test)\n",
    "    \n",
    "#     # Plot input data distribution\n",
    "#     fig = make_subplots(rows=1, cols=1)\n",
    "#     fig.add_trace(go.Histogram(x=X_train.flatten().cpu().numpy(), nbinsx=50, name='Train', histnorm='probability density', opacity=0.5))\n",
    "#     fig.add_trace(go.Histogram(x=X_test.flatten().cpu().numpy(), nbinsx=50, name='Test', histnorm='probability density', opacity=0.5))\n",
    "#     fig.update_layout(title_text='Input Data Distribution', xaxis_title='Input Feature Value', yaxis_title='Probability Density', barmode='overlay')\n",
    "#     fig.show()\n",
    "\n",
    "#     # Plot activations\n",
    "#     for name, activation in activations.items():\n",
    "#         fig = make_subplots(rows=1, cols=1)\n",
    "#         fig.add_trace(go.Histogram(x=activation.flatten().cpu().numpy(), nbinsx=50, name='Activation', histnorm='probability density', opacity=0.5))\n",
    "#         fig.update_layout(title_text=f'Activations at Layer: {name}', xaxis_title='Activation Value', yaxis_title='Probability Density', barmode='overlay')\n",
    "#         fig.show()\n",
    "\n",
    "\n",
    "# neuron_distribution_for_each_layer(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit on a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_allmodels_1dataset(\n",
    "        generator: torch.Generator,\n",
    "        X_train: Tensor,\n",
    "        y_train: Tensor,\n",
    "        X_test: Tensor,\n",
    "        y_test: Tensor,\n",
    "        ):\n",
    "    \n",
    "    D = X_train.shape[1]\n",
    "    hidden_size = 128\n",
    "    bottleneck_dim = 2*hidden_size\n",
    "\n",
    "    # (name, model, kwargs). kwargs separate to save memory\n",
    "    model_list = [\n",
    "        [\"RidgeCV\", RidgeCVModule, {}],\n",
    "\n",
    "        [\"T=3 End2End\", E2EResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": bottleneck_dim,\n",
    "                \"out_dim\": 1,\n",
    "                \"n_blocks\": 2,\n",
    "                \"activation\": nn.Tanh(),\n",
    "                \"loss\": nn.MSELoss(),\n",
    "                \"lr\": 1e-3,\n",
    "                \"epochs\": 50,\n",
    "                \"batch_size\": 64,}\n",
    "                ],\n",
    "\n",
    "        [\"T=1 Dense\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                 \"in_dim\": D,\n",
    "                 \"hidden_size\": hidden_size,\n",
    "                 \"bottleneck_dim\": None,\n",
    "                 \"n_blocks\": 0,\n",
    "                 \"upsample_layer\": \"dense\",}\n",
    "                 ],\n",
    "\n",
    "        [\"T=1 SWIM Grad\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": None,\n",
    "                \"n_blocks\": 0,\n",
    "                \"upsample_layer\": \"SWIM\",}\n",
    "                ],\n",
    "        \n",
    "        [\"T=1 SWIM Unif\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": None,\n",
    "                \"n_blocks\": 0,\n",
    "                \"upsample_layer\": \"SWIM\",\n",
    "                \"sampling_method\": \"uniform\",}\n",
    "                ],\n",
    "    ]\n",
    "\n",
    "    for n_blocks in [2, 4]:\n",
    "        model_list += [\n",
    "        [f\"T={n_blocks+1} ResSWIM Grad-dense\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": bottleneck_dim,\n",
    "                \"n_blocks\": n_blocks,\n",
    "                \"upsample_layer\": \"SWIM\",\n",
    "                \"res_layer1\": \"SWIM\",\n",
    "                \"res_layer2\": \"dense\",}\n",
    "                ],\n",
    "\n",
    "        [f\"T={n_blocks+1} ResSWIM Grad-id\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": hidden_size,\n",
    "                \"n_blocks\": n_blocks,\n",
    "                \"upsample_layer\": \"SWIM\",\n",
    "                \"res_layer1\": \"SWIM\",\n",
    "                \"res_layer2\": \"identity\",}\n",
    "                ],\n",
    "                \n",
    "        [f\"T={n_blocks+1} ResDense\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": hidden_size,\n",
    "                \"n_blocks\": n_blocks,\n",
    "                \"upsample_layer\": \"dense\",\n",
    "                \"res_layer1\": \"dense\",\n",
    "                \"res_layer2\": \"identity\",}\n",
    "                ],\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    model_names = []\n",
    "    for name, model, model_args in model_list:\n",
    "        t0 = time.perf_counter()\n",
    "        model = model(**model_args).to(X_train.device)\n",
    "        pred_train, _ = model.fit(X_train, y_train)\n",
    "        t1 = time.perf_counter()\n",
    "        pred_test = model(X_test)\n",
    "        t2 = time.perf_counter()\n",
    "        rmse_train = root_mean_squared_error(y_train.cpu(), pred_train.cpu().detach()) \n",
    "        rmse_test = root_mean_squared_error(y_test.cpu(), pred_test.cpu().detach())\n",
    "\n",
    "        result = np.array( [rmse_train, rmse_test, t1-t0, t2-t1] )\n",
    "        results.append( result )\n",
    "        model_names.append( name )\n",
    "\n",
    "    return model_names, results\n",
    "\n",
    "\n",
    "\n",
    "def run_all_experiments(\n",
    "        dataset_ids: List,\n",
    "        name_save: str = \"PLACEHOLDER\",\n",
    "        device=\"cpu\",\n",
    "        ):\n",
    "    # Fetch and process each dataset\n",
    "    experiments = {}\n",
    "    for i, dataset_id in enumerate(dataset_ids):\n",
    "        X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id, split_seed=0, device=device)\n",
    "        generator = torch.Generator(device=device).manual_seed(999)\n",
    "        results = run_allmodels_1dataset(\n",
    "            generator, X_train, y_train, X_test, y_test, \n",
    "            )\n",
    "        experiments[dataset_id] = results\n",
    "        print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset_id}\")\n",
    "\n",
    "    # Save results\n",
    "    # Assuming experiments is a dict where keys are dataset names and values are tuples (model_names, results)\n",
    "    attributes = [\"RMSE_train\", \"RMSE_test\", \"t_fit\", \"t_feat\"]\n",
    "    data_list = []\n",
    "    # Process the data\n",
    "    for dataset_name, (model_names, results) in experiments.items():\n",
    "        dataset_data = {}\n",
    "        for attr_idx, attribute in enumerate(attributes):\n",
    "            for model_idx, model_name in enumerate(model_names):\n",
    "                dataset_data[(attribute, model_name)] = results[model_idx][attr_idx]\n",
    "        data_list.append(pd.DataFrame(dataset_data, index=[dataset_name]))\n",
    "\n",
    "    # Combine all datasets into a single DataFrame\n",
    "    df = pd.concat(data_list)\n",
    "    df = df.sort_index(axis=1)\n",
    "    print(df)\n",
    "    df.to_pickle(f\"OpenML_reg_{name_save}.pkl\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:23<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/20 Processed dataset 44973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:51<00:00,  7.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/20 Processed dataset 44975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:17<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/20 Processed dataset 44980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:17<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/20 Processed dataset 44981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:06<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/20 Processed dataset 45402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 25.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/20 Processed dataset 44994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/20 Processed dataset 44957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 24.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/20 Processed dataset 44970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 20.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/20 Processed dataset 44959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 26.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10/20 Processed dataset 44960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:37<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/20 Processed dataset 44963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:44<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12/20 Processed dataset 44976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:44<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13/20 Processed dataset 44977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:29<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14/20 Processed dataset 44983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:46<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15/20 Processed dataset 44964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 19.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16/20 Processed dataset 44965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:17<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17/20 Processed dataset 44978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18/20 Processed dataset 44969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19/20 Processed dataset 44972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:10<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20/20 Processed dataset 44971\n",
      "      RMSE_test                                                    \\\n",
      "        RidgeCV T=1 Dense T=1 SWIM Grad T=1 SWIM Unif T=3 End2End   \n",
      "44973  0.595158  0.487190      0.484540      0.515265    0.267764   \n",
      "44975  0.006491  0.216284      0.014534      0.016062    0.035913   \n",
      "44980  0.771311  0.626406      0.603183      0.579103    0.332173   \n",
      "44981  0.904478  0.906060      0.904416      0.904333    0.764078   \n",
      "45402  0.706690  0.594246      0.681441      0.733225    0.618801   \n",
      "44994  0.296725  0.232125      0.256265      0.259723    0.294330   \n",
      "44957  0.674484  0.423936      0.469324      0.523909    0.424904   \n",
      "44970  0.666021  0.614415      0.620453      0.635694    0.683948   \n",
      "44959  0.542088  0.423389      0.364107      0.446359    0.381762   \n",
      "44960  0.304327  0.201810      0.275287      0.266248    0.254899   \n",
      "44963  0.839762  0.773993      0.789532      0.790094    0.604565   \n",
      "44976  0.294862  0.284154      0.233588      0.245341    0.142780   \n",
      "44977  0.587720  0.516793      0.534415      0.539150    0.480224   \n",
      "44983  0.586507  0.441029      0.389925      0.407275    0.354591   \n",
      "44964  0.517322  0.495828      0.486101      0.491231    0.345597   \n",
      "44965  0.914663  0.914064      0.910656      0.924252    0.921391   \n",
      "44978  0.323560  0.284968      0.211208      0.191627    0.158181   \n",
      "44969  0.413739  0.050529      0.126296      0.349671    0.133620   \n",
      "44972  0.766536  0.761113      0.767613      0.780693    0.864814   \n",
      "44971  0.878211  0.835470      0.834845      0.838370    0.853791   \n",
      "\n",
      "                                                                            \\\n",
      "      T=3 ResDense T=3 ResSWIM Grad-dense T=3 ResSWIM Grad-id T=5 ResDense   \n",
      "44973     0.462851               0.476432            0.501349     0.507460   \n",
      "44975     0.267795               0.031480            0.029316     0.398372   \n",
      "44980     0.615005               0.575760            0.547171     0.633022   \n",
      "44981     0.909947               0.904919            0.904100     0.910580   \n",
      "45402     0.641916               0.651372            0.748465     0.579334   \n",
      "44994     0.255599               0.247598            0.237971     0.265426   \n",
      "44957     0.429798               0.343744            0.354992     0.448010   \n",
      "44970     0.613921               0.626454            0.625207     0.622942   \n",
      "44959     0.436573               0.355477            0.358918     0.429209   \n",
      "44960     0.239604               0.167304            0.219069     0.223315   \n",
      "44963     0.783170               0.790074            0.785923     0.779814   \n",
      "44976     0.300719               0.253073            0.253712     0.329131   \n",
      "44977     0.530283               0.532421            0.529373     0.514005   \n",
      "44983     0.451503               0.381475            0.388478     0.474671   \n",
      "44964     0.498161               0.465897            0.468154     0.506828   \n",
      "44965     0.916860               0.896677            0.905649     0.918414   \n",
      "44978     0.292272               0.174839            0.178823     0.278780   \n",
      "44969     0.033090               0.130476            0.127957     0.029743   \n",
      "44972     0.765488               0.768979            0.774997     0.769672   \n",
      "44971     0.833280               0.834555            0.830837     0.837249   \n",
      "\n",
      "                              ...     t_fit                              \\\n",
      "      T=5 ResSWIM Grad-dense  ... T=1 Dense T=1 SWIM Grad T=1 SWIM Unif   \n",
      "44973               0.484716  ...  0.181305      0.294013      0.255261   \n",
      "44975               0.059381  ...  1.858905      1.613717      1.590133   \n",
      "44980               0.540944  ...  0.075352      0.183124      0.145012   \n",
      "44981               0.904503  ...  0.128444      0.170660      0.186523   \n",
      "45402               0.717807  ...  0.038897      0.088248      0.057958   \n",
      "44994               0.242917  ...  0.019839      0.041580      0.036466   \n",
      "44957               0.362259  ...  0.034389      0.106709      0.143593   \n",
      "44970               0.631894  ...  0.044006      0.078031      0.130627   \n",
      "44959               0.375161  ...  0.043546      0.068022      0.099432   \n",
      "44960               0.197696  ...  0.035328      0.095180      0.086452   \n",
      "44963               0.784235  ...  0.880499      0.905746      0.846305   \n",
      "44976               0.265410  ...  0.979099      1.003486      0.997437   \n",
      "44977               0.540965  ...  0.346783      0.357059      0.370600   \n",
      "44983               0.387581  ...  0.184538      0.229745      0.232644   \n",
      "44964               0.475043  ...  0.329750      0.377716      0.407980   \n",
      "44965               0.912388  ...  0.014172      0.109990      0.124500   \n",
      "44978               0.174055  ...  0.081702      0.146765      0.152880   \n",
      "44969               0.175395  ...  0.163849      0.235477      0.187641   \n",
      "44972               0.777686  ...  0.028193      0.052786      0.053960   \n",
      "44971               0.840444  ...  0.082106      0.085614      0.165476   \n",
      "\n",
      "                                                                           \\\n",
      "      T=3 End2End T=3 ResDense T=3 ResSWIM Grad-dense T=3 ResSWIM Grad-id   \n",
      "44973   24.392364     0.177129               0.303514            0.224949   \n",
      "44975  356.992386     1.603182               1.984443            1.848183   \n",
      "44980   17.700974     0.175246               0.172382            0.265026   \n",
      "44981   17.919285     0.222856               0.233243            0.234229   \n",
      "45402    6.964257     0.082471               0.140973            0.181281   \n",
      "44994    1.939736     0.052477               0.135522            0.093249   \n",
      "44957    3.481455     0.099679               0.113773            0.128989   \n",
      "44970    2.043959     0.100299               0.065376            0.063853   \n",
      "44959    2.469734     0.116321               0.131063            0.121981   \n",
      "44960    1.891372     0.078895               0.139757            0.113925   \n",
      "44963   97.944627     0.951424               1.154188            1.062207   \n",
      "44976  104.681020     1.030184               1.273045            1.224793   \n",
      "44977   44.229377     0.344253               0.466553            0.449456   \n",
      "44983   29.950977     0.257408               0.353615            0.273624   \n",
      "44964   46.130064     0.435280               0.500047            0.514084   \n",
      "44965    2.521701     0.046627               0.144261            0.094935   \n",
      "44978   17.855008     0.171994               0.226676            0.187504   \n",
      "44969   25.779036     0.214497               0.230594            0.229097   \n",
      "44972    3.665596     0.065992               0.134572            0.070702   \n",
      "44971   10.952801     0.098106               0.168406            0.148602   \n",
      "\n",
      "                                                               \n",
      "      T=5 ResDense T=5 ResSWIM Grad-dense T=5 ResSWIM Grad-id  \n",
      "44973     0.192235               0.340333            0.297860  \n",
      "44975     1.654306               2.337145            2.173944  \n",
      "44980     0.189547               0.250708            0.182656  \n",
      "44981     0.193021               0.226908            0.206999  \n",
      "45402     0.081883               0.167284            0.161679  \n",
      "44994     0.054872               0.070515            0.093620  \n",
      "44957     0.118105               0.137354            0.132180  \n",
      "44970     0.045134               0.130529            0.075617  \n",
      "44959     0.122685               0.163284            0.078237  \n",
      "44960     0.146919               0.117862            0.102822  \n",
      "44963     0.963192               1.404269            1.302495  \n",
      "44976     1.022921               1.504022            1.455326  \n",
      "44977     0.431670               0.566045            0.569267  \n",
      "44983     0.261781               0.394503            0.295672  \n",
      "44964     0.425239               0.629915            0.539160  \n",
      "44965     0.161098               0.130873            0.063790  \n",
      "44978     0.127873               0.262874            0.252036  \n",
      "44969     0.215244               0.284928            0.313638  \n",
      "44972     0.120035               0.132372            0.133070  \n",
      "44971     0.158976               0.204861            0.191928  \n",
      "\n",
      "[20 rows x 44 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">RMSE_test</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">t_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>RidgeCV</th>\n",
       "      <th>T=1 Dense</th>\n",
       "      <th>T=1 SWIM Grad</th>\n",
       "      <th>T=1 SWIM Unif</th>\n",
       "      <th>T=3 End2End</th>\n",
       "      <th>T=3 ResDense</th>\n",
       "      <th>T=3 ResSWIM Grad-dense</th>\n",
       "      <th>T=3 ResSWIM Grad-id</th>\n",
       "      <th>T=5 ResDense</th>\n",
       "      <th>T=5 ResSWIM Grad-dense</th>\n",
       "      <th>...</th>\n",
       "      <th>T=1 Dense</th>\n",
       "      <th>T=1 SWIM Grad</th>\n",
       "      <th>T=1 SWIM Unif</th>\n",
       "      <th>T=3 End2End</th>\n",
       "      <th>T=3 ResDense</th>\n",
       "      <th>T=3 ResSWIM Grad-dense</th>\n",
       "      <th>T=3 ResSWIM Grad-id</th>\n",
       "      <th>T=5 ResDense</th>\n",
       "      <th>T=5 ResSWIM Grad-dense</th>\n",
       "      <th>T=5 ResSWIM Grad-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44973</th>\n",
       "      <td>0.595158</td>\n",
       "      <td>0.487190</td>\n",
       "      <td>0.484540</td>\n",
       "      <td>0.515265</td>\n",
       "      <td>0.267764</td>\n",
       "      <td>0.462851</td>\n",
       "      <td>0.476432</td>\n",
       "      <td>0.501349</td>\n",
       "      <td>0.507460</td>\n",
       "      <td>0.484716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181305</td>\n",
       "      <td>0.294013</td>\n",
       "      <td>0.255261</td>\n",
       "      <td>24.392364</td>\n",
       "      <td>0.177129</td>\n",
       "      <td>0.303514</td>\n",
       "      <td>0.224949</td>\n",
       "      <td>0.192235</td>\n",
       "      <td>0.340333</td>\n",
       "      <td>0.297860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44975</th>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.216284</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.016062</td>\n",
       "      <td>0.035913</td>\n",
       "      <td>0.267795</td>\n",
       "      <td>0.031480</td>\n",
       "      <td>0.029316</td>\n",
       "      <td>0.398372</td>\n",
       "      <td>0.059381</td>\n",
       "      <td>...</td>\n",
       "      <td>1.858905</td>\n",
       "      <td>1.613717</td>\n",
       "      <td>1.590133</td>\n",
       "      <td>356.992386</td>\n",
       "      <td>1.603182</td>\n",
       "      <td>1.984443</td>\n",
       "      <td>1.848183</td>\n",
       "      <td>1.654306</td>\n",
       "      <td>2.337145</td>\n",
       "      <td>2.173944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44980</th>\n",
       "      <td>0.771311</td>\n",
       "      <td>0.626406</td>\n",
       "      <td>0.603183</td>\n",
       "      <td>0.579103</td>\n",
       "      <td>0.332173</td>\n",
       "      <td>0.615005</td>\n",
       "      <td>0.575760</td>\n",
       "      <td>0.547171</td>\n",
       "      <td>0.633022</td>\n",
       "      <td>0.540944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075352</td>\n",
       "      <td>0.183124</td>\n",
       "      <td>0.145012</td>\n",
       "      <td>17.700974</td>\n",
       "      <td>0.175246</td>\n",
       "      <td>0.172382</td>\n",
       "      <td>0.265026</td>\n",
       "      <td>0.189547</td>\n",
       "      <td>0.250708</td>\n",
       "      <td>0.182656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44981</th>\n",
       "      <td>0.904478</td>\n",
       "      <td>0.906060</td>\n",
       "      <td>0.904416</td>\n",
       "      <td>0.904333</td>\n",
       "      <td>0.764078</td>\n",
       "      <td>0.909947</td>\n",
       "      <td>0.904919</td>\n",
       "      <td>0.904100</td>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.904503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128444</td>\n",
       "      <td>0.170660</td>\n",
       "      <td>0.186523</td>\n",
       "      <td>17.919285</td>\n",
       "      <td>0.222856</td>\n",
       "      <td>0.233243</td>\n",
       "      <td>0.234229</td>\n",
       "      <td>0.193021</td>\n",
       "      <td>0.226908</td>\n",
       "      <td>0.206999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45402</th>\n",
       "      <td>0.706690</td>\n",
       "      <td>0.594246</td>\n",
       "      <td>0.681441</td>\n",
       "      <td>0.733225</td>\n",
       "      <td>0.618801</td>\n",
       "      <td>0.641916</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>0.748465</td>\n",
       "      <td>0.579334</td>\n",
       "      <td>0.717807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038897</td>\n",
       "      <td>0.088248</td>\n",
       "      <td>0.057958</td>\n",
       "      <td>6.964257</td>\n",
       "      <td>0.082471</td>\n",
       "      <td>0.140973</td>\n",
       "      <td>0.181281</td>\n",
       "      <td>0.081883</td>\n",
       "      <td>0.167284</td>\n",
       "      <td>0.161679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44994</th>\n",
       "      <td>0.296725</td>\n",
       "      <td>0.232125</td>\n",
       "      <td>0.256265</td>\n",
       "      <td>0.259723</td>\n",
       "      <td>0.294330</td>\n",
       "      <td>0.255599</td>\n",
       "      <td>0.247598</td>\n",
       "      <td>0.237971</td>\n",
       "      <td>0.265426</td>\n",
       "      <td>0.242917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019839</td>\n",
       "      <td>0.041580</td>\n",
       "      <td>0.036466</td>\n",
       "      <td>1.939736</td>\n",
       "      <td>0.052477</td>\n",
       "      <td>0.135522</td>\n",
       "      <td>0.093249</td>\n",
       "      <td>0.054872</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.093620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44957</th>\n",
       "      <td>0.674484</td>\n",
       "      <td>0.423936</td>\n",
       "      <td>0.469324</td>\n",
       "      <td>0.523909</td>\n",
       "      <td>0.424904</td>\n",
       "      <td>0.429798</td>\n",
       "      <td>0.343744</td>\n",
       "      <td>0.354992</td>\n",
       "      <td>0.448010</td>\n",
       "      <td>0.362259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034389</td>\n",
       "      <td>0.106709</td>\n",
       "      <td>0.143593</td>\n",
       "      <td>3.481455</td>\n",
       "      <td>0.099679</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.128989</td>\n",
       "      <td>0.118105</td>\n",
       "      <td>0.137354</td>\n",
       "      <td>0.132180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44970</th>\n",
       "      <td>0.666021</td>\n",
       "      <td>0.614415</td>\n",
       "      <td>0.620453</td>\n",
       "      <td>0.635694</td>\n",
       "      <td>0.683948</td>\n",
       "      <td>0.613921</td>\n",
       "      <td>0.626454</td>\n",
       "      <td>0.625207</td>\n",
       "      <td>0.622942</td>\n",
       "      <td>0.631894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044006</td>\n",
       "      <td>0.078031</td>\n",
       "      <td>0.130627</td>\n",
       "      <td>2.043959</td>\n",
       "      <td>0.100299</td>\n",
       "      <td>0.065376</td>\n",
       "      <td>0.063853</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>0.130529</td>\n",
       "      <td>0.075617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44959</th>\n",
       "      <td>0.542088</td>\n",
       "      <td>0.423389</td>\n",
       "      <td>0.364107</td>\n",
       "      <td>0.446359</td>\n",
       "      <td>0.381762</td>\n",
       "      <td>0.436573</td>\n",
       "      <td>0.355477</td>\n",
       "      <td>0.358918</td>\n",
       "      <td>0.429209</td>\n",
       "      <td>0.375161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043546</td>\n",
       "      <td>0.068022</td>\n",
       "      <td>0.099432</td>\n",
       "      <td>2.469734</td>\n",
       "      <td>0.116321</td>\n",
       "      <td>0.131063</td>\n",
       "      <td>0.121981</td>\n",
       "      <td>0.122685</td>\n",
       "      <td>0.163284</td>\n",
       "      <td>0.078237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44960</th>\n",
       "      <td>0.304327</td>\n",
       "      <td>0.201810</td>\n",
       "      <td>0.275287</td>\n",
       "      <td>0.266248</td>\n",
       "      <td>0.254899</td>\n",
       "      <td>0.239604</td>\n",
       "      <td>0.167304</td>\n",
       "      <td>0.219069</td>\n",
       "      <td>0.223315</td>\n",
       "      <td>0.197696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035328</td>\n",
       "      <td>0.095180</td>\n",
       "      <td>0.086452</td>\n",
       "      <td>1.891372</td>\n",
       "      <td>0.078895</td>\n",
       "      <td>0.139757</td>\n",
       "      <td>0.113925</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.117862</td>\n",
       "      <td>0.102822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44963</th>\n",
       "      <td>0.839762</td>\n",
       "      <td>0.773993</td>\n",
       "      <td>0.789532</td>\n",
       "      <td>0.790094</td>\n",
       "      <td>0.604565</td>\n",
       "      <td>0.783170</td>\n",
       "      <td>0.790074</td>\n",
       "      <td>0.785923</td>\n",
       "      <td>0.779814</td>\n",
       "      <td>0.784235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880499</td>\n",
       "      <td>0.905746</td>\n",
       "      <td>0.846305</td>\n",
       "      <td>97.944627</td>\n",
       "      <td>0.951424</td>\n",
       "      <td>1.154188</td>\n",
       "      <td>1.062207</td>\n",
       "      <td>0.963192</td>\n",
       "      <td>1.404269</td>\n",
       "      <td>1.302495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44976</th>\n",
       "      <td>0.294862</td>\n",
       "      <td>0.284154</td>\n",
       "      <td>0.233588</td>\n",
       "      <td>0.245341</td>\n",
       "      <td>0.142780</td>\n",
       "      <td>0.300719</td>\n",
       "      <td>0.253073</td>\n",
       "      <td>0.253712</td>\n",
       "      <td>0.329131</td>\n",
       "      <td>0.265410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>1.003486</td>\n",
       "      <td>0.997437</td>\n",
       "      <td>104.681020</td>\n",
       "      <td>1.030184</td>\n",
       "      <td>1.273045</td>\n",
       "      <td>1.224793</td>\n",
       "      <td>1.022921</td>\n",
       "      <td>1.504022</td>\n",
       "      <td>1.455326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44977</th>\n",
       "      <td>0.587720</td>\n",
       "      <td>0.516793</td>\n",
       "      <td>0.534415</td>\n",
       "      <td>0.539150</td>\n",
       "      <td>0.480224</td>\n",
       "      <td>0.530283</td>\n",
       "      <td>0.532421</td>\n",
       "      <td>0.529373</td>\n",
       "      <td>0.514005</td>\n",
       "      <td>0.540965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346783</td>\n",
       "      <td>0.357059</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>44.229377</td>\n",
       "      <td>0.344253</td>\n",
       "      <td>0.466553</td>\n",
       "      <td>0.449456</td>\n",
       "      <td>0.431670</td>\n",
       "      <td>0.566045</td>\n",
       "      <td>0.569267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44983</th>\n",
       "      <td>0.586507</td>\n",
       "      <td>0.441029</td>\n",
       "      <td>0.389925</td>\n",
       "      <td>0.407275</td>\n",
       "      <td>0.354591</td>\n",
       "      <td>0.451503</td>\n",
       "      <td>0.381475</td>\n",
       "      <td>0.388478</td>\n",
       "      <td>0.474671</td>\n",
       "      <td>0.387581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184538</td>\n",
       "      <td>0.229745</td>\n",
       "      <td>0.232644</td>\n",
       "      <td>29.950977</td>\n",
       "      <td>0.257408</td>\n",
       "      <td>0.353615</td>\n",
       "      <td>0.273624</td>\n",
       "      <td>0.261781</td>\n",
       "      <td>0.394503</td>\n",
       "      <td>0.295672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44964</th>\n",
       "      <td>0.517322</td>\n",
       "      <td>0.495828</td>\n",
       "      <td>0.486101</td>\n",
       "      <td>0.491231</td>\n",
       "      <td>0.345597</td>\n",
       "      <td>0.498161</td>\n",
       "      <td>0.465897</td>\n",
       "      <td>0.468154</td>\n",
       "      <td>0.506828</td>\n",
       "      <td>0.475043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329750</td>\n",
       "      <td>0.377716</td>\n",
       "      <td>0.407980</td>\n",
       "      <td>46.130064</td>\n",
       "      <td>0.435280</td>\n",
       "      <td>0.500047</td>\n",
       "      <td>0.514084</td>\n",
       "      <td>0.425239</td>\n",
       "      <td>0.629915</td>\n",
       "      <td>0.539160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44965</th>\n",
       "      <td>0.914663</td>\n",
       "      <td>0.914064</td>\n",
       "      <td>0.910656</td>\n",
       "      <td>0.924252</td>\n",
       "      <td>0.921391</td>\n",
       "      <td>0.916860</td>\n",
       "      <td>0.896677</td>\n",
       "      <td>0.905649</td>\n",
       "      <td>0.918414</td>\n",
       "      <td>0.912388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>0.109990</td>\n",
       "      <td>0.124500</td>\n",
       "      <td>2.521701</td>\n",
       "      <td>0.046627</td>\n",
       "      <td>0.144261</td>\n",
       "      <td>0.094935</td>\n",
       "      <td>0.161098</td>\n",
       "      <td>0.130873</td>\n",
       "      <td>0.063790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44978</th>\n",
       "      <td>0.323560</td>\n",
       "      <td>0.284968</td>\n",
       "      <td>0.211208</td>\n",
       "      <td>0.191627</td>\n",
       "      <td>0.158181</td>\n",
       "      <td>0.292272</td>\n",
       "      <td>0.174839</td>\n",
       "      <td>0.178823</td>\n",
       "      <td>0.278780</td>\n",
       "      <td>0.174055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081702</td>\n",
       "      <td>0.146765</td>\n",
       "      <td>0.152880</td>\n",
       "      <td>17.855008</td>\n",
       "      <td>0.171994</td>\n",
       "      <td>0.226676</td>\n",
       "      <td>0.187504</td>\n",
       "      <td>0.127873</td>\n",
       "      <td>0.262874</td>\n",
       "      <td>0.252036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44969</th>\n",
       "      <td>0.413739</td>\n",
       "      <td>0.050529</td>\n",
       "      <td>0.126296</td>\n",
       "      <td>0.349671</td>\n",
       "      <td>0.133620</td>\n",
       "      <td>0.033090</td>\n",
       "      <td>0.130476</td>\n",
       "      <td>0.127957</td>\n",
       "      <td>0.029743</td>\n",
       "      <td>0.175395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163849</td>\n",
       "      <td>0.235477</td>\n",
       "      <td>0.187641</td>\n",
       "      <td>25.779036</td>\n",
       "      <td>0.214497</td>\n",
       "      <td>0.230594</td>\n",
       "      <td>0.229097</td>\n",
       "      <td>0.215244</td>\n",
       "      <td>0.284928</td>\n",
       "      <td>0.313638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44972</th>\n",
       "      <td>0.766536</td>\n",
       "      <td>0.761113</td>\n",
       "      <td>0.767613</td>\n",
       "      <td>0.780693</td>\n",
       "      <td>0.864814</td>\n",
       "      <td>0.765488</td>\n",
       "      <td>0.768979</td>\n",
       "      <td>0.774997</td>\n",
       "      <td>0.769672</td>\n",
       "      <td>0.777686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028193</td>\n",
       "      <td>0.052786</td>\n",
       "      <td>0.053960</td>\n",
       "      <td>3.665596</td>\n",
       "      <td>0.065992</td>\n",
       "      <td>0.134572</td>\n",
       "      <td>0.070702</td>\n",
       "      <td>0.120035</td>\n",
       "      <td>0.132372</td>\n",
       "      <td>0.133070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44971</th>\n",
       "      <td>0.878211</td>\n",
       "      <td>0.835470</td>\n",
       "      <td>0.834845</td>\n",
       "      <td>0.838370</td>\n",
       "      <td>0.853791</td>\n",
       "      <td>0.833280</td>\n",
       "      <td>0.834555</td>\n",
       "      <td>0.830837</td>\n",
       "      <td>0.837249</td>\n",
       "      <td>0.840444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082106</td>\n",
       "      <td>0.085614</td>\n",
       "      <td>0.165476</td>\n",
       "      <td>10.952801</td>\n",
       "      <td>0.098106</td>\n",
       "      <td>0.168406</td>\n",
       "      <td>0.148602</td>\n",
       "      <td>0.158976</td>\n",
       "      <td>0.204861</td>\n",
       "      <td>0.191928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RMSE_test                                                    \\\n",
       "        RidgeCV T=1 Dense T=1 SWIM Grad T=1 SWIM Unif T=3 End2End   \n",
       "44973  0.595158  0.487190      0.484540      0.515265    0.267764   \n",
       "44975  0.006491  0.216284      0.014534      0.016062    0.035913   \n",
       "44980  0.771311  0.626406      0.603183      0.579103    0.332173   \n",
       "44981  0.904478  0.906060      0.904416      0.904333    0.764078   \n",
       "45402  0.706690  0.594246      0.681441      0.733225    0.618801   \n",
       "44994  0.296725  0.232125      0.256265      0.259723    0.294330   \n",
       "44957  0.674484  0.423936      0.469324      0.523909    0.424904   \n",
       "44970  0.666021  0.614415      0.620453      0.635694    0.683948   \n",
       "44959  0.542088  0.423389      0.364107      0.446359    0.381762   \n",
       "44960  0.304327  0.201810      0.275287      0.266248    0.254899   \n",
       "44963  0.839762  0.773993      0.789532      0.790094    0.604565   \n",
       "44976  0.294862  0.284154      0.233588      0.245341    0.142780   \n",
       "44977  0.587720  0.516793      0.534415      0.539150    0.480224   \n",
       "44983  0.586507  0.441029      0.389925      0.407275    0.354591   \n",
       "44964  0.517322  0.495828      0.486101      0.491231    0.345597   \n",
       "44965  0.914663  0.914064      0.910656      0.924252    0.921391   \n",
       "44978  0.323560  0.284968      0.211208      0.191627    0.158181   \n",
       "44969  0.413739  0.050529      0.126296      0.349671    0.133620   \n",
       "44972  0.766536  0.761113      0.767613      0.780693    0.864814   \n",
       "44971  0.878211  0.835470      0.834845      0.838370    0.853791   \n",
       "\n",
       "                                                                            \\\n",
       "      T=3 ResDense T=3 ResSWIM Grad-dense T=3 ResSWIM Grad-id T=5 ResDense   \n",
       "44973     0.462851               0.476432            0.501349     0.507460   \n",
       "44975     0.267795               0.031480            0.029316     0.398372   \n",
       "44980     0.615005               0.575760            0.547171     0.633022   \n",
       "44981     0.909947               0.904919            0.904100     0.910580   \n",
       "45402     0.641916               0.651372            0.748465     0.579334   \n",
       "44994     0.255599               0.247598            0.237971     0.265426   \n",
       "44957     0.429798               0.343744            0.354992     0.448010   \n",
       "44970     0.613921               0.626454            0.625207     0.622942   \n",
       "44959     0.436573               0.355477            0.358918     0.429209   \n",
       "44960     0.239604               0.167304            0.219069     0.223315   \n",
       "44963     0.783170               0.790074            0.785923     0.779814   \n",
       "44976     0.300719               0.253073            0.253712     0.329131   \n",
       "44977     0.530283               0.532421            0.529373     0.514005   \n",
       "44983     0.451503               0.381475            0.388478     0.474671   \n",
       "44964     0.498161               0.465897            0.468154     0.506828   \n",
       "44965     0.916860               0.896677            0.905649     0.918414   \n",
       "44978     0.292272               0.174839            0.178823     0.278780   \n",
       "44969     0.033090               0.130476            0.127957     0.029743   \n",
       "44972     0.765488               0.768979            0.774997     0.769672   \n",
       "44971     0.833280               0.834555            0.830837     0.837249   \n",
       "\n",
       "                              ...     t_fit                              \\\n",
       "      T=5 ResSWIM Grad-dense  ... T=1 Dense T=1 SWIM Grad T=1 SWIM Unif   \n",
       "44973               0.484716  ...  0.181305      0.294013      0.255261   \n",
       "44975               0.059381  ...  1.858905      1.613717      1.590133   \n",
       "44980               0.540944  ...  0.075352      0.183124      0.145012   \n",
       "44981               0.904503  ...  0.128444      0.170660      0.186523   \n",
       "45402               0.717807  ...  0.038897      0.088248      0.057958   \n",
       "44994               0.242917  ...  0.019839      0.041580      0.036466   \n",
       "44957               0.362259  ...  0.034389      0.106709      0.143593   \n",
       "44970               0.631894  ...  0.044006      0.078031      0.130627   \n",
       "44959               0.375161  ...  0.043546      0.068022      0.099432   \n",
       "44960               0.197696  ...  0.035328      0.095180      0.086452   \n",
       "44963               0.784235  ...  0.880499      0.905746      0.846305   \n",
       "44976               0.265410  ...  0.979099      1.003486      0.997437   \n",
       "44977               0.540965  ...  0.346783      0.357059      0.370600   \n",
       "44983               0.387581  ...  0.184538      0.229745      0.232644   \n",
       "44964               0.475043  ...  0.329750      0.377716      0.407980   \n",
       "44965               0.912388  ...  0.014172      0.109990      0.124500   \n",
       "44978               0.174055  ...  0.081702      0.146765      0.152880   \n",
       "44969               0.175395  ...  0.163849      0.235477      0.187641   \n",
       "44972               0.777686  ...  0.028193      0.052786      0.053960   \n",
       "44971               0.840444  ...  0.082106      0.085614      0.165476   \n",
       "\n",
       "                                                                           \\\n",
       "      T=3 End2End T=3 ResDense T=3 ResSWIM Grad-dense T=3 ResSWIM Grad-id   \n",
       "44973   24.392364     0.177129               0.303514            0.224949   \n",
       "44975  356.992386     1.603182               1.984443            1.848183   \n",
       "44980   17.700974     0.175246               0.172382            0.265026   \n",
       "44981   17.919285     0.222856               0.233243            0.234229   \n",
       "45402    6.964257     0.082471               0.140973            0.181281   \n",
       "44994    1.939736     0.052477               0.135522            0.093249   \n",
       "44957    3.481455     0.099679               0.113773            0.128989   \n",
       "44970    2.043959     0.100299               0.065376            0.063853   \n",
       "44959    2.469734     0.116321               0.131063            0.121981   \n",
       "44960    1.891372     0.078895               0.139757            0.113925   \n",
       "44963   97.944627     0.951424               1.154188            1.062207   \n",
       "44976  104.681020     1.030184               1.273045            1.224793   \n",
       "44977   44.229377     0.344253               0.466553            0.449456   \n",
       "44983   29.950977     0.257408               0.353615            0.273624   \n",
       "44964   46.130064     0.435280               0.500047            0.514084   \n",
       "44965    2.521701     0.046627               0.144261            0.094935   \n",
       "44978   17.855008     0.171994               0.226676            0.187504   \n",
       "44969   25.779036     0.214497               0.230594            0.229097   \n",
       "44972    3.665596     0.065992               0.134572            0.070702   \n",
       "44971   10.952801     0.098106               0.168406            0.148602   \n",
       "\n",
       "                                                               \n",
       "      T=5 ResDense T=5 ResSWIM Grad-dense T=5 ResSWIM Grad-id  \n",
       "44973     0.192235               0.340333            0.297860  \n",
       "44975     1.654306               2.337145            2.173944  \n",
       "44980     0.189547               0.250708            0.182656  \n",
       "44981     0.193021               0.226908            0.206999  \n",
       "45402     0.081883               0.167284            0.161679  \n",
       "44994     0.054872               0.070515            0.093620  \n",
       "44957     0.118105               0.137354            0.132180  \n",
       "44970     0.045134               0.130529            0.075617  \n",
       "44959     0.122685               0.163284            0.078237  \n",
       "44960     0.146919               0.117862            0.102822  \n",
       "44963     0.963192               1.404269            1.302495  \n",
       "44976     1.022921               1.504022            1.455326  \n",
       "44977     0.431670               0.566045            0.569267  \n",
       "44983     0.261781               0.394503            0.295672  \n",
       "44964     0.425239               0.629915            0.539160  \n",
       "44965     0.161098               0.130873            0.063790  \n",
       "44978     0.127873               0.262874            0.252036  \n",
       "44969     0.215244               0.284928            0.313638  \n",
       "44972     0.120035               0.132372            0.133070  \n",
       "44971     0.158976               0.204861            0.191928  \n",
       "\n",
       "[20 rows x 44 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ids_not_categorical = list(df_metadata.query(\"has_categorical == False\").index.values)\n",
    "dataset_ids_not_categorical = [int(x) for x in dataset_ids_not_categorical]\n",
    "run_all_experiments(dataset_ids_not_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T=3 End2End               0.445906\n",
       "T=3 ResSWIM Grad-dense    0.480450\n",
       "T=5 ResSWIM Grad-id       0.485050\n",
       "T=3 ResSWIM Grad-id       0.488523\n",
       "T=5 ResSWIM Grad-dense    0.492524\n",
       "T=1 SWIM Grad             0.497886\n",
       "T=1 Dense                 0.504190\n",
       "T=3 ResDense              0.513892\n",
       "T=1 SWIM Unif             0.521881\n",
       "T=5 ResDense              0.522799\n",
       "RidgeCV                   0.579533\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg = pd.read_pickle(\"OpenML_reg_PLACEHOLDER.pkl\")\n",
    "df_reg[\"RMSE_test\"].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T=3 ResSWIM Grad-dense    4.25\n",
       "T=5 ResSWIM Grad-id       4.55\n",
       "T=3 ResSWIM Grad-id       4.70\n",
       "T=3 End2End               4.85\n",
       "T=1 Dense                 5.40\n",
       "T=1 SWIM Grad             5.50\n",
       "T=5 ResSWIM Grad-dense    5.90\n",
       "T=3 ResDense              6.40\n",
       "T=5 ResDense              7.20\n",
       "T=1 SWIM Unif             7.95\n",
       "RidgeCV                   9.30\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg[\"RMSE_test\"].rank(axis=1).mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T=3 End2End               0.288300\n",
       "T=3 ResSWIM Grad-dense    0.452473\n",
       "T=5 ResSWIM Grad-id       0.455653\n",
       "T=3 ResSWIM Grad-id       0.459548\n",
       "T=5 ResSWIM Grad-dense    0.459733\n",
       "T=1 Dense                 0.475713\n",
       "T=3 ResDense              0.475718\n",
       "T=1 SWIM Grad             0.476500\n",
       "T=5 ResDense              0.490480\n",
       "T=1 SWIM Unif             0.495691\n",
       "RidgeCV                   0.569632\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg[\"RMSE_train\"].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T=3 End2End                2.25\n",
       "T=3 ResSWIM Grad-dense     4.75\n",
       "T=3 ResDense               5.30\n",
       "T=5 ResSWIM Grad-id        5.40\n",
       "T=3 ResSWIM Grad-id        5.45\n",
       "T=5 ResSWIM Grad-dense     5.50\n",
       "T=1 Dense                  6.00\n",
       "T=5 ResDense               6.55\n",
       "T=1 SWIM Grad              6.65\n",
       "T=1 SWIM Unif              7.95\n",
       "RidgeCV                   10.20\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg[\"RMSE_train\"].rank(axis=1).mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT: implement boosting for the RandFeat models\n",
    "# ALSO: I should also do boosting for learned Nets ...\n",
    "\n",
    "\n",
    "\n",
    "#TODO NOTE NOTE next: add end2end and randfeatboost to regression models\n",
    "#          i might also need to implement the gradient approach before this?  maybe not.  at least do line search probabily"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
