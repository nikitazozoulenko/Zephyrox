{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, tensor\n",
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "#from aeon.regression.sklearn import RotationForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from preprocessing.stream_transforms import normalize_mean_std_traindata, normalize_streams, augment_time, add_basepoint_zero\n",
    "from utils.utils import print_name, print_shape\n",
    "from models import ResNet, NeuralEulerODE, RidgeCVModule, E2EResNet\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import FittableModule, create_layer\n",
    "from ridge_ALOOCV import fit_ridge_ALOOCV\n",
    "\n",
    "class StagewiseRandFeatBoostRegression(FittableModule):\n",
    "    def __init__(self, \n",
    "                 generator: torch.Generator, \n",
    "                 hidden_dim: int = 128, \n",
    "                 bottleneck_dim: int = 128,\n",
    "                 out_dim: int = 1,\n",
    "                 n_layers: int = 5,\n",
    "                 activation: nn.Module = nn.Tanh(),\n",
    "                 l2_reg: float = 0.01,\n",
    "                 feature_type = \"SWIM\", # \"dense\", identity\n",
    "                 boost_lr: float = 1.0,\n",
    "                 ):\n",
    "        super(StagewiseRandFeatBoostRegression, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bottleneck_dim = bottleneck_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.activation = activation\n",
    "        self.l2_reg = l2_reg\n",
    "        self.feature_type = feature_type\n",
    "        self.boost_lr = boost_lr\n",
    "\n",
    "        # save for now. for more memory efficient implementation, we can remove a lot of this\n",
    "        self.W = []\n",
    "        self.b = []\n",
    "        self.alphas = []\n",
    "        self.layers = []\n",
    "        self.deltas = []\n",
    "\n",
    "\n",
    "    def fit(self, X: Tensor, y: Tensor):\n",
    "        # Create regressor W_0\n",
    "        W, b, alpha = fit_ridge_ALOOCV(X, y)\n",
    "        self.W.append(W)\n",
    "        self.b.append(b)\n",
    "        self.alphas.append(alpha)\n",
    "\n",
    "        # Layerwise boosting\n",
    "        for t in range(self.n_layers):\n",
    "            # Step 1: Create random feature layer   \n",
    "            layer = create_layer(self.generator, self.feature_type, self.hidden_dim, self.bottleneck_dim, self.activation)\n",
    "            F, y = layer.fit(X, y)\n",
    "\n",
    "            # Step 2: Obtain activation gradient and learn Delta\n",
    "            # X shape (N, D) --- ResNet neurons\n",
    "            # F shape (N, p) --- random features\n",
    "            # y shape (N, d) --- target\n",
    "            # r shape (N, D) --- residual at currect boosting iteration\n",
    "            # W shape (D, d) --- top level classifier\n",
    "            r = y - X @ W - b   # G = (y - X @ W - b) @ W.T\n",
    "            SW, U = torch.linalg.eigh(W @ W.T)\n",
    "            SF, V = torch.linalg.eigh(F.T @ F)\n",
    "            Delta = (U.T @ W @ r.T @ F @ V) / (N*self.l2_reg + SW[:, None]*SF[None, :])\n",
    "            Delta = (U @ Delta @ V.T).T\n",
    "            #TODO de-center F and r, and include an intercept. How to do this for my special equation?\n",
    "\n",
    "            # Step 3: Learn top level classifier\n",
    "            X = X + self.boost_lr * F @ Delta\n",
    "            W, b, alpha = fit_ridge_ALOOCV(X, y)\n",
    "\n",
    "            # store\n",
    "            self.layers.append(layer)\n",
    "            self.deltas.append(Delta)\n",
    "            self.W.append(W)\n",
    "            self.b.append(b)\n",
    "            self.alphas.append(alpha)\n",
    "\n",
    "        return X @ W + b, y\n",
    "\n",
    "\n",
    "    def forward(self, X: Tensor) -> Tensor:\n",
    "        for layer, Delta in zip(self.layers, self.deltas):\n",
    "            X = X + self.boost_lr * layer(X) @ Delta\n",
    "        return X @ self.W[-1] + self.b[-1]\n",
    "    \n",
    "N = 100\n",
    "D = 50\n",
    "p = 30\n",
    "d = 4\n",
    "bottleneck_dim = 70\n",
    "\n",
    "gen = torch.Generator().manual_seed(42)\n",
    "X = torch.randn(N, D, generator=gen)\n",
    "y = torch.randn(N, d, generator=gen)\n",
    "model = StagewiseRandFeatBoostRegression(\n",
    "        gen,\n",
    "        hidden_dim = D,\n",
    "        bottleneck_dim = bottleneck_dim,\n",
    "        out_dim = d,\n",
    "        n_layers = 5,\n",
    "    )\n",
    "_, _ = model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models import FittableModule, create_layer, ResidualBlock\n",
    "\n",
    "# class RandFeatBoostRegression(FittableModule):\n",
    "#     def __init__(self, \n",
    "#                  generator: torch.Generator, \n",
    "#                  in_dim: int = 1,\n",
    "#                  hidden_size: int = 128, \n",
    "#                  out_dim: int = 1,\n",
    "#                  n_blocks: int = 5,\n",
    "#                  activation: nn.Module = nn.Tanh(),\n",
    "#                  adam_lr: float = 1e-3,\n",
    "#                  boost_lr: float = 1.0,\n",
    "#                  epochs: int = 50,\n",
    "#                  batch_size: int = 64,\n",
    "#                  upscale_type = \"SWIM\", # \"dense\", identity\n",
    "#                  second_in_resblock = \"identity\",\n",
    "#                  ):\n",
    "#         super(RandFeatBoostRegression, self).__init__()\n",
    "#         self.generator = generator\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.out_dim = out_dim\n",
    "#         self.n_blocks = n_blocks\n",
    "#         self.activation = activation\n",
    "#         self.adam_lr = adam_lr\n",
    "#         self.boost_lr = boost_lr\n",
    "#         self.epochs = epochs\n",
    "#         self.batch_size = batch_size\n",
    "#         self.upscale_type = upscale_type\n",
    "#         self.second_in_resblock = second_in_resblock\n",
    "\n",
    "#         self.upscale = create_layer(generator, upscale_type, in_dim, hidden_size, activation)\n",
    "#         self.layers = []\n",
    "#         self.deltas = []\n",
    "#         self.regressors = []\n",
    "#         self.reg = None\n",
    "\n",
    "\n",
    "#     def fit(self, X: Tensor, y: Tensor):\n",
    "#         device = X.device\n",
    "#         X0 = X\n",
    "#         X, y = self.upscale.fit(X, y)\n",
    "\n",
    "#         # Create a CPU generator for DataLoader\n",
    "#         data_loader_generator = torch.Generator(device='cpu')\n",
    "#         data_loader_generator.manual_seed(self.generator.initial_seed())\n",
    "\n",
    "#         # Layerwise boosting\n",
    "#         for t in range(self.n_blocks):\n",
    "#             layer = ResidualBlock(self.generator, self.hidden_size, self.hidden_size, self.upscale_type, self.second_in_resblock, self.activation)\n",
    "#             layer.fit(X, y)\n",
    "\n",
    "#             # Create top classifier\n",
    "#             reg = RidgeCVModule()\n",
    "\n",
    "\n",
    "#             #DELTA = nn.Parameter(torch.zeros(1, self.hidden_size, device=device))\n",
    "#             DELTA = nn.Parameter(torch.zeros(1, 1, device=device))\n",
    "#             if t > 0:\n",
    "#                 classifier.weight.data = self.classifiers[-1].weight.data.clone()\n",
    "#                 classifier.bias.data = self.classifiers[-1].bias.data.clone()\n",
    "\n",
    "#             #data loader\n",
    "#             dataset = torch.utils.data.TensorDataset(X, y)\n",
    "#             loader = torch.utils.data.DataLoader(\n",
    "#                 dataset, \n",
    "#                 batch_size=self.batch_size, \n",
    "#                 shuffle=True, \n",
    "#                 generator=data_loader_generator\n",
    "#             )\n",
    "\n",
    "#             #learn top level classifier and boost\n",
    "#             params = list(classifier.parameters()) + [DELTA]\n",
    "#             self.optimizer = torch.optim.Adam(params, lr=self.adam_lr, weight_decay=1e-5)\n",
    "#             for epoch in tqdm(range(self.epochs)):\n",
    "#                 for batch_X, batch_y in loader:\n",
    "#                     self.optimizer.zero_grad()\n",
    "\n",
    "#                     #forward pass\n",
    "#                     FofX = layer(batch_X) - batch_X # due to how i programmed ResidualBlock...\n",
    "#                     outputs = classifier(batch_X + DELTA * FofX)\n",
    "\n",
    "#                     #loss and backprop\n",
    "#                     loss = self.loss_fn(outputs, batch_y)\n",
    "#                     loss.backward()\n",
    "#                     self.optimizer.step()\n",
    "            \n",
    "#             #after convergence, update layers, deltas, and X\n",
    "#             self.layers.append(layer)\n",
    "#             self.deltas.append(DELTA)\n",
    "#             self.classifiers.append(classifier)\n",
    "#             with torch.no_grad():\n",
    "#                 X = X + self.boost_lr * DELTA * (layer(X)-X)\n",
    "\n",
    "#         self.classifier = classifier\n",
    "#         return self(X0), y\n",
    "\n",
    "\n",
    "#     def forward(self, X: Tensor) -> Tensor:\n",
    "#         X = self.upscale(X)\n",
    "#         for layer, DELTA in zip(self.layers, self.deltas):\n",
    "#             FofX = layer(X) - X\n",
    "#             X = X + self.boost_lr * DELTA * FofX\n",
    "#         return self.classifier(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/35 Processed dataset 44956: abalone\n",
      " 2/35 Processed dataset 44957: airfoil_self_noise\n",
      " 3/35 Processed dataset 44958: auction_verification\n",
      " 4/35 Processed dataset 44959: concrete_compressive_strength\n",
      " 5/35 Processed dataset 44963: physiochemical_protein\n",
      " 6/35 Processed dataset 44964: superconductivity\n",
      " 7/35 Processed dataset 44965: geographical_origin_of_music\n",
      " 8/35 Processed dataset 44966: solar_flare\n",
      " 9/35 Processed dataset 44969: naval_propulsion_plant\n",
      " 10/35 Processed dataset 44971: white_wine\n",
      " 11/35 Processed dataset 44972: red_wine\n",
      " 12/35 Processed dataset 44973: grid_stability\n",
      " 13/35 Processed dataset 44974: video_transcoding\n",
      " 14/35 Processed dataset 44975: wave_energy\n",
      " 15/35 Processed dataset 44976: sarcos\n",
      " 16/35 Processed dataset 44977: california_housing\n",
      " 17/35 Processed dataset 44978: cpu_activity\n",
      " 18/35 Processed dataset 44979: diamonds\n",
      " 19/35 Processed dataset 44980: kin8nm\n",
      " 20/35 Processed dataset 44981: pumadyn32nh\n",
      " 21/35 Processed dataset 44983: miami_housing\n",
      " 22/35 Processed dataset 44984: cps88wages\n",
      " 23/35 Processed dataset 44987: socmob\n",
      " 24/35 Processed dataset 44989: kings_county\n",
      " 25/35 Processed dataset 44990: brazilian_houses\n",
      " 26/35 Processed dataset 44992: fps_benchmark\n",
      " 27/35 Processed dataset 44993: health_insurance\n",
      " 28/35 Processed dataset 45012: fifa\n",
      " 29/35 Processed dataset 41021: Moneyball\n",
      " 30/35 Processed dataset 44960: energy_efficiency\n",
      " 31/35 Processed dataset 44962: forest_fires\n",
      " 32/35 Processed dataset 44967: student_performance_por\n",
      " 33/35 Processed dataset 44970: QSAR_fish_toxicity\n",
      " 34/35 Processed dataset 44994: cars\n",
      " 35/35 Processed dataset 45402: space_ga\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>n_features</th>\n",
       "      <th>%_unique_y</th>\n",
       "      <th>n_unique_y</th>\n",
       "      <th>has_categorical</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44973</th>\n",
       "      <td>grid_stability</td>\n",
       "      <td>10000</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44975</th>\n",
       "      <td>wave_energy</td>\n",
       "      <td>72000</td>\n",
       "      <td>49</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>71993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44980</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8192</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>8191</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44981</th>\n",
       "      <td>pumadyn32nh</td>\n",
       "      <td>8192</td>\n",
       "      <td>33</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>8191</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45402</th>\n",
       "      <td>space_ga</td>\n",
       "      <td>3107</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999356</td>\n",
       "      <td>3105</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44958</th>\n",
       "      <td>auction_verification</td>\n",
       "      <td>2043</td>\n",
       "      <td>8</td>\n",
       "      <td>0.998042</td>\n",
       "      <td>2039</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44994</th>\n",
       "      <td>cars</td>\n",
       "      <td>804</td>\n",
       "      <td>18</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>798</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44957</th>\n",
       "      <td>airfoil_self_noise</td>\n",
       "      <td>1503</td>\n",
       "      <td>6</td>\n",
       "      <td>0.968729</td>\n",
       "      <td>1456</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44970</th>\n",
       "      <td>QSAR_fish_toxicity</td>\n",
       "      <td>908</td>\n",
       "      <td>7</td>\n",
       "      <td>0.910793</td>\n",
       "      <td>827</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44959</th>\n",
       "      <td>concrete_compressive_strength</td>\n",
       "      <td>1030</td>\n",
       "      <td>9</td>\n",
       "      <td>0.910680</td>\n",
       "      <td>938</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44960</th>\n",
       "      <td>energy_efficiency</td>\n",
       "      <td>768</td>\n",
       "      <td>9</td>\n",
       "      <td>0.764323</td>\n",
       "      <td>587</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44990</th>\n",
       "      <td>brazilian_houses</td>\n",
       "      <td>10692</td>\n",
       "      <td>10</td>\n",
       "      <td>0.537879</td>\n",
       "      <td>5751</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44962</th>\n",
       "      <td>forest_fires</td>\n",
       "      <td>517</td>\n",
       "      <td>13</td>\n",
       "      <td>0.485493</td>\n",
       "      <td>251</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44963</th>\n",
       "      <td>physiochemical_protein</td>\n",
       "      <td>45730</td>\n",
       "      <td>10</td>\n",
       "      <td>0.347759</td>\n",
       "      <td>15903</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44987</th>\n",
       "      <td>socmob</td>\n",
       "      <td>1156</td>\n",
       "      <td>6</td>\n",
       "      <td>0.312284</td>\n",
       "      <td>361</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41021</th>\n",
       "      <td>Moneyball</td>\n",
       "      <td>1232</td>\n",
       "      <td>15</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>374</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44976</th>\n",
       "      <td>sarcos</td>\n",
       "      <td>48933</td>\n",
       "      <td>22</td>\n",
       "      <td>0.233258</td>\n",
       "      <td>11414</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44979</th>\n",
       "      <td>diamonds</td>\n",
       "      <td>53940</td>\n",
       "      <td>10</td>\n",
       "      <td>0.215091</td>\n",
       "      <td>11602</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44984</th>\n",
       "      <td>cps88wages</td>\n",
       "      <td>28155</td>\n",
       "      <td>7</td>\n",
       "      <td>0.212040</td>\n",
       "      <td>5970</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44989</th>\n",
       "      <td>kings_county</td>\n",
       "      <td>21613</td>\n",
       "      <td>22</td>\n",
       "      <td>0.186369</td>\n",
       "      <td>4028</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44977</th>\n",
       "      <td>california_housing</td>\n",
       "      <td>20640</td>\n",
       "      <td>9</td>\n",
       "      <td>0.186143</td>\n",
       "      <td>3842</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44974</th>\n",
       "      <td>video_transcoding</td>\n",
       "      <td>68784</td>\n",
       "      <td>19</td>\n",
       "      <td>0.159339</td>\n",
       "      <td>10960</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44983</th>\n",
       "      <td>miami_housing</td>\n",
       "      <td>13932</td>\n",
       "      <td>16</td>\n",
       "      <td>0.151522</td>\n",
       "      <td>2111</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44964</th>\n",
       "      <td>superconductivity</td>\n",
       "      <td>21263</td>\n",
       "      <td>82</td>\n",
       "      <td>0.141419</td>\n",
       "      <td>3007</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44992</th>\n",
       "      <td>fps_benchmark</td>\n",
       "      <td>24624</td>\n",
       "      <td>44</td>\n",
       "      <td>0.108634</td>\n",
       "      <td>2675</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44965</th>\n",
       "      <td>geographical_origin_of_music</td>\n",
       "      <td>1059</td>\n",
       "      <td>117</td>\n",
       "      <td>0.029273</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44967</th>\n",
       "      <td>student_performance_por</td>\n",
       "      <td>649</td>\n",
       "      <td>31</td>\n",
       "      <td>0.026194</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44966</th>\n",
       "      <td>solar_flare</td>\n",
       "      <td>1066</td>\n",
       "      <td>11</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45012</th>\n",
       "      <td>fifa</td>\n",
       "      <td>19178</td>\n",
       "      <td>29</td>\n",
       "      <td>0.006935</td>\n",
       "      <td>133</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44978</th>\n",
       "      <td>cpu_activity</td>\n",
       "      <td>8192</td>\n",
       "      <td>22</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>56</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44956</th>\n",
       "      <td>abalone</td>\n",
       "      <td>4177</td>\n",
       "      <td>9</td>\n",
       "      <td>0.006703</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44969</th>\n",
       "      <td>naval_propulsion_plant</td>\n",
       "      <td>11934</td>\n",
       "      <td>15</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44972</th>\n",
       "      <td>red_wine</td>\n",
       "      <td>1599</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44993</th>\n",
       "      <td>health_insurance</td>\n",
       "      <td>22272</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>75</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44971</th>\n",
       "      <td>white_wine</td>\n",
       "      <td>4898</td>\n",
       "      <td>12</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     name  n_obs  n_features  %_unique_y  \\\n",
       "dataset_id                                                                 \n",
       "44973                      grid_stability  10000          13    1.000000   \n",
       "44975                         wave_energy  72000          49    0.999903   \n",
       "44980                              kin8nm   8192           9    0.999878   \n",
       "44981                         pumadyn32nh   8192          33    0.999878   \n",
       "45402                            space_ga   3107           7    0.999356   \n",
       "44958                auction_verification   2043           8    0.998042   \n",
       "44994                                cars    804          18    0.992537   \n",
       "44957                  airfoil_self_noise   1503           6    0.968729   \n",
       "44970                  QSAR_fish_toxicity    908           7    0.910793   \n",
       "44959       concrete_compressive_strength   1030           9    0.910680   \n",
       "44960                   energy_efficiency    768           9    0.764323   \n",
       "44990                    brazilian_houses  10692          10    0.537879   \n",
       "44962                        forest_fires    517          13    0.485493   \n",
       "44963              physiochemical_protein  45730          10    0.347759   \n",
       "44987                              socmob   1156           6    0.312284   \n",
       "41021                           Moneyball   1232          15    0.303571   \n",
       "44976                              sarcos  48933          22    0.233258   \n",
       "44979                            diamonds  53940          10    0.215091   \n",
       "44984                          cps88wages  28155           7    0.212040   \n",
       "44989                        kings_county  21613          22    0.186369   \n",
       "44977                  california_housing  20640           9    0.186143   \n",
       "44974                   video_transcoding  68784          19    0.159339   \n",
       "44983                       miami_housing  13932          16    0.151522   \n",
       "44964                   superconductivity  21263          82    0.141419   \n",
       "44992                       fps_benchmark  24624          44    0.108634   \n",
       "44965        geographical_origin_of_music   1059         117    0.029273   \n",
       "44967             student_performance_por    649          31    0.026194   \n",
       "44966                         solar_flare   1066          11    0.007505   \n",
       "45012                                fifa  19178          29    0.006935   \n",
       "44978                        cpu_activity   8192          22    0.006836   \n",
       "44956                             abalone   4177           9    0.006703   \n",
       "44969              naval_propulsion_plant  11934          15    0.004274   \n",
       "44972                            red_wine   1599          12    0.003752   \n",
       "44993                    health_insurance  22272          12    0.003367   \n",
       "44971                          white_wine   4898          12    0.001429   \n",
       "\n",
       "            n_unique_y  has_categorical  \n",
       "dataset_id                               \n",
       "44973            10000            False  \n",
       "44975            71993            False  \n",
       "44980             8191            False  \n",
       "44981             8191            False  \n",
       "45402             3105            False  \n",
       "44958             2039             True  \n",
       "44994              798            False  \n",
       "44957             1456            False  \n",
       "44970              827            False  \n",
       "44959              938            False  \n",
       "44960              587            False  \n",
       "44990             5751             True  \n",
       "44962              251             True  \n",
       "44963            15903            False  \n",
       "44987              361             True  \n",
       "41021              374             True  \n",
       "44976            11414            False  \n",
       "44979            11602             True  \n",
       "44984             5970             True  \n",
       "44989             4028             True  \n",
       "44977             3842            False  \n",
       "44974            10960             True  \n",
       "44983             2111            False  \n",
       "44964             3007            False  \n",
       "44992             2675             True  \n",
       "44965               31            False  \n",
       "44967               17             True  \n",
       "44966                8             True  \n",
       "45012              133             True  \n",
       "44978               56            False  \n",
       "44956               28             True  \n",
       "44969               51            False  \n",
       "44972                6            False  \n",
       "44993               75             True  \n",
       "44971                7            False  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the collection with ID 353\n",
    "collection = openml.study.get_suite(353)\n",
    "dataset_ids = collection.data\n",
    "metadata_list = []\n",
    "\n",
    "# Fetch and process each dataset\n",
    "for i, dataset_id in enumerate(dataset_ids):\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        target=dataset.default_target_attribute\n",
    "    )\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)[..., None]\n",
    "    \n",
    "    # Determine if the dataset has categorical features\n",
    "    has_categorical = any(categorical_indicator)\n",
    "    \n",
    "    # Extract the required metadata\n",
    "    metadata = {\n",
    "        'dataset_id': dataset.id,\n",
    "        'name': dataset.name,\n",
    "        'n_obs': int(dataset.qualities['NumberOfInstances']),\n",
    "        'n_features': int(dataset.qualities['NumberOfFeatures']),\n",
    "        '%_unique_y': len(np.unique(y))/len(y),\n",
    "        'n_unique_y': len(np.unique(y)),\n",
    "        'has_categorical': has_categorical\n",
    "    }\n",
    "    \n",
    "    metadata_list.append(metadata)\n",
    "    print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset.id}: {dataset.name}\")\n",
    "\n",
    "# Create a DataFrame from the metadata list\n",
    "df_metadata = pd.DataFrame(metadata_list).sort_values('%_unique_y', ascending=False).set_index(\"dataset_id\")\n",
    "df_metadata.sort_values('%_unique_y', ascending=True)\n",
    "\n",
    "# Display the metadata DataFrame\n",
    "df_metadata.loc[44962, \"has_categorical\"] = True\n",
    "df_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_openml_dataset(dataset_id, \n",
    "                        normalize_X:bool = True,\n",
    "                        normalize_y:bool = True,\n",
    "                        train_test_size:float = 0.7,\n",
    "                        split_seed:int = 0,\n",
    "                        device=\"cpu\",\n",
    "                        ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # Fetch dataset from OpenML by its ID\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    df, _, categorical_indicator, attribute_names = dataset.get_data()\n",
    "    df.dropna(inplace=True)\n",
    "    y = np.array(df.pop(dataset.default_target_attribute))[..., None]\n",
    "    X = np.array(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_test_size, random_state=split_seed)\n",
    "\n",
    "    #normalize\n",
    "    if normalize_X:\n",
    "        X_train, X_test = normalize_mean_std_traindata(X_train, X_test)\n",
    "        X_train = np.clip(X_train, -3, 3)\n",
    "        X_test = np.clip(X_test, -3, 3)\n",
    "    if normalize_y:\n",
    "        y_train, y_test = normalize_mean_std_traindata(y_train, y_test)\n",
    "\n",
    "    return (torch.tensor(X_train.astype(np.float32), requires_grad=False, device=device),\n",
    "            torch.tensor(X_test.astype(np.float32), requires_grad=False, device=device),\n",
    "            torch.tensor(y_train.astype(np.float32), requires_grad=False, device=device),\n",
    "            torch.tensor(y_test.astype(np.float32), requires_grad=False, device=device))\n",
    "\n",
    "#dataset_id = 44971  # Replace with the dataset ID you want\n",
    "dataset_id = 44971 #44970\n",
    "X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id, False, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import matplotlib.pyplot as plt\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# def get_activation(name, activations):\n",
    "#     def hook(model, input, output):\n",
    "#         activations[name] = output.detach()\n",
    "#     return hook\n",
    "\n",
    "\n",
    "# def register_hooks(model, activations):\n",
    "#     for name, layer in model.named_modules():\n",
    "#         print(name)\n",
    "#         if \".dense\" not in name:\n",
    "#             layer.register_forward_hook(get_activation(name, activations))\n",
    "\n",
    "\n",
    "\n",
    "# def neuron_distribution_for_each_layer(X_train, y_train, X_test):\n",
    "#     D = X_train.shape[1]\n",
    "#     n_layers = 2\n",
    "#     g1 = torch.Generator().manual_seed(0)\n",
    "#     model = SampledEulerODE(g1, D, 10*D, n_layers, upsample_module='sampled', sampling_method='gradient')\n",
    "#     #model = SampledResNet(g1, D, 10*D, 10*D, n_layers, upsample_module='sampled', sampling_method='gradient')\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     activations = {}\n",
    "#     register_hooks(model, activations)\n",
    "    \n",
    "#     # Forward pass\n",
    "#     model(X_test)\n",
    "    \n",
    "#     # Plot input data distribution\n",
    "#     fig = make_subplots(rows=1, cols=1)\n",
    "#     fig.add_trace(go.Histogram(x=X_train.flatten().cpu().numpy(), nbinsx=50, name='Train', histnorm='probability density', opacity=0.5))\n",
    "#     fig.add_trace(go.Histogram(x=X_test.flatten().cpu().numpy(), nbinsx=50, name='Test', histnorm='probability density', opacity=0.5))\n",
    "#     fig.update_layout(title_text='Input Data Distribution', xaxis_title='Input Feature Value', yaxis_title='Probability Density', barmode='overlay')\n",
    "#     fig.show()\n",
    "\n",
    "#     # Plot activations\n",
    "#     for name, activation in activations.items():\n",
    "#         fig = make_subplots(rows=1, cols=1)\n",
    "#         fig.add_trace(go.Histogram(x=activation.flatten().cpu().numpy(), nbinsx=50, name='Activation', histnorm='probability density', opacity=0.5))\n",
    "#         fig.update_layout(title_text=f'Activations at Layer: {name}', xaxis_title='Activation Value', yaxis_title='Probability Density', barmode='overlay')\n",
    "#         fig.show()\n",
    "\n",
    "\n",
    "# neuron_distribution_for_each_layer(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit on a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_allmodels_1dataset(\n",
    "        generator: torch.Generator,\n",
    "        X_train: Tensor,\n",
    "        y_train: Tensor,\n",
    "        X_test: Tensor,\n",
    "        y_test: Tensor,\n",
    "        ):\n",
    "    \n",
    "    D = X_train.shape[1]\n",
    "    hidden_size = 512\n",
    "    bottleneck_dim = hidden_size\n",
    "\n",
    "    # (name, model, kwargs). kwargs separate to save memory\n",
    "    model_list = [\n",
    "        [\"RidgeCV\", RidgeCVModule, {}],\n",
    "\n",
    "        [\"T=3 End2End\", E2EResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": bottleneck_dim,\n",
    "                \"out_dim\": 1,\n",
    "                \"n_blocks\": 2,\n",
    "                \"activation\": nn.Tanh(),\n",
    "                \"loss\": nn.MSELoss(),\n",
    "                \"lr\": 1e-3,\n",
    "                \"epochs\": 50,\n",
    "                \"batch_size\": 64,}\n",
    "                ],\n",
    "\n",
    "        [\"T=1 Dense\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                 \"in_dim\": D,\n",
    "                 \"hidden_size\": hidden_size,\n",
    "                 \"bottleneck_dim\": None,\n",
    "                 \"n_blocks\": 0,\n",
    "                 \"upsample_layer\": \"dense\",}\n",
    "                 ],\n",
    "\n",
    "        [\"T=1 SWIM Grad\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": None,\n",
    "                \"n_blocks\": 0,\n",
    "                \"upsample_layer\": \"SWIM\",}\n",
    "                ],\n",
    "        \n",
    "        [\"T=1 SWIM Unif\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": None,\n",
    "                \"n_blocks\": 0,\n",
    "                \"upsample_layer\": \"SWIM\",\n",
    "                \"sampling_method\": \"uniform\",}\n",
    "                ],\n",
    "    ]\n",
    "\n",
    "    for n_blocks in [2, 4]:\n",
    "        model_list += [\n",
    "        [f\"T={n_blocks+1} ResSWIM Grad-dense\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": bottleneck_dim,\n",
    "                \"n_blocks\": n_blocks,\n",
    "                \"upsample_layer\": \"SWIM\",\n",
    "                \"res_layer1\": \"SWIM\",\n",
    "                \"res_layer2\": \"dense\",}\n",
    "                ],\n",
    "\n",
    "        [f\"T={n_blocks+1} ResSWIM Grad-id\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": hidden_size,\n",
    "                \"n_blocks\": n_blocks,\n",
    "                \"upsample_layer\": \"SWIM\",\n",
    "                \"res_layer1\": \"SWIM\",\n",
    "                \"res_layer2\": \"identity\",}\n",
    "                ],\n",
    "                \n",
    "        [f\"T={n_blocks+1} ResDense\", ResNet,\n",
    "                {\"generator\": generator,\n",
    "                \"in_dim\": D,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"bottleneck_dim\": hidden_size,\n",
    "                \"n_blocks\": n_blocks,\n",
    "                \"upsample_layer\": \"dense\",\n",
    "                \"res_layer1\": \"dense\",\n",
    "                \"res_layer2\": \"identity\",}\n",
    "                ],\n",
    "        ]\n",
    "        \n",
    "    for n_layers in range(0, 30, 5):\n",
    "        model_list += [\n",
    "        [f\"StagewiseRandFeatBoost_{n_layers}\", StagewiseRandFeatBoostRegression,\n",
    "                {\"generator\": generator,\n",
    "                \"hidden_dim\": D,\n",
    "                \"bottleneck_dim\": bottleneck_dim,\n",
    "                \"out_dim\": 1,\n",
    "                \"n_layers\": n_layers,\n",
    "                \"activation\": nn.Tanh(),\n",
    "                \"l2_reg\": 0.01,\n",
    "                \"feature_type\": \"SWIM\",\n",
    "                \"boost_lr\": 1.0,}\n",
    "                ],\n",
    "        ]\n",
    "    \n",
    "    results = []\n",
    "    model_names = []\n",
    "    for name, model, model_args in model_list:\n",
    "        t0 = time.perf_counter()\n",
    "        model = model(**model_args).to(X_train.device)\n",
    "        pred_train, _ = model.fit(X_train, y_train)\n",
    "        t1 = time.perf_counter()\n",
    "        pred_test = model(X_test)\n",
    "        t2 = time.perf_counter()\n",
    "        rmse_train = root_mean_squared_error(y_train.cpu(), pred_train.cpu().detach()) \n",
    "        rmse_test = root_mean_squared_error(y_test.cpu(), pred_test.cpu().detach())\n",
    "\n",
    "        result = np.array( [rmse_train, rmse_test, t1-t0, t2-t1] )\n",
    "        results.append( result )\n",
    "        model_names.append( name )\n",
    "\n",
    "    return model_names, results\n",
    "\n",
    "\n",
    "\n",
    "def run_all_experiments(\n",
    "        dataset_ids: List,\n",
    "        name_save: str = \"PLACEHOLDER\",\n",
    "        device=\"cuda\",\n",
    "        ):\n",
    "    # Fetch and process each dataset\n",
    "    experiments = {}\n",
    "    for i, dataset_id in enumerate(dataset_ids):\n",
    "        X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id, split_seed=0, device=device)\n",
    "        generator = torch.Generator(device=device).manual_seed(999)\n",
    "        results = run_allmodels_1dataset(\n",
    "            generator, X_train, y_train, X_test, y_test, \n",
    "            )\n",
    "        experiments[dataset_id] = results\n",
    "        print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset_id}\")\n",
    "\n",
    "    # Save results\n",
    "    # Assuming experiments is a dict where keys are dataset names and values are tuples (model_names, results)\n",
    "    attributes = [\"RMSE_train\", \"RMSE_test\", \"t_fit\", \"t_feat\"]\n",
    "    data_list = []\n",
    "    # Process the data\n",
    "    for dataset_name, (model_names, results) in experiments.items():\n",
    "        dataset_data = {}\n",
    "        for attr_idx, attribute in enumerate(attributes):\n",
    "            for model_idx, model_name in enumerate(model_names):\n",
    "                dataset_data[(attribute, model_name)] = results[model_idx][attr_idx]\n",
    "        data_list.append(pd.DataFrame(dataset_data, index=[dataset_name]))\n",
    "\n",
    "    # Combine all datasets into a single DataFrame\n",
    "    df = pd.concat(data_list)\n",
    "    df = df.sort_index(axis=1)\n",
    "    print(df)\n",
    "    df.to_pickle(f\"OpenML_reg_{name_save}.pkl\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 14.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/20 Processed dataset 44957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 20.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/20 Processed dataset 44959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 29.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/20 Processed dataset 44960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:28<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/20 Processed dataset 44963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:40<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/20 Processed dataset 44964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 22.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/20 Processed dataset 44965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/20 Processed dataset 44969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 26.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/20 Processed dataset 44970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:09<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/20 Processed dataset 44971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10/20 Processed dataset 44972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:19<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/20 Processed dataset 44973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:14<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12/20 Processed dataset 44975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:18<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13/20 Processed dataset 44976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:38<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14/20 Processed dataset 44977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15/20 Processed dataset 44978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16/20 Processed dataset 44980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17/20 Processed dataset 44981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:27<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18/20 Processed dataset 44983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 26.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19/20 Processed dataset 44994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:06<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20/20 Processed dataset 45402\n",
      "      RMSE_test                                                     \\\n",
      "        RidgeCV StagewiseRandFeatBoost_0 StagewiseRandFeatBoost_10   \n",
      "44957  0.674484                 0.674487                  0.402275   \n",
      "44959  0.542088                 0.542044                  0.329459   \n",
      "44960  0.304327                 0.304327                  0.169761   \n",
      "44963  0.839762                 0.839761                  0.730424   \n",
      "44964  0.517322                 0.517327                  0.411197   \n",
      "44965  0.914663                 0.914638                  0.995283   \n",
      "44969  0.413739                 0.408667                  0.200477   \n",
      "44970  0.666021                 0.666545                  0.632870   \n",
      "44971  0.878211                 0.878160                  0.827621   \n",
      "44972  0.766536                 0.766350                  0.762375   \n",
      "44973  0.595158                 0.595154                  0.235134   \n",
      "44975  0.006491                 0.006491                  0.006369   \n",
      "44976  0.294862                 0.294861                  0.195097   \n",
      "44977  0.587720                 0.587717                  0.492176   \n",
      "44978  0.323560                 0.323637                  0.149028   \n",
      "44980  0.771311                 0.771320                  0.434602   \n",
      "44981  0.904478                 0.904085                  0.903820   \n",
      "44983  0.586507                 0.586500                  0.346487   \n",
      "44994  0.296725                 0.296724                  0.232334   \n",
      "45402  0.706690                 0.706694                  0.564376   \n",
      "\n",
      "                                                           \\\n",
      "      StagewiseRandFeatBoost_15 StagewiseRandFeatBoost_20   \n",
      "44957                  0.371531                  0.363176   \n",
      "44959                  0.350480                  0.340559   \n",
      "44960                  0.093226                  0.100749   \n",
      "44963                  0.723815                  0.719567   \n",
      "44964                  0.401247                  0.399572   \n",
      "44965                  1.148351                  1.233783   \n",
      "44969                  0.102135                  0.091919   \n",
      "44970                  0.621211                  0.650791   \n",
      "44971                  0.836399                  0.830669   \n",
      "44972                  0.760444                  0.760841   \n",
      "44973                  0.231926                  0.229407   \n",
      "44975                  0.006359                  0.006322   \n",
      "44976                  0.190723                  0.188065   \n",
      "44977                  0.490337                  0.489689   \n",
      "44978                  0.145636                  0.144581   \n",
      "44980                  0.423030                  0.416212   \n",
      "44981                  0.903416                  0.903327   \n",
      "44983                  0.340540                  0.336163   \n",
      "44994                  0.233176                  0.243936   \n",
      "45402                  0.545395                  0.560295   \n",
      "\n",
      "                                                                    \\\n",
      "      StagewiseRandFeatBoost_25 StagewiseRandFeatBoost_5 T=1 Dense   \n",
      "44957                  0.381567                 0.410049  0.424680   \n",
      "44959                  0.334590                 0.360222  0.377728   \n",
      "44960                  0.074538                 0.232315  0.200248   \n",
      "44963                  0.717562                 0.740267  0.768821   \n",
      "44964                  0.393684                 0.426311  0.507481   \n",
      "44965                  1.440395                 0.902871  0.922860   \n",
      "44969                  0.508549                 0.584405  0.034592   \n",
      "44970                  0.657732                 0.627557  0.610808   \n",
      "44971                  0.841934                 0.825289  0.829079   \n",
      "44972                  0.749766                 0.755722  0.760606   \n",
      "44973                  0.230432                 0.275658  0.486082   \n",
      "44975                  0.006331                 0.006428  0.223069   \n",
      "44976                  0.183696                 0.204568  0.297940   \n",
      "44977                  0.486593                 0.499646  0.518562   \n",
      "44978                  0.142113                 0.159144  0.262635   \n",
      "44980                  0.413760                 0.489260  0.567570   \n",
      "44981                  0.903078                 0.903927  0.908482   \n",
      "44983                  0.332562                 0.357253  0.436589   \n",
      "44994                  0.239024                 0.221746  0.228476   \n",
      "45402                  0.568286                 0.578979  0.591418   \n",
      "\n",
      "                                   ...     t_fit                              \\\n",
      "      T=1 SWIM Grad T=1 SWIM Unif  ... T=1 Dense T=1 SWIM Grad T=1 SWIM Unif   \n",
      "44957      0.476077      0.500399  ...  0.037149      0.048563      0.026278   \n",
      "44959      0.423298      0.446550  ...  0.016910      0.028934      0.027148   \n",
      "44960      0.259649      0.264216  ...  0.022585      0.039492      0.034956   \n",
      "44963      0.792099      0.793024  ...  1.129858      1.001937      1.027092   \n",
      "44964      0.491303      0.492552  ...  0.409294      0.372071      0.402858   \n",
      "44965      0.906198      0.905319  ...  0.013971      0.029078      0.025057   \n",
      "44969      0.067562      0.449469  ...  0.138217      0.198264      0.234294   \n",
      "44970      0.638345      0.648441  ...  0.024857      0.032486      0.032628   \n",
      "44971      0.832194      0.835323  ...  0.059310      0.066782      0.120872   \n",
      "44972      0.770519      0.771048  ...  0.037638      0.042334      0.040502   \n",
      "44973      0.473364      0.512633  ...  0.185433      0.157332      0.172688   \n",
      "44975      0.012694      0.015784  ...  1.736978      1.504789      1.464262   \n",
      "44976      0.239661      0.247210  ...  0.955949      0.924126      0.944262   \n",
      "44977      0.529575      0.544155  ...  0.379658      0.353879      0.357469   \n",
      "44978      0.214158      0.216543  ...  0.140335      0.187912      0.148519   \n",
      "44980      0.636373      0.585936  ...  0.149235      0.185948      0.187917   \n",
      "44981      0.905389      0.903433  ...  0.150331      0.125750      0.120486   \n",
      "44983      0.393242      0.392023  ...  0.187940      0.237550      0.270211   \n",
      "44994      0.258183      0.261548  ...  0.014166      0.029637      0.018653   \n",
      "45402      0.659942      0.668379  ...  0.061713      0.080156      0.107401   \n",
      "\n",
      "                                                                           \\\n",
      "      T=3 End2End T=3 ResDense T=3 ResSWIM Grad-dense T=3 ResSWIM Grad-id   \n",
      "44957    3.478067     0.044773               0.039301            0.040360   \n",
      "44959    2.412283     0.027065               0.023220            0.036922   \n",
      "44960    1.725706     0.033834               0.045645            0.047782   \n",
      "44963   88.676260     1.006271               1.023794            1.028898   \n",
      "44964   40.495464     0.414610               0.402672            0.398201   \n",
      "44965    2.243213     0.035805               0.044113            0.040106   \n",
      "44969   22.922965     0.211904               0.241977            0.202942   \n",
      "44970    1.891859     0.041233               0.040841            0.054705   \n",
      "44971    9.679895     0.115978               0.093079            0.120600   \n",
      "44972    3.422929     0.045032               0.051529            0.050775   \n",
      "44973   19.331471     0.200014               0.203751            0.203844   \n",
      "44975  134.409286     1.471468               1.490047            1.490144   \n",
      "44976   78.385047     0.928995               0.979985            0.963427   \n",
      "44977   38.128586     0.346429               0.408187            0.377559   \n",
      "44978   16.128083     0.205617               0.153798            0.138588   \n",
      "44980   16.275776     0.167361               0.178467            0.171480   \n",
      "44981   16.107573     0.117851               0.115771            0.120702   \n",
      "44983   27.117575     0.263690               0.236828            0.284380   \n",
      "44994    1.925450     0.034081               0.026401            0.039026   \n",
      "45402    6.221771     0.085732               0.080351            0.080170   \n",
      "\n",
      "                                                               \n",
      "      T=5 ResDense T=5 ResSWIM Grad-dense T=5 ResSWIM Grad-id  \n",
      "44957     0.044366               0.096211            0.066376  \n",
      "44959     0.021435               0.030333            0.026865  \n",
      "44960     0.051409               0.053225            0.065124  \n",
      "44963     1.076974               1.083936            1.082646  \n",
      "44964     0.369224               0.460022            0.444525  \n",
      "44965     0.031932               0.056503            0.153849  \n",
      "44969     0.220156               0.230138            0.257736  \n",
      "44970     0.042325               0.059595            0.045046  \n",
      "44971     0.145675               0.161961            0.142813  \n",
      "44972     0.040645               0.039347            0.033065  \n",
      "44973     0.193068               0.213386            0.195777  \n",
      "44975     1.486977               1.506756            1.528774  \n",
      "44976     0.933719               0.957782            0.945963  \n",
      "44977     0.365830               0.414740            0.354316  \n",
      "44978     0.118033               0.146801            0.135073  \n",
      "44980     0.211810               0.210039            0.224337  \n",
      "44981     0.131110               0.125640            0.119606  \n",
      "44983     0.206791               0.224624            0.219350  \n",
      "44994     0.051969               0.065887            0.047031  \n",
      "45402     0.078562               0.109594            0.108246  \n",
      "\n",
      "[20 rows x 68 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">RMSE_test</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">t_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>RidgeCV</th>\n",
       "      <th>StagewiseRandFeatBoost_0</th>\n",
       "      <th>StagewiseRandFeatBoost_10</th>\n",
       "      <th>StagewiseRandFeatBoost_15</th>\n",
       "      <th>StagewiseRandFeatBoost_20</th>\n",
       "      <th>StagewiseRandFeatBoost_25</th>\n",
       "      <th>StagewiseRandFeatBoost_5</th>\n",
       "      <th>T=1 Dense</th>\n",
       "      <th>T=1 SWIM Grad</th>\n",
       "      <th>T=1 SWIM Unif</th>\n",
       "      <th>...</th>\n",
       "      <th>T=1 Dense</th>\n",
       "      <th>T=1 SWIM Grad</th>\n",
       "      <th>T=1 SWIM Unif</th>\n",
       "      <th>T=3 End2End</th>\n",
       "      <th>T=3 ResDense</th>\n",
       "      <th>T=3 ResSWIM Grad-dense</th>\n",
       "      <th>T=3 ResSWIM Grad-id</th>\n",
       "      <th>T=5 ResDense</th>\n",
       "      <th>T=5 ResSWIM Grad-dense</th>\n",
       "      <th>T=5 ResSWIM Grad-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44957</th>\n",
       "      <td>0.674484</td>\n",
       "      <td>0.674487</td>\n",
       "      <td>0.402275</td>\n",
       "      <td>0.371531</td>\n",
       "      <td>0.363176</td>\n",
       "      <td>0.381567</td>\n",
       "      <td>0.410049</td>\n",
       "      <td>0.424680</td>\n",
       "      <td>0.476077</td>\n",
       "      <td>0.500399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037149</td>\n",
       "      <td>0.048563</td>\n",
       "      <td>0.026278</td>\n",
       "      <td>3.478067</td>\n",
       "      <td>0.044773</td>\n",
       "      <td>0.039301</td>\n",
       "      <td>0.040360</td>\n",
       "      <td>0.044366</td>\n",
       "      <td>0.096211</td>\n",
       "      <td>0.066376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44959</th>\n",
       "      <td>0.542088</td>\n",
       "      <td>0.542044</td>\n",
       "      <td>0.329459</td>\n",
       "      <td>0.350480</td>\n",
       "      <td>0.340559</td>\n",
       "      <td>0.334590</td>\n",
       "      <td>0.360222</td>\n",
       "      <td>0.377728</td>\n",
       "      <td>0.423298</td>\n",
       "      <td>0.446550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016910</td>\n",
       "      <td>0.028934</td>\n",
       "      <td>0.027148</td>\n",
       "      <td>2.412283</td>\n",
       "      <td>0.027065</td>\n",
       "      <td>0.023220</td>\n",
       "      <td>0.036922</td>\n",
       "      <td>0.021435</td>\n",
       "      <td>0.030333</td>\n",
       "      <td>0.026865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44960</th>\n",
       "      <td>0.304327</td>\n",
       "      <td>0.304327</td>\n",
       "      <td>0.169761</td>\n",
       "      <td>0.093226</td>\n",
       "      <td>0.100749</td>\n",
       "      <td>0.074538</td>\n",
       "      <td>0.232315</td>\n",
       "      <td>0.200248</td>\n",
       "      <td>0.259649</td>\n",
       "      <td>0.264216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022585</td>\n",
       "      <td>0.039492</td>\n",
       "      <td>0.034956</td>\n",
       "      <td>1.725706</td>\n",
       "      <td>0.033834</td>\n",
       "      <td>0.045645</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>0.051409</td>\n",
       "      <td>0.053225</td>\n",
       "      <td>0.065124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44963</th>\n",
       "      <td>0.839762</td>\n",
       "      <td>0.839761</td>\n",
       "      <td>0.730424</td>\n",
       "      <td>0.723815</td>\n",
       "      <td>0.719567</td>\n",
       "      <td>0.717562</td>\n",
       "      <td>0.740267</td>\n",
       "      <td>0.768821</td>\n",
       "      <td>0.792099</td>\n",
       "      <td>0.793024</td>\n",
       "      <td>...</td>\n",
       "      <td>1.129858</td>\n",
       "      <td>1.001937</td>\n",
       "      <td>1.027092</td>\n",
       "      <td>88.676260</td>\n",
       "      <td>1.006271</td>\n",
       "      <td>1.023794</td>\n",
       "      <td>1.028898</td>\n",
       "      <td>1.076974</td>\n",
       "      <td>1.083936</td>\n",
       "      <td>1.082646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44964</th>\n",
       "      <td>0.517322</td>\n",
       "      <td>0.517327</td>\n",
       "      <td>0.411197</td>\n",
       "      <td>0.401247</td>\n",
       "      <td>0.399572</td>\n",
       "      <td>0.393684</td>\n",
       "      <td>0.426311</td>\n",
       "      <td>0.507481</td>\n",
       "      <td>0.491303</td>\n",
       "      <td>0.492552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409294</td>\n",
       "      <td>0.372071</td>\n",
       "      <td>0.402858</td>\n",
       "      <td>40.495464</td>\n",
       "      <td>0.414610</td>\n",
       "      <td>0.402672</td>\n",
       "      <td>0.398201</td>\n",
       "      <td>0.369224</td>\n",
       "      <td>0.460022</td>\n",
       "      <td>0.444525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44965</th>\n",
       "      <td>0.914663</td>\n",
       "      <td>0.914638</td>\n",
       "      <td>0.995283</td>\n",
       "      <td>1.148351</td>\n",
       "      <td>1.233783</td>\n",
       "      <td>1.440395</td>\n",
       "      <td>0.902871</td>\n",
       "      <td>0.922860</td>\n",
       "      <td>0.906198</td>\n",
       "      <td>0.905319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013971</td>\n",
       "      <td>0.029078</td>\n",
       "      <td>0.025057</td>\n",
       "      <td>2.243213</td>\n",
       "      <td>0.035805</td>\n",
       "      <td>0.044113</td>\n",
       "      <td>0.040106</td>\n",
       "      <td>0.031932</td>\n",
       "      <td>0.056503</td>\n",
       "      <td>0.153849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44969</th>\n",
       "      <td>0.413739</td>\n",
       "      <td>0.408667</td>\n",
       "      <td>0.200477</td>\n",
       "      <td>0.102135</td>\n",
       "      <td>0.091919</td>\n",
       "      <td>0.508549</td>\n",
       "      <td>0.584405</td>\n",
       "      <td>0.034592</td>\n",
       "      <td>0.067562</td>\n",
       "      <td>0.449469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138217</td>\n",
       "      <td>0.198264</td>\n",
       "      <td>0.234294</td>\n",
       "      <td>22.922965</td>\n",
       "      <td>0.211904</td>\n",
       "      <td>0.241977</td>\n",
       "      <td>0.202942</td>\n",
       "      <td>0.220156</td>\n",
       "      <td>0.230138</td>\n",
       "      <td>0.257736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44970</th>\n",
       "      <td>0.666021</td>\n",
       "      <td>0.666545</td>\n",
       "      <td>0.632870</td>\n",
       "      <td>0.621211</td>\n",
       "      <td>0.650791</td>\n",
       "      <td>0.657732</td>\n",
       "      <td>0.627557</td>\n",
       "      <td>0.610808</td>\n",
       "      <td>0.638345</td>\n",
       "      <td>0.648441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024857</td>\n",
       "      <td>0.032486</td>\n",
       "      <td>0.032628</td>\n",
       "      <td>1.891859</td>\n",
       "      <td>0.041233</td>\n",
       "      <td>0.040841</td>\n",
       "      <td>0.054705</td>\n",
       "      <td>0.042325</td>\n",
       "      <td>0.059595</td>\n",
       "      <td>0.045046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44971</th>\n",
       "      <td>0.878211</td>\n",
       "      <td>0.878160</td>\n",
       "      <td>0.827621</td>\n",
       "      <td>0.836399</td>\n",
       "      <td>0.830669</td>\n",
       "      <td>0.841934</td>\n",
       "      <td>0.825289</td>\n",
       "      <td>0.829079</td>\n",
       "      <td>0.832194</td>\n",
       "      <td>0.835323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059310</td>\n",
       "      <td>0.066782</td>\n",
       "      <td>0.120872</td>\n",
       "      <td>9.679895</td>\n",
       "      <td>0.115978</td>\n",
       "      <td>0.093079</td>\n",
       "      <td>0.120600</td>\n",
       "      <td>0.145675</td>\n",
       "      <td>0.161961</td>\n",
       "      <td>0.142813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44972</th>\n",
       "      <td>0.766536</td>\n",
       "      <td>0.766350</td>\n",
       "      <td>0.762375</td>\n",
       "      <td>0.760444</td>\n",
       "      <td>0.760841</td>\n",
       "      <td>0.749766</td>\n",
       "      <td>0.755722</td>\n",
       "      <td>0.760606</td>\n",
       "      <td>0.770519</td>\n",
       "      <td>0.771048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037638</td>\n",
       "      <td>0.042334</td>\n",
       "      <td>0.040502</td>\n",
       "      <td>3.422929</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>0.051529</td>\n",
       "      <td>0.050775</td>\n",
       "      <td>0.040645</td>\n",
       "      <td>0.039347</td>\n",
       "      <td>0.033065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44973</th>\n",
       "      <td>0.595158</td>\n",
       "      <td>0.595154</td>\n",
       "      <td>0.235134</td>\n",
       "      <td>0.231926</td>\n",
       "      <td>0.229407</td>\n",
       "      <td>0.230432</td>\n",
       "      <td>0.275658</td>\n",
       "      <td>0.486082</td>\n",
       "      <td>0.473364</td>\n",
       "      <td>0.512633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185433</td>\n",
       "      <td>0.157332</td>\n",
       "      <td>0.172688</td>\n",
       "      <td>19.331471</td>\n",
       "      <td>0.200014</td>\n",
       "      <td>0.203751</td>\n",
       "      <td>0.203844</td>\n",
       "      <td>0.193068</td>\n",
       "      <td>0.213386</td>\n",
       "      <td>0.195777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44975</th>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.006359</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.006428</td>\n",
       "      <td>0.223069</td>\n",
       "      <td>0.012694</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>...</td>\n",
       "      <td>1.736978</td>\n",
       "      <td>1.504789</td>\n",
       "      <td>1.464262</td>\n",
       "      <td>134.409286</td>\n",
       "      <td>1.471468</td>\n",
       "      <td>1.490047</td>\n",
       "      <td>1.490144</td>\n",
       "      <td>1.486977</td>\n",
       "      <td>1.506756</td>\n",
       "      <td>1.528774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44976</th>\n",
       "      <td>0.294862</td>\n",
       "      <td>0.294861</td>\n",
       "      <td>0.195097</td>\n",
       "      <td>0.190723</td>\n",
       "      <td>0.188065</td>\n",
       "      <td>0.183696</td>\n",
       "      <td>0.204568</td>\n",
       "      <td>0.297940</td>\n",
       "      <td>0.239661</td>\n",
       "      <td>0.247210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955949</td>\n",
       "      <td>0.924126</td>\n",
       "      <td>0.944262</td>\n",
       "      <td>78.385047</td>\n",
       "      <td>0.928995</td>\n",
       "      <td>0.979985</td>\n",
       "      <td>0.963427</td>\n",
       "      <td>0.933719</td>\n",
       "      <td>0.957782</td>\n",
       "      <td>0.945963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44977</th>\n",
       "      <td>0.587720</td>\n",
       "      <td>0.587717</td>\n",
       "      <td>0.492176</td>\n",
       "      <td>0.490337</td>\n",
       "      <td>0.489689</td>\n",
       "      <td>0.486593</td>\n",
       "      <td>0.499646</td>\n",
       "      <td>0.518562</td>\n",
       "      <td>0.529575</td>\n",
       "      <td>0.544155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379658</td>\n",
       "      <td>0.353879</td>\n",
       "      <td>0.357469</td>\n",
       "      <td>38.128586</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.408187</td>\n",
       "      <td>0.377559</td>\n",
       "      <td>0.365830</td>\n",
       "      <td>0.414740</td>\n",
       "      <td>0.354316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44978</th>\n",
       "      <td>0.323560</td>\n",
       "      <td>0.323637</td>\n",
       "      <td>0.149028</td>\n",
       "      <td>0.145636</td>\n",
       "      <td>0.144581</td>\n",
       "      <td>0.142113</td>\n",
       "      <td>0.159144</td>\n",
       "      <td>0.262635</td>\n",
       "      <td>0.214158</td>\n",
       "      <td>0.216543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140335</td>\n",
       "      <td>0.187912</td>\n",
       "      <td>0.148519</td>\n",
       "      <td>16.128083</td>\n",
       "      <td>0.205617</td>\n",
       "      <td>0.153798</td>\n",
       "      <td>0.138588</td>\n",
       "      <td>0.118033</td>\n",
       "      <td>0.146801</td>\n",
       "      <td>0.135073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44980</th>\n",
       "      <td>0.771311</td>\n",
       "      <td>0.771320</td>\n",
       "      <td>0.434602</td>\n",
       "      <td>0.423030</td>\n",
       "      <td>0.416212</td>\n",
       "      <td>0.413760</td>\n",
       "      <td>0.489260</td>\n",
       "      <td>0.567570</td>\n",
       "      <td>0.636373</td>\n",
       "      <td>0.585936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149235</td>\n",
       "      <td>0.185948</td>\n",
       "      <td>0.187917</td>\n",
       "      <td>16.275776</td>\n",
       "      <td>0.167361</td>\n",
       "      <td>0.178467</td>\n",
       "      <td>0.171480</td>\n",
       "      <td>0.211810</td>\n",
       "      <td>0.210039</td>\n",
       "      <td>0.224337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44981</th>\n",
       "      <td>0.904478</td>\n",
       "      <td>0.904085</td>\n",
       "      <td>0.903820</td>\n",
       "      <td>0.903416</td>\n",
       "      <td>0.903327</td>\n",
       "      <td>0.903078</td>\n",
       "      <td>0.903927</td>\n",
       "      <td>0.908482</td>\n",
       "      <td>0.905389</td>\n",
       "      <td>0.903433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150331</td>\n",
       "      <td>0.125750</td>\n",
       "      <td>0.120486</td>\n",
       "      <td>16.107573</td>\n",
       "      <td>0.117851</td>\n",
       "      <td>0.115771</td>\n",
       "      <td>0.120702</td>\n",
       "      <td>0.131110</td>\n",
       "      <td>0.125640</td>\n",
       "      <td>0.119606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44983</th>\n",
       "      <td>0.586507</td>\n",
       "      <td>0.586500</td>\n",
       "      <td>0.346487</td>\n",
       "      <td>0.340540</td>\n",
       "      <td>0.336163</td>\n",
       "      <td>0.332562</td>\n",
       "      <td>0.357253</td>\n",
       "      <td>0.436589</td>\n",
       "      <td>0.393242</td>\n",
       "      <td>0.392023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187940</td>\n",
       "      <td>0.237550</td>\n",
       "      <td>0.270211</td>\n",
       "      <td>27.117575</td>\n",
       "      <td>0.263690</td>\n",
       "      <td>0.236828</td>\n",
       "      <td>0.284380</td>\n",
       "      <td>0.206791</td>\n",
       "      <td>0.224624</td>\n",
       "      <td>0.219350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44994</th>\n",
       "      <td>0.296725</td>\n",
       "      <td>0.296724</td>\n",
       "      <td>0.232334</td>\n",
       "      <td>0.233176</td>\n",
       "      <td>0.243936</td>\n",
       "      <td>0.239024</td>\n",
       "      <td>0.221746</td>\n",
       "      <td>0.228476</td>\n",
       "      <td>0.258183</td>\n",
       "      <td>0.261548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>0.029637</td>\n",
       "      <td>0.018653</td>\n",
       "      <td>1.925450</td>\n",
       "      <td>0.034081</td>\n",
       "      <td>0.026401</td>\n",
       "      <td>0.039026</td>\n",
       "      <td>0.051969</td>\n",
       "      <td>0.065887</td>\n",
       "      <td>0.047031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45402</th>\n",
       "      <td>0.706690</td>\n",
       "      <td>0.706694</td>\n",
       "      <td>0.564376</td>\n",
       "      <td>0.545395</td>\n",
       "      <td>0.560295</td>\n",
       "      <td>0.568286</td>\n",
       "      <td>0.578979</td>\n",
       "      <td>0.591418</td>\n",
       "      <td>0.659942</td>\n",
       "      <td>0.668379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061713</td>\n",
       "      <td>0.080156</td>\n",
       "      <td>0.107401</td>\n",
       "      <td>6.221771</td>\n",
       "      <td>0.085732</td>\n",
       "      <td>0.080351</td>\n",
       "      <td>0.080170</td>\n",
       "      <td>0.078562</td>\n",
       "      <td>0.109594</td>\n",
       "      <td>0.108246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RMSE_test                                                     \\\n",
       "        RidgeCV StagewiseRandFeatBoost_0 StagewiseRandFeatBoost_10   \n",
       "44957  0.674484                 0.674487                  0.402275   \n",
       "44959  0.542088                 0.542044                  0.329459   \n",
       "44960  0.304327                 0.304327                  0.169761   \n",
       "44963  0.839762                 0.839761                  0.730424   \n",
       "44964  0.517322                 0.517327                  0.411197   \n",
       "44965  0.914663                 0.914638                  0.995283   \n",
       "44969  0.413739                 0.408667                  0.200477   \n",
       "44970  0.666021                 0.666545                  0.632870   \n",
       "44971  0.878211                 0.878160                  0.827621   \n",
       "44972  0.766536                 0.766350                  0.762375   \n",
       "44973  0.595158                 0.595154                  0.235134   \n",
       "44975  0.006491                 0.006491                  0.006369   \n",
       "44976  0.294862                 0.294861                  0.195097   \n",
       "44977  0.587720                 0.587717                  0.492176   \n",
       "44978  0.323560                 0.323637                  0.149028   \n",
       "44980  0.771311                 0.771320                  0.434602   \n",
       "44981  0.904478                 0.904085                  0.903820   \n",
       "44983  0.586507                 0.586500                  0.346487   \n",
       "44994  0.296725                 0.296724                  0.232334   \n",
       "45402  0.706690                 0.706694                  0.564376   \n",
       "\n",
       "                                                           \\\n",
       "      StagewiseRandFeatBoost_15 StagewiseRandFeatBoost_20   \n",
       "44957                  0.371531                  0.363176   \n",
       "44959                  0.350480                  0.340559   \n",
       "44960                  0.093226                  0.100749   \n",
       "44963                  0.723815                  0.719567   \n",
       "44964                  0.401247                  0.399572   \n",
       "44965                  1.148351                  1.233783   \n",
       "44969                  0.102135                  0.091919   \n",
       "44970                  0.621211                  0.650791   \n",
       "44971                  0.836399                  0.830669   \n",
       "44972                  0.760444                  0.760841   \n",
       "44973                  0.231926                  0.229407   \n",
       "44975                  0.006359                  0.006322   \n",
       "44976                  0.190723                  0.188065   \n",
       "44977                  0.490337                  0.489689   \n",
       "44978                  0.145636                  0.144581   \n",
       "44980                  0.423030                  0.416212   \n",
       "44981                  0.903416                  0.903327   \n",
       "44983                  0.340540                  0.336163   \n",
       "44994                  0.233176                  0.243936   \n",
       "45402                  0.545395                  0.560295   \n",
       "\n",
       "                                                                    \\\n",
       "      StagewiseRandFeatBoost_25 StagewiseRandFeatBoost_5 T=1 Dense   \n",
       "44957                  0.381567                 0.410049  0.424680   \n",
       "44959                  0.334590                 0.360222  0.377728   \n",
       "44960                  0.074538                 0.232315  0.200248   \n",
       "44963                  0.717562                 0.740267  0.768821   \n",
       "44964                  0.393684                 0.426311  0.507481   \n",
       "44965                  1.440395                 0.902871  0.922860   \n",
       "44969                  0.508549                 0.584405  0.034592   \n",
       "44970                  0.657732                 0.627557  0.610808   \n",
       "44971                  0.841934                 0.825289  0.829079   \n",
       "44972                  0.749766                 0.755722  0.760606   \n",
       "44973                  0.230432                 0.275658  0.486082   \n",
       "44975                  0.006331                 0.006428  0.223069   \n",
       "44976                  0.183696                 0.204568  0.297940   \n",
       "44977                  0.486593                 0.499646  0.518562   \n",
       "44978                  0.142113                 0.159144  0.262635   \n",
       "44980                  0.413760                 0.489260  0.567570   \n",
       "44981                  0.903078                 0.903927  0.908482   \n",
       "44983                  0.332562                 0.357253  0.436589   \n",
       "44994                  0.239024                 0.221746  0.228476   \n",
       "45402                  0.568286                 0.578979  0.591418   \n",
       "\n",
       "                                   ...     t_fit                              \\\n",
       "      T=1 SWIM Grad T=1 SWIM Unif  ... T=1 Dense T=1 SWIM Grad T=1 SWIM Unif   \n",
       "44957      0.476077      0.500399  ...  0.037149      0.048563      0.026278   \n",
       "44959      0.423298      0.446550  ...  0.016910      0.028934      0.027148   \n",
       "44960      0.259649      0.264216  ...  0.022585      0.039492      0.034956   \n",
       "44963      0.792099      0.793024  ...  1.129858      1.001937      1.027092   \n",
       "44964      0.491303      0.492552  ...  0.409294      0.372071      0.402858   \n",
       "44965      0.906198      0.905319  ...  0.013971      0.029078      0.025057   \n",
       "44969      0.067562      0.449469  ...  0.138217      0.198264      0.234294   \n",
       "44970      0.638345      0.648441  ...  0.024857      0.032486      0.032628   \n",
       "44971      0.832194      0.835323  ...  0.059310      0.066782      0.120872   \n",
       "44972      0.770519      0.771048  ...  0.037638      0.042334      0.040502   \n",
       "44973      0.473364      0.512633  ...  0.185433      0.157332      0.172688   \n",
       "44975      0.012694      0.015784  ...  1.736978      1.504789      1.464262   \n",
       "44976      0.239661      0.247210  ...  0.955949      0.924126      0.944262   \n",
       "44977      0.529575      0.544155  ...  0.379658      0.353879      0.357469   \n",
       "44978      0.214158      0.216543  ...  0.140335      0.187912      0.148519   \n",
       "44980      0.636373      0.585936  ...  0.149235      0.185948      0.187917   \n",
       "44981      0.905389      0.903433  ...  0.150331      0.125750      0.120486   \n",
       "44983      0.393242      0.392023  ...  0.187940      0.237550      0.270211   \n",
       "44994      0.258183      0.261548  ...  0.014166      0.029637      0.018653   \n",
       "45402      0.659942      0.668379  ...  0.061713      0.080156      0.107401   \n",
       "\n",
       "                                                                           \\\n",
       "      T=3 End2End T=3 ResDense T=3 ResSWIM Grad-dense T=3 ResSWIM Grad-id   \n",
       "44957    3.478067     0.044773               0.039301            0.040360   \n",
       "44959    2.412283     0.027065               0.023220            0.036922   \n",
       "44960    1.725706     0.033834               0.045645            0.047782   \n",
       "44963   88.676260     1.006271               1.023794            1.028898   \n",
       "44964   40.495464     0.414610               0.402672            0.398201   \n",
       "44965    2.243213     0.035805               0.044113            0.040106   \n",
       "44969   22.922965     0.211904               0.241977            0.202942   \n",
       "44970    1.891859     0.041233               0.040841            0.054705   \n",
       "44971    9.679895     0.115978               0.093079            0.120600   \n",
       "44972    3.422929     0.045032               0.051529            0.050775   \n",
       "44973   19.331471     0.200014               0.203751            0.203844   \n",
       "44975  134.409286     1.471468               1.490047            1.490144   \n",
       "44976   78.385047     0.928995               0.979985            0.963427   \n",
       "44977   38.128586     0.346429               0.408187            0.377559   \n",
       "44978   16.128083     0.205617               0.153798            0.138588   \n",
       "44980   16.275776     0.167361               0.178467            0.171480   \n",
       "44981   16.107573     0.117851               0.115771            0.120702   \n",
       "44983   27.117575     0.263690               0.236828            0.284380   \n",
       "44994    1.925450     0.034081               0.026401            0.039026   \n",
       "45402    6.221771     0.085732               0.080351            0.080170   \n",
       "\n",
       "                                                               \n",
       "      T=5 ResDense T=5 ResSWIM Grad-dense T=5 ResSWIM Grad-id  \n",
       "44957     0.044366               0.096211            0.066376  \n",
       "44959     0.021435               0.030333            0.026865  \n",
       "44960     0.051409               0.053225            0.065124  \n",
       "44963     1.076974               1.083936            1.082646  \n",
       "44964     0.369224               0.460022            0.444525  \n",
       "44965     0.031932               0.056503            0.153849  \n",
       "44969     0.220156               0.230138            0.257736  \n",
       "44970     0.042325               0.059595            0.045046  \n",
       "44971     0.145675               0.161961            0.142813  \n",
       "44972     0.040645               0.039347            0.033065  \n",
       "44973     0.193068               0.213386            0.195777  \n",
       "44975     1.486977               1.506756            1.528774  \n",
       "44976     0.933719               0.957782            0.945963  \n",
       "44977     0.365830               0.414740            0.354316  \n",
       "44978     0.118033               0.146801            0.135073  \n",
       "44980     0.211810               0.210039            0.224337  \n",
       "44981     0.131110               0.125640            0.119606  \n",
       "44983     0.206791               0.224624            0.219350  \n",
       "44994     0.051969               0.065887            0.047031  \n",
       "45402     0.078562               0.109594            0.108246  \n",
       "\n",
       "[20 rows x 68 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ids_not_categorical = list(df_metadata.query(\"has_categorical == False\").index.values)\n",
    "dataset_ids_not_categorical = sorted([int(x) for x in dataset_ids_not_categorical])\n",
    "run_all_experiments(dataset_ids_not_categorical, name_save=\"FIRSTBOOST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T=3 End2End                  0.440158\n",
       "StagewiseRandFeatBoost_15    0.445969\n",
       "StagewiseRandFeatBoost_20    0.450481\n",
       "StagewiseRandFeatBoost_10    0.451058\n",
       "StagewiseRandFeatBoost_5     0.478081\n",
       "StagewiseRandFeatBoost_25    0.480310\n",
       "T=5 ResSWIM Grad-dense       0.485768\n",
       "T=3 ResSWIM Grad-id          0.486900\n",
       "T=3 ResSWIM Grad-dense       0.487529\n",
       "T=5 ResSWIM Grad-id          0.489470\n",
       "T=1 Dense                    0.497886\n",
       "T=1 SWIM Grad                0.498991\n",
       "T=3 ResDense                 0.511270\n",
       "T=1 SWIM Unif                0.522699\n",
       "T=5 ResDense                 0.525264\n",
       "StagewiseRandFeatBoost_0     0.579274\n",
       "RidgeCV                      0.579533\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg = pd.read_pickle(\"OpenML_reg_FIRSTBOOST.pkl\")\n",
    "df_reg[\"RMSE_test\"].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StagewiseRandFeatBoost_20     4.60\n",
       "StagewiseRandFeatBoost_15     4.70\n",
       "StagewiseRandFeatBoost_25     5.20\n",
       "StagewiseRandFeatBoost_10     5.80\n",
       "StagewiseRandFeatBoost_5      6.20\n",
       "T=3 End2End                   6.70\n",
       "T=5 ResSWIM Grad-dense        8.35\n",
       "T=3 ResSWIM Grad-id           8.80\n",
       "T=1 Dense                     8.85\n",
       "T=3 ResSWIM Grad-dense        8.85\n",
       "T=5 ResSWIM Grad-id           9.70\n",
       "T=1 SWIM Grad                10.90\n",
       "T=3 ResDense                 11.25\n",
       "T=5 ResDense                 11.80\n",
       "T=1 SWIM Unif                12.00\n",
       "StagewiseRandFeatBoost_0     14.45\n",
       "RidgeCV                      14.85\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg[\"RMSE_test\"].rank(axis=1).mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T=3 End2End                  0.285152\n",
       "StagewiseRandFeatBoost_25    0.355267\n",
       "StagewiseRandFeatBoost_20    0.361087\n",
       "StagewiseRandFeatBoost_15    0.370432\n",
       "StagewiseRandFeatBoost_10    0.396441\n",
       "StagewiseRandFeatBoost_5     0.437691\n",
       "T=3 ResSWIM Grad-dense       0.457572\n",
       "T=5 ResSWIM Grad-dense       0.457998\n",
       "T=5 ResSWIM Grad-id          0.459707\n",
       "T=3 ResSWIM Grad-id          0.460334\n",
       "T=1 Dense                    0.471736\n",
       "T=1 SWIM Grad                0.476854\n",
       "T=3 ResDense                 0.480694\n",
       "T=5 ResDense                 0.489757\n",
       "T=1 SWIM Unif                0.499885\n",
       "StagewiseRandFeatBoost_0     0.568376\n",
       "RidgeCV                      0.569632\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg[\"RMSE_train\"].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StagewiseRandFeatBoost_25     2.05\n",
       "StagewiseRandFeatBoost_20     2.70\n",
       "StagewiseRandFeatBoost_15     3.95\n",
       "T=3 End2End                   4.05\n",
       "StagewiseRandFeatBoost_10     5.45\n",
       "StagewiseRandFeatBoost_5      6.95\n",
       "T=3 ResSWIM Grad-dense        9.50\n",
       "T=5 ResSWIM Grad-dense        9.65\n",
       "T=1 Dense                    10.00\n",
       "T=3 ResSWIM Grad-id          10.20\n",
       "T=5 ResSWIM Grad-id          10.60\n",
       "T=3 ResDense                 11.05\n",
       "T=5 ResDense                 11.25\n",
       "T=1 SWIM Grad                11.90\n",
       "T=1 SWIM Unif                12.75\n",
       "StagewiseRandFeatBoost_0     15.15\n",
       "RidgeCV                      15.80\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg[\"RMSE_train\"].rank(axis=1).mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT: implement boosting for the RandFeat models\n",
    "# ALSO: I should also do boosting for learned Nets ...\n",
    "\n",
    "\n",
    "\n",
    "#TODO NOTE NOTE next: add end2end and randfeatboost to regression models\n",
    "#          i might also need to implement the gradient approach before this?  maybe not.  at least do line search probabily"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
