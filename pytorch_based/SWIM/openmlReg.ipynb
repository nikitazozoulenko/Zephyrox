{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikita/Code/zephyrox/.conda/lib/python3.10/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import openml\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn.functional import relu\n",
    "from torch.nn.functional import tanh\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from aeon.regression.sklearn import RotationForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from aeon.datasets.tser_datasets import tser_soton\n",
    "from aeon.datasets import load_regression, load_classification\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from preprocessing.stream_transforms import normalize_mean_std_traindata, normalize_streams, augment_time, add_basepoint_zero\n",
    "from utils.utils import print_name, print_shape\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fetch the collection with ID 353\n",
    "# collection = openml.study.get_suite(353)\n",
    "# dataset_ids = collection.data\n",
    "# metadata_list = []\n",
    "\n",
    "# # Fetch and process each dataset\n",
    "# for i, dataset_id in enumerate(dataset_ids):\n",
    "#     dataset = openml.datasets.get_dataset(dataset_id)\n",
    "#     X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "#         target=dataset.default_target_attribute\n",
    "#     )\n",
    "#     X = np.array(X)\n",
    "#     y = np.array(y)[..., None]\n",
    "    \n",
    "#     # Extract the required metadata\n",
    "#     metadata = {\n",
    "#         'dataset_id': dataset.id,\n",
    "#         'name': dataset.name,\n",
    "#         'n_obs': int(dataset.qualities['NumberOfInstances']),\n",
    "#         'n_features': int(dataset.qualities['NumberOfFeatures']),\n",
    "#         '%_unique_y': len(np.unique(y))/len(y),\n",
    "#         'n_unique_y': len(np.unique(y)),\n",
    "#     }\n",
    "    \n",
    "#     metadata_list.append(metadata)\n",
    "#     print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset.id}: {dataset.name}\")\n",
    "\n",
    "# # Create a DataFrame from the metadata list\n",
    "# df_metadata = pd.DataFrame(metadata_list).sort_values('%_unique_y', ascending=False)\n",
    "# df_metadata.sort_values('%_unique_y', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_openml_dataset(dataset_id, \n",
    "                        normalize_X:bool = True,\n",
    "                        normalize_y:bool = True,\n",
    "                        train_test_size:float = 0.7,\n",
    "                        split_seed:int = 0) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # Fetch dataset from OpenML by its ID\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)[..., None]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_test_size, random_state=split_seed)\n",
    "\n",
    "    #normalize\n",
    "    if normalize_X:\n",
    "        X_train, X_test = normalize_mean_std_traindata(X_train, X_test)\n",
    "    if normalize_y:\n",
    "        y_train, y_test = normalize_mean_std_traindata(y_train, y_test)\n",
    "\n",
    "    return (Tensor(X_train.astype(np.float32)), \n",
    "            Tensor(X_test.astype(np.float32)), \n",
    "            Tensor(y_train.astype(np.float32)), \n",
    "            Tensor(y_test.astype(np.float32)))\n",
    "\n",
    "#dataset_id = 44971  # Replace with the dataset ID you want\n",
    "dataset_id = 44970\n",
    "X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Module for sampled networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "##### Base classes                                          #####\n",
    "##### - FittableModule: A nn.Module with .fit(X, y) support #####\n",
    "##### - ResNetBase: which interatively calls .fit(X, y)     #####\n",
    "#################################################################\n",
    "\n",
    "class FittableModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FittableModule, self).__init__()\n",
    "    \n",
    "\n",
    "    def fit(self, \n",
    "            X: Optional[Tensor] = None, \n",
    "            y: Optional[Tensor] = None,\n",
    "        ) -> Tuple[Optional[Tensor], Optional[Tensor]]:\n",
    "        \"\"\"Given neurons of the previous layer, and target labels, fit the \n",
    "        module. Returns the forwarded activations and labels [f(X), y].\n",
    "\n",
    "        Args:\n",
    "            X (Optional[Tensor]): Forward-propagated activations of training data, shape (N, d).\n",
    "            y (Optional[Tensor]): Training labels, shape (N, p).\n",
    "        \n",
    "        Returns:\n",
    "            Forwarded activations and labels [f(X), y].\n",
    "        \"\"\"\n",
    "        return self(X), y\n",
    "\n",
    "\n",
    "\n",
    "class ResNetBase(nn.Module):\n",
    "    def __init__(self,\n",
    "                upsample:FittableModule,\n",
    "                blocks:List[FittableModule],\n",
    "                output_layer:FittableModule,\n",
    "                ):\n",
    "        \"\"\"Residual Network base class, with fit method for non-SGD training/initialization.\n",
    "\n",
    "        Args:\n",
    "            upsample (FittableModule): _description_\n",
    "            blocks (List[FittableModule]): _description_\n",
    "            output_layer (FittableModule): _description_\n",
    "        \"\"\"\n",
    "        super(ResNetBase, self).__init__()\n",
    "        self.upsample = upsample\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "        self.output_layer = output_layer\n",
    "\n",
    "    \n",
    "    def fit(self, X:Tensor, y:Tensor):\n",
    "        # X shape (N, d)\n",
    "        # y shape (N, p)\n",
    "        X, y = self.upsample.fit(X, y)\n",
    "        for block in self.blocks:\n",
    "            X, y = block.fit(X, y)\n",
    "        X, y = self.output_layer.fit(X, y)\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        # x shape (N, d)\n",
    "        x = self.upsample(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([273, 3]) out torch.float32\n",
      "tensor([[ 1.0063e+00,  6.0632e-01, -1.3344e+00],\n",
      "        [-7.7373e-01,  2.5015e+00,  1.6009e+00],\n",
      "        [ 9.0851e-02,  1.0703e+00, -8.2686e-01],\n",
      "        [ 4.3493e-01,  1.8349e+00,  5.2403e-02],\n",
      "        [ 1.3343e+00,  7.0151e-01,  5.1928e-01],\n",
      "        [ 2.5770e+00,  4.4369e-01, -1.7169e+00],\n",
      "        [-4.1187e-01,  3.9454e-01, -3.6120e-01],\n",
      "        [-1.7308e-01,  1.0798e+00, -4.3126e-01],\n",
      "        [ 7.6029e-01,  7.0146e-02, -1.6973e+00],\n",
      "        [ 1.0815e+00,  2.5981e-03, -5.3142e-01],\n",
      "        [-9.2615e-01,  4.2799e-03,  2.0159e+00],\n",
      "        [ 1.1285e+00,  4.1362e-01,  1.4112e+00],\n",
      "        [-1.6260e+00,  1.5503e+00,  1.2666e+00],\n",
      "        [ 1.1246e+00,  6.6066e-01,  2.3194e+00],\n",
      "        [ 6.8546e-01,  1.1508e+00, -6.2143e-01],\n",
      "        [ 3.5718e-01,  3.8035e-01, -9.0341e-02],\n",
      "        [-2.5088e+00,  2.6201e+00,  3.6691e+00],\n",
      "        [ 1.2671e+00,  1.7701e+00, -9.2772e-01],\n",
      "        [-1.2412e+00,  1.9267e+00,  3.5902e-01],\n",
      "        [-1.4199e+00,  2.6209e-01,  3.8377e-01],\n",
      "        [ 1.4739e+00,  3.8779e-01,  4.7998e-01],\n",
      "        [-4.7118e-01, -2.1916e-01,  2.5017e-02],\n",
      "        [ 1.8244e+00,  1.2646e+00,  1.4898e+00],\n",
      "        [-9.5931e-02,  4.0271e-01, -8.3322e-01],\n",
      "        [ 3.0081e-01, -5.1546e-02, -7.6423e-02],\n",
      "        [ 5.2869e-01, -7.0923e-01, -7.8221e-01],\n",
      "        [-1.7132e-01,  2.0519e+00,  1.6108e+00],\n",
      "        [-1.3525e+00,  1.0700e+00,  2.5287e+00],\n",
      "        [ 2.0023e+00,  6.8920e-01, -7.3606e-01],\n",
      "        [ 8.0307e-01,  1.1304e+00, -2.5536e-01],\n",
      "        [-4.3621e-01, -2.9112e-01,  1.2964e+00],\n",
      "        [-5.1466e-01,  7.3381e-01,  7.1885e-01],\n",
      "        [-6.2423e-01,  6.9342e-01,  2.1425e+00],\n",
      "        [-8.4240e-01,  1.4385e+00, -4.8875e-01],\n",
      "        [-8.2978e-01,  9.3420e-01,  2.0235e+00],\n",
      "        [ 1.0113e+00,  3.7025e-01,  3.9068e-01],\n",
      "        [ 3.7799e-01,  2.4562e-01,  4.8072e-03],\n",
      "        [-1.7175e+00,  4.8626e-01,  1.7267e+00],\n",
      "        [-1.7894e-01,  1.5177e+00,  1.4022e+00],\n",
      "        [ 1.7649e+00,  8.9746e-01, -1.0848e+00],\n",
      "        [ 1.7879e+00, -1.0908e+00, -2.8341e+00],\n",
      "        [-3.1571e-01,  3.1620e+00,  1.8065e+00],\n",
      "        [ 5.5239e-01,  2.6505e+00,  1.0045e+00],\n",
      "        [ 6.1705e-01, -1.6285e-01, -3.0154e-01],\n",
      "        [ 2.3667e+00,  1.1291e+00, -5.4295e-01],\n",
      "        [ 7.1089e-01, -1.4119e-01, -5.0032e-01],\n",
      "        [-8.5738e-01,  1.8091e+00,  5.3956e-03],\n",
      "        [ 2.4984e+00,  5.7090e-01, -1.6310e+00],\n",
      "        [-2.2917e-01,  9.4192e-01, -4.4514e-01],\n",
      "        [ 1.2182e+00,  5.1022e-05,  2.2184e-01],\n",
      "        [-8.5825e-01, -4.2408e-02,  2.8638e-01],\n",
      "        [-1.3522e-01, -2.0206e-01, -4.6432e-01],\n",
      "        [ 1.5301e+00,  1.8762e+00,  7.0370e-01],\n",
      "        [ 1.2120e-01,  1.1339e+00,  7.8190e-01],\n",
      "        [-4.1271e-01,  1.2982e+00, -4.6664e-01],\n",
      "        [ 2.3026e-01,  5.1188e-01,  6.7629e-01],\n",
      "        [ 1.9195e-01, -1.3388e-01,  7.7230e-01],\n",
      "        [ 3.7084e-01, -3.3841e-01, -1.1383e+00],\n",
      "        [ 1.2440e+00,  1.5910e+00, -2.0696e-01],\n",
      "        [ 2.0112e+00,  2.6454e-01, -8.9336e-01],\n",
      "        [ 1.1755e-01, -2.0084e-01, -8.1114e-01],\n",
      "        [ 3.1907e+00, -1.1372e-01, -3.4857e+00],\n",
      "        [ 1.1857e+00,  9.5301e-01,  6.4277e-03],\n",
      "        [ 2.0628e+00,  1.0674e+00, -1.4252e+00],\n",
      "        [ 6.0515e-01,  1.9185e-01, -9.9621e-01],\n",
      "        [ 1.4068e-01,  7.2070e-01, -1.1925e+00],\n",
      "        [ 1.0547e-01,  3.5248e-01, -8.9632e-01],\n",
      "        [ 4.2625e-01, -3.7828e-01, -1.2708e+00],\n",
      "        [ 1.2925e+00, -8.5087e-02, -1.0538e+00],\n",
      "        [-6.1037e-01, -3.1923e-01, -4.7591e-01],\n",
      "        [ 1.7125e+00,  1.2809e+00,  2.2237e+00],\n",
      "        [ 2.2908e+00,  1.1143e+00, -2.7952e-01],\n",
      "        [ 2.6655e+00, -8.7779e-01, -3.1039e+00],\n",
      "        [ 1.4178e+00, -4.1669e-02, -1.8585e+00],\n",
      "        [-5.3628e-01,  2.0684e+00,  5.3504e-01],\n",
      "        [-6.9809e-01,  1.3897e+00, -6.7609e-02],\n",
      "        [ 8.4247e-01,  4.5651e-01, -1.7023e+00],\n",
      "        [ 1.5272e+00,  1.6215e-01, -4.6746e-01],\n",
      "        [-7.7125e-01,  8.7054e-01,  4.8191e-01],\n",
      "        [-2.9442e-01,  3.8069e-01, -4.5629e-01],\n",
      "        [-1.8026e+00,  2.1352e+00,  1.6587e+00],\n",
      "        [-2.9653e+00,  1.7325e+00,  2.2746e+00],\n",
      "        [-1.7371e-01,  1.7734e+00,  8.6039e-01],\n",
      "        [ 1.5555e-01, -3.7805e-01, -8.8411e-01],\n",
      "        [-1.4959e+00,  1.0016e+00,  5.6141e-01],\n",
      "        [-1.2533e+00,  1.1551e-01,  1.2170e+00],\n",
      "        [ 1.7444e+00,  2.9166e-01,  1.3750e-01],\n",
      "        [ 9.2281e-02,  1.0698e+00,  1.3584e+00],\n",
      "        [-2.1162e-01,  1.4412e+00,  1.4838e+00],\n",
      "        [-1.0227e+00,  1.2507e+00, -2.2136e-02],\n",
      "        [ 8.6752e-01,  2.6935e-01, -4.1614e-01],\n",
      "        [ 1.3508e+00, -3.4442e-01,  1.0471e-01],\n",
      "        [-1.8402e+00, -2.0990e-01,  1.5640e+00],\n",
      "        [ 2.7080e+00,  6.2389e-02, -2.8457e+00],\n",
      "        [-4.7131e-01,  1.4665e+00,  1.3102e+00],\n",
      "        [ 5.2598e-01,  7.3233e-01, -8.3860e-01],\n",
      "        [ 7.6010e-01,  1.1933e-01,  2.7707e-01],\n",
      "        [ 7.7529e-02, -2.5320e-02,  8.2056e-01],\n",
      "        [ 4.3612e-01,  2.7830e-01, -4.2741e-01],\n",
      "        [ 1.4098e+00,  1.5381e+00, -1.3344e+00],\n",
      "        [-1.1528e+00,  1.5133e+00,  3.2007e-01],\n",
      "        [-1.0021e+00,  1.8563e+00,  1.2463e+00],\n",
      "        [-1.2614e+00,  8.7410e-01,  1.0997e+00],\n",
      "        [ 1.5397e+00,  4.0997e-01, -5.5982e-01],\n",
      "        [ 1.9037e-01,  1.0908e+00, -1.4192e+00],\n",
      "        [ 3.9814e-01,  5.4015e-01, -4.5839e-01],\n",
      "        [ 1.8036e+00,  5.0901e-01, -1.9731e-01],\n",
      "        [-1.1926e+00,  1.5857e+00,  2.3692e+00],\n",
      "        [ 9.3838e-01,  9.3076e-03, -1.8590e+00],\n",
      "        [ 1.0854e+00,  1.5391e+00, -1.8727e+00],\n",
      "        [ 4.7140e-01,  6.1975e-01, -5.9412e-01],\n",
      "        [-1.2405e+00,  2.2459e+00,  2.1405e+00],\n",
      "        [ 1.0311e+00,  1.0240e+00, -1.4456e+00],\n",
      "        [ 5.9040e-01,  1.1373e+00,  1.4877e+00],\n",
      "        [-2.2111e-01, -6.9129e-01, -9.5597e-01],\n",
      "        [-7.7125e-01,  8.7054e-01,  4.8191e-01],\n",
      "        [-7.2031e-02,  1.0621e+00,  1.7215e+00],\n",
      "        [ 9.8183e-01,  2.2968e-01, -1.8540e+00],\n",
      "        [ 4.5608e-01,  5.3069e-01,  4.8783e-01],\n",
      "        [ 1.6605e+00,  3.2755e-02, -9.7640e-01],\n",
      "        [-3.2943e-01, -1.6499e-01,  5.1166e-01],\n",
      "        [ 8.8306e-01,  6.2478e-01, -1.6816e+00],\n",
      "        [ 1.3708e+00, -1.7771e-02, -3.4897e-01],\n",
      "        [-9.0769e-02, -1.1920e-01,  3.2456e-01],\n",
      "        [ 2.2859e-01, -5.6517e-01, -1.1002e+00],\n",
      "        [ 2.8308e-01, -1.2500e-01, -1.9537e-01],\n",
      "        [ 2.0270e+00, -6.2410e-01, -7.8988e-01],\n",
      "        [ 7.8817e-01,  7.9839e-01, -4.6209e-01],\n",
      "        [-8.6976e-01,  5.2182e-01,  2.4297e+00],\n",
      "        [ 5.7984e-01,  3.2908e-01,  5.1169e-01],\n",
      "        [-1.3184e+00,  1.7349e+00,  1.1772e+00],\n",
      "        [-1.7624e+00,  1.8801e+00,  1.1300e+00],\n",
      "        [-5.5261e-01, -1.9677e-01,  1.7070e+00],\n",
      "        [-1.0414e+00,  7.8856e-01,  1.1238e+00],\n",
      "        [-1.3632e+00,  1.3720e+00,  2.2185e+00],\n",
      "        [-4.6494e-01,  1.6570e-01,  4.7993e-01],\n",
      "        [-3.6031e-01,  8.0889e-01, -5.1748e-01],\n",
      "        [ 1.2136e+00,  4.4449e-01,  1.3550e-01],\n",
      "        [ 2.4876e-01,  7.7401e-01, -1.1706e+00],\n",
      "        [ 3.2382e+00, -2.7947e-01, -3.4615e+00],\n",
      "        [ 1.4480e+00,  4.2204e-01, -2.4986e+00],\n",
      "        [ 1.3057e+00,  3.0122e-01,  5.5293e-01],\n",
      "        [ 2.0561e+00,  4.0117e-01, -9.8425e-01],\n",
      "        [ 1.7820e-01, -1.5526e-01, -9.6799e-02],\n",
      "        [ 7.9480e-01,  4.3154e-02, -9.0511e-01],\n",
      "        [-2.2534e-01,  1.0438e+00,  1.5063e+00],\n",
      "        [ 9.2840e-01, -1.0997e-01, -1.0890e+00],\n",
      "        [ 9.1755e-01,  1.3327e+00,  1.5266e+00],\n",
      "        [-2.8722e-01, -3.9213e-01,  2.8284e+00],\n",
      "        [-4.4906e-01,  2.0231e+00,  6.0904e-01],\n",
      "        [-1.0408e+00,  2.8008e-01, -5.2067e-02],\n",
      "        [ 1.2051e+00,  2.8808e-01, -1.7464e-01],\n",
      "        [-2.7332e+00,  1.1708e+00,  3.3179e+00],\n",
      "        [-5.2299e-01, -5.7001e-01, -8.9461e-02],\n",
      "        [-7.6268e-01, -6.8267e-01, -3.9610e-01],\n",
      "        [ 1.0302e+00, -6.3042e-02, -1.3416e+00],\n",
      "        [ 6.2739e-01,  2.0181e+00,  1.5425e-01],\n",
      "        [ 2.6676e-02, -3.3189e-02,  2.8705e-01],\n",
      "        [ 8.6828e-01,  2.5209e-01,  1.5181e-01],\n",
      "        [-1.8359e+00,  2.2339e+00,  1.9557e+00],\n",
      "        [ 1.0494e+00,  2.0240e-01,  7.8453e-01],\n",
      "        [ 4.5779e-01, -1.2838e-01, -3.7938e-01],\n",
      "        [-4.5679e-01,  8.0398e-01, -5.2972e-01],\n",
      "        [-9.9185e-01,  9.9497e-01,  4.3812e-01],\n",
      "        [ 1.2609e+00,  9.1280e-01, -1.5405e+00],\n",
      "        [-4.3907e-02, -5.6642e-01, -7.1656e-01],\n",
      "        [-9.9670e-01,  2.3663e+00,  1.0459e+00],\n",
      "        [ 4.7662e-01,  2.8494e-01, -6.3008e-01],\n",
      "        [-4.7881e-01,  9.5087e-02, -3.8194e-01],\n",
      "        [-5.9495e-01,  1.4206e+00, -5.1979e-01],\n",
      "        [ 2.9469e+00,  3.7972e-02, -2.4964e+00],\n",
      "        [ 1.3162e+00,  1.7527e-01, -2.4633e-01],\n",
      "        [ 2.9564e+00,  3.2213e-01, -2.6738e+00],\n",
      "        [-1.1962e+00,  4.3452e-01,  5.2928e-01],\n",
      "        [ 4.0282e-01,  2.9066e-01,  8.9215e-01],\n",
      "        [ 7.6029e-01,  7.0146e-02, -1.6973e+00],\n",
      "        [-9.5865e-01,  1.1526e+00,  3.3400e-01],\n",
      "        [ 1.0248e+00,  1.0740e+00,  2.5646e+00],\n",
      "        [ 9.1724e-01,  5.9957e-02, -5.0434e-01],\n",
      "        [-1.6457e+00,  1.8867e+00,  8.5491e-01],\n",
      "        [ 4.5803e-01,  5.5618e-01, -1.3430e+00],\n",
      "        [-1.3306e-01,  1.2379e+00, -1.2059e-01],\n",
      "        [-4.2697e+00,  3.3075e+00,  3.8688e+00],\n",
      "        [ 1.0842e+00,  1.9789e-01, -2.2549e-01],\n",
      "        [-1.2614e+00,  8.7410e-01,  1.0997e+00],\n",
      "        [ 4.3255e-01,  9.6945e-02, -1.4086e-01],\n",
      "        [ 4.3376e-01,  1.6456e+00,  1.1557e+00],\n",
      "        [ 1.8806e+00, -1.9706e-02, -2.5383e+00],\n",
      "        [-8.9698e-01,  1.5192e+00, -2.6286e-02],\n",
      "        [ 2.2995e+00,  1.1584e-01, -1.5327e+00],\n",
      "        [ 9.8119e-02,  3.7368e-01,  1.2866e+00],\n",
      "        [ 1.8143e+00,  4.2420e-01, -6.5735e-01],\n",
      "        [ 9.8689e-01, -1.1634e-01, -7.6315e-01],\n",
      "        [-2.3444e-01, -3.0790e-01, -9.1646e-01],\n",
      "        [ 5.0181e-01,  4.5790e-01, -1.3504e+00],\n",
      "        [ 1.8891e+00,  7.2012e-01, -2.1784e+00],\n",
      "        [ 1.6079e-01,  9.3523e-01,  1.0311e-01],\n",
      "        [ 1.0624e+00,  3.1282e-01, -1.4130e+00],\n",
      "        [ 5.3806e-01, -1.8641e-01, -1.1586e+00],\n",
      "        [ 2.9441e-01,  1.5791e+00, -4.0063e-01],\n",
      "        [ 1.9496e+00,  4.0449e-01, -2.0052e+00],\n",
      "        [-1.9763e+00,  2.6815e+00,  3.2403e+00],\n",
      "        [ 1.6575e+00, -1.6690e-01, -2.0048e+00],\n",
      "        [ 1.5555e-01, -3.7805e-01, -8.8411e-01],\n",
      "        [-9.7476e-01,  1.5490e+00,  1.1005e+00],\n",
      "        [ 4.8077e-01,  1.4186e+00,  1.1204e-01],\n",
      "        [-1.3232e-01,  1.0114e+00, -4.3613e-01],\n",
      "        [ 1.6376e+00, -4.4895e-02, -1.3798e+00],\n",
      "        [-2.2917e-01,  9.4192e-01, -4.4514e-01],\n",
      "        [ 4.2625e-01, -3.7828e-01, -1.2708e+00],\n",
      "        [ 1.3029e+00, -7.8276e-02, -8.7983e-01],\n",
      "        [-5.2332e-01,  4.9208e-01,  1.7365e+00],\n",
      "        [-3.5614e-01,  2.2920e-01,  1.2768e+00],\n",
      "        [-2.5453e-01, -4.0905e-01, -2.3391e-01],\n",
      "        [ 2.3054e-01,  8.3162e-01, -1.2027e+00],\n",
      "        [ 5.3154e-01, -5.6445e-01, -1.5527e+00],\n",
      "        [ 1.5609e+00,  1.0432e+00,  3.9821e-01],\n",
      "        [ 2.1320e+00,  4.2771e-02, -2.4605e+00],\n",
      "        [-2.2597e+00,  2.2024e+00,  2.4451e+00],\n",
      "        [-9.8820e-02,  2.9308e-01,  9.2332e-01],\n",
      "        [-5.4179e-01,  2.3926e-01, -5.7754e-01],\n",
      "        [-4.3907e-02, -5.6642e-01, -7.1656e-01],\n",
      "        [ 7.2118e-01,  2.0831e-01,  9.5521e-01],\n",
      "        [-1.4199e+00,  2.6209e-01,  3.8377e-01],\n",
      "        [-2.7320e-01, -1.2413e-01,  4.1506e-03],\n",
      "        [ 1.2467e+00,  2.0118e+00, -2.6633e-01],\n",
      "        [ 1.6100e-01, -2.8036e-01, -4.1677e-01],\n",
      "        [ 1.2877e+00,  9.9115e-01, -7.0724e-01],\n",
      "        [-6.7311e-01,  2.1358e+00,  1.7923e+00],\n",
      "        [-8.5738e-01,  1.8091e+00,  5.3956e-03],\n",
      "        [-5.6742e-01,  1.9980e-01,  1.4842e+00],\n",
      "        [ 1.4633e+00,  1.6650e+00, -7.0228e-01],\n",
      "        [ 2.4484e+00,  6.1003e-01, -1.8539e-01],\n",
      "        [ 1.3375e+00,  9.7275e-01,  8.3237e-01],\n",
      "        [-3.2929e-01, -7.0724e-01, -3.6731e-01],\n",
      "        [ 9.8689e-01, -1.1634e-01, -7.6315e-01],\n",
      "        [ 4.0282e-01,  2.9066e-01,  8.9215e-01],\n",
      "        [ 1.9952e-01,  4.5581e-01, -9.0748e-01],\n",
      "        [-6.7826e-01,  1.8202e+00,  8.5908e-01],\n",
      "        [-1.3232e-01,  1.0114e+00, -4.3613e-01],\n",
      "        [ 1.1260e+00, -4.0188e-01, -4.1249e-01],\n",
      "        [ 5.6622e-02,  1.6757e-01,  9.4134e-01],\n",
      "        [ 5.4343e-01, -2.6480e-01, -5.6382e-01],\n",
      "        [ 1.2616e+00, -3.3674e-02, -1.4362e+00],\n",
      "        [ 1.9667e+00,  1.5684e+00, -9.9322e-01],\n",
      "        [ 2.2760e+00,  9.0202e-01, -2.6325e-01],\n",
      "        [ 1.4366e-01,  1.0093e+00, -8.2575e-01],\n",
      "        [-1.0605e+00, -3.4884e-02,  1.2407e+00],\n",
      "        [-6.0798e-01,  2.4214e+00,  3.9096e+00],\n",
      "        [ 4.5103e-02,  2.2009e-01,  3.0266e-01],\n",
      "        [-1.1399e+00,  5.4184e-01,  8.8100e-01],\n",
      "        [-1.7062e+00,  1.1709e+00,  8.8661e-01],\n",
      "        [ 6.6291e-01, -3.5662e-01, -1.7320e+00],\n",
      "        [ 1.1782e+00, -1.6232e-01, -5.7270e-01],\n",
      "        [ 1.8741e+00,  1.1220e+00, -1.1433e+00],\n",
      "        [ 4.0854e-01,  1.0382e+00, -8.1494e-01],\n",
      "        [ 9.4769e-01,  3.7304e-01,  9.4772e-01],\n",
      "        [ 2.0478e-01,  5.4883e-01,  1.1472e+00],\n",
      "        [-4.8028e-01,  2.8620e-01, -2.5750e-01],\n",
      "        [ 4.8077e-01,  1.4186e+00,  1.1204e-01],\n",
      "        [ 1.0547e-01,  3.5248e-01, -8.9632e-01],\n",
      "        [-6.4595e-01,  1.0383e+00, -2.2861e-01],\n",
      "        [ 1.6213e+00,  1.0829e+00,  1.3659e+00],\n",
      "        [ 2.3294e+00,  1.1828e+00,  1.0947e+00],\n",
      "        [-1.2412e+00,  1.9267e+00,  3.5902e-01],\n",
      "        [ 1.2965e+00,  4.3482e-01, -9.8788e-01],\n",
      "        [ 1.0302e+00, -6.3042e-02, -1.3416e+00],\n",
      "        [ 2.7578e+00, -2.1792e-01, -3.4126e+00],\n",
      "        [-4.2867e-01,  6.0655e-01,  2.5447e+00],\n",
      "        [-4.0625e-01,  1.0746e+00, -5.1980e-01],\n",
      "        [-1.0190e+00, -6.5531e-01,  7.5141e-02],\n",
      "        [-3.8966e-01,  1.4970e+00, -3.2598e-01],\n",
      "        [ 1.4893e-01,  8.0732e-01,  4.7103e-02]], grad_fn=<AddmmBackward0>) \n",
      "\n",
      "Dense(\n",
      "  (dense): Linear(in_features=6, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "######## Dense Layer ########\n",
    "#############################\n",
    "\n",
    "\n",
    "class Dense(FittableModule):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 in_dim: int,\n",
    "                 out_dim: int,\n",
    "                 ):\n",
    "        \"\"\"Dense MLP layer with LeCun weight initialization,\n",
    "        Gaussan bias initialization.\"\"\"\n",
    "        super(Dense, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.dense = nn.Linear(in_dim, out_dim)\n",
    "    \n",
    "    def fit(self, X:Tensor, y:Tensor):\n",
    "        with torch.no_grad():\n",
    "            nn.init.normal_(self.dense.weight, mean=0, std=self.in_dim**-0.5, generator=self.generator)\n",
    "            nn.init.normal_(self.dense.bias, mean=0, std=self.in_dim**-0.5, generator=self.generator)\n",
    "            return self(X), y\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.dense(X)\n",
    "    \n",
    "\n",
    "class Identity(FittableModule):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    \n",
    "    def fit(self, X:Tensor, y:Tensor):\n",
    "        return X, y\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return X\n",
    "\n",
    "\n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator().manual_seed(0)\n",
    "net = Dense(g1, D, 3)\n",
    "net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print_name(out)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([273, 3]) out torch.float32\n",
      "tensor([[ 3.3456e-01, -2.2509e-01,  1.5428e-01],\n",
      "        [-1.5937e-01, -2.1131e-01,  5.6211e-01],\n",
      "        [ 3.1890e-01, -3.4543e-01,  4.5053e-01],\n",
      "        [-6.3202e-02, -2.9029e-01,  1.0104e+00],\n",
      "        [ 1.4667e-01,  3.2821e-01,  3.7209e-01],\n",
      "        [ 4.2502e-01,  5.4385e-01,  6.1908e-01],\n",
      "        [ 5.0000e-01, -3.7438e-01, -1.7110e-01],\n",
      "        [ 3.0951e-01, -3.5543e-01,  3.0490e-01],\n",
      "        [ 5.6117e-01, -1.8869e-01,  2.8079e-01],\n",
      "        [ 3.5847e-01,  1.4138e-02,  3.2554e-01],\n",
      "        [ 1.2324e-01, -5.1429e-01, -4.1025e-01],\n",
      "        [-1.8248e-01, -8.1484e-02,  6.2416e-01],\n",
      "        [ 1.7651e-01, -5.7704e-01, -1.1708e-01],\n",
      "        [-7.4602e-01, -5.1382e-01,  1.9618e+00],\n",
      "        [ 2.7526e-01, -1.4222e-01,  2.0107e-01],\n",
      "        [ 4.2758e-01,  3.0626e-02, -7.8444e-02],\n",
      "        [-4.3642e-01, -9.2550e-01,  3.6025e-01],\n",
      "        [ 1.0645e-01,  6.3015e-02,  9.9766e-01],\n",
      "        [ 1.4542e-01, -6.9116e-01,  3.0739e-01],\n",
      "        [ 5.3052e-01, -5.9615e-01, -5.5975e-01],\n",
      "        [ 2.3023e-01,  4.0692e-01,  1.9492e-01],\n",
      "        [ 6.0459e-01, -2.3536e-01, -5.4600e-01],\n",
      "        [-3.8673e-01,  2.4632e-01,  1.3182e+00],\n",
      "        [ 5.0965e-01, -3.6426e-01,  4.0302e-03],\n",
      "        [ 5.3517e-01,  5.2121e-02, -3.2912e-01],\n",
      "        [ 6.7228e-01, -1.5893e-01, -8.5993e-01],\n",
      "        [-3.0524e-01, -4.0996e-01,  9.5683e-01],\n",
      "        [-1.2468e-01, -6.6775e-01, -7.9507e-02],\n",
      "        [ 3.3084e-01,  5.3302e-01,  4.2920e-01],\n",
      "        [ 1.0033e-01, -1.4424e-01,  7.7882e-01],\n",
      "        [ 5.4461e-01,  1.2234e-01, -9.1408e-01],\n",
      "        [ 3.7535e-01, -1.6820e-01, -3.3246e-01],\n",
      "        [-5.4264e-02, -3.2374e-01,  2.1263e-01],\n",
      "        [ 2.6926e-01, -6.9364e-01,  3.9259e-01],\n",
      "        [ 1.0088e-01, -2.2435e-01, -1.7881e-01],\n",
      "        [ 2.4945e-01,  1.8820e-01,  1.8257e-01],\n",
      "        [ 3.0488e-01, -1.6986e-01,  2.1195e-01],\n",
      "        [ 4.2019e-01, -3.9204e-01, -8.5826e-01],\n",
      "        [-8.5495e-03, -1.6923e-01,  3.1517e-01],\n",
      "        [ 2.6429e-01,  3.2422e-01,  7.4371e-01],\n",
      "        [ 7.3483e-01, -3.0611e-01, -6.3400e-01],\n",
      "        [-2.2427e-01, -3.9394e-02,  5.5278e-01],\n",
      "        [-1.3305e-01,  1.7504e-01,  7.1518e-01],\n",
      "        [ 5.7085e-01,  1.3790e-01, -3.1865e-01],\n",
      "        [ 2.3900e-01,  6.9247e-01,  5.4062e-01],\n",
      "        [ 5.4067e-01,  3.0906e-02, -4.1909e-01],\n",
      "        [ 1.7193e-01, -6.0806e-01,  4.0158e-01],\n",
      "        [ 3.9335e-01,  5.2041e-01,  6.5396e-01],\n",
      "        [ 3.5515e-01, -3.7066e-01,  1.9997e-01],\n",
      "        [ 1.4966e-01,  2.5217e-02,  5.5867e-01],\n",
      "        [ 5.3786e-01, -4.4268e-01, -7.6342e-01],\n",
      "        [ 6.1334e-01, -2.2224e-01, -3.6220e-01],\n",
      "        [ 3.9400e-02,  5.8858e-01,  4.6298e-01],\n",
      "        [ 7.5129e-02, -1.6345e-01,  4.0211e-01],\n",
      "        [ 2.6207e-01, -5.8404e-01,  1.5311e-01],\n",
      "        [ 2.0675e-01, -8.1747e-02,  1.6344e-01],\n",
      "        [ 3.7330e-01, -1.1416e-02, -2.6109e-01],\n",
      "        [ 6.6046e-01, -1.6983e-01, -1.8593e-01],\n",
      "        [-4.8608e-04,  8.7921e-03,  9.7601e-01],\n",
      "        [ 2.6567e-01,  1.9600e-01,  4.3685e-01],\n",
      "        [ 6.1931e-01, -2.0535e-01, -2.2955e-01],\n",
      "        [ 5.5924e-01,  2.1027e-01,  5.4298e-01],\n",
      "        [ 7.0855e-02,  1.4208e-02,  5.0622e-01],\n",
      "        [ 1.5217e-01,  8.9887e-02,  1.1424e+00],\n",
      "        [ 5.1406e-01, -8.3772e-02,  9.3460e-02],\n",
      "        [ 4.4034e-01, -3.8846e-01,  3.1117e-01],\n",
      "        [ 5.0424e-01, -2.8842e-01,  5.4709e-02],\n",
      "        [ 6.6875e-01, -1.7644e-01, -1.4616e-01],\n",
      "        [ 5.3325e-01,  1.2844e-01, -1.6739e-01],\n",
      "        [ 6.5726e-01, -4.1663e-01, -4.6457e-01],\n",
      "        [-4.1398e-01,  3.8889e-01,  1.0753e+00],\n",
      "        [ 1.3848e-01,  5.4877e-01,  1.7933e-01],\n",
      "        [ 6.7434e-01, -2.3870e-02, -3.7765e-01],\n",
      "        [ 5.8687e-01,  5.9169e-02,  2.9113e-01],\n",
      "        [ 7.9770e-02, -3.5782e-01,  3.9652e-01],\n",
      "        [ 2.6823e-01, -5.1797e-01,  2.1890e-01],\n",
      "        [ 4.4845e-01, -2.8692e-01,  2.7817e-01],\n",
      "        [ 3.0979e-01,  2.0482e-01,  4.1219e-01],\n",
      "        [ 3.3941e-01, -3.5083e-01, -1.4478e-01],\n",
      "        [ 4.9924e-01, -3.4734e-01, -1.2562e-01],\n",
      "        [ 2.4600e-02, -6.0670e-01,  6.2226e-02],\n",
      "        [ 1.6991e-01, -9.0631e-01, -5.6161e-01],\n",
      "        [-9.3800e-02, -3.2886e-01,  7.5993e-01],\n",
      "        [ 6.6118e-01, -1.9066e-01, -2.9165e-01],\n",
      "        [ 3.3600e-01, -6.5298e-01, -1.8753e-01],\n",
      "        [ 4.9884e-01, -2.8942e-01, -8.0778e-01],\n",
      "        [ 9.5553e-02,  1.9600e-01,  7.0412e-01],\n",
      "        [-9.5929e-02, -2.6448e-01,  6.1261e-01],\n",
      "        [ 1.7167e-01,  9.1641e-02, -1.8650e-01],\n",
      "        [ 3.1538e-01, -6.3159e-01,  8.5042e-02],\n",
      "        [ 2.9727e-01, -7.3139e-02,  4.1201e-01],\n",
      "        [ 2.1810e-01, -9.7644e-03,  1.9306e-01],\n",
      "        [ 5.9482e-01, -4.1866e-01, -1.1849e+00],\n",
      "        [ 5.8120e-01,  3.3877e-01,  7.1610e-01],\n",
      "        [-1.8774e-02, -3.0917e-01,  3.9497e-01],\n",
      "        [ 3.6793e-01, -2.2389e-01,  9.3314e-02],\n",
      "        [ 2.8490e-01, -1.6312e-02, -1.0137e-01],\n",
      "        [ 5.2077e-01,  1.8689e-01, -6.8200e-01],\n",
      "        [ 4.7988e-01, -1.5836e-02, -6.8167e-02],\n",
      "        [ 3.1521e-02, -2.0830e-01,  1.3826e+00],\n",
      "        [ 2.5103e-01, -6.2409e-01,  8.1922e-02],\n",
      "        [ 6.1164e-02, -3.4349e-01,  1.7704e-01],\n",
      "        [ 3.3122e-01, -3.9875e-01, -3.8897e-01],\n",
      "        [ 2.4824e-01,  1.6234e-01,  5.9244e-01],\n",
      "        [ 3.6101e-01, -4.6300e-01,  5.8209e-01],\n",
      "        [ 2.7134e-01, -3.1346e-01,  4.6446e-01],\n",
      "        [ 2.2301e-01,  3.5784e-01,  4.9066e-01],\n",
      "        [-5.2878e-02, -3.5286e-01,  1.6191e-02],\n",
      "        [ 5.5465e-01, -2.4284e-01,  1.0788e-01],\n",
      "        [ 2.5563e-01, -2.4498e-01,  1.0118e+00],\n",
      "        [ 4.1187e-01, -7.8732e-02,  1.4814e-01],\n",
      "        [-2.1053e-01, -5.9283e-01,  1.9895e-01],\n",
      "        [ 3.3664e-01, -1.0293e-01,  6.7207e-01],\n",
      "        [-1.4392e-01, -2.3459e-02,  6.8352e-01],\n",
      "        [ 7.5634e-01, -3.4019e-01, -4.8632e-01],\n",
      "        [ 3.3941e-01, -3.5083e-01, -1.4478e-01],\n",
      "        [ 2.0211e-01,  2.5565e-01, -3.1840e-01],\n",
      "        [ 4.8906e-01, -2.4329e-01,  2.6176e-01],\n",
      "        [ 1.6426e-01, -2.2469e-01, -1.7734e-01],\n",
      "        [ 2.1720e-01, -2.2824e-01, -1.6073e-01],\n",
      "        [ 5.8229e-01, -5.4339e-02, -7.0271e-01],\n",
      "        [ 3.9500e-01, -2.7942e-01,  3.9815e-01],\n",
      "        [ 3.5804e-01,  1.8615e-01,  2.4910e-01],\n",
      "        [ 3.9225e-01, -2.5027e-01, -1.2214e-01],\n",
      "        [ 7.2448e-01, -1.9913e-01, -3.5257e-01],\n",
      "        [ 4.0214e-01, -2.2627e-01,  7.5223e-02],\n",
      "        [ 2.3394e-01, -1.1322e-01,  3.6395e-02],\n",
      "        [ 3.6568e-01,  7.2252e-02,  1.9523e-01],\n",
      "        [ 2.1663e-02, -3.4078e-01, -1.0620e-01],\n",
      "        [ 4.2163e-01,  2.8690e-01, -3.1665e-01],\n",
      "        [ 1.2933e-01, -4.8758e-01,  2.8726e-02],\n",
      "        [ 1.5217e-01, -7.0822e-01, -3.9195e-02],\n",
      "        [ 1.7860e-01, -4.1687e-01, -4.0642e-01],\n",
      "        [ 1.7695e-01, -5.3585e-01,  1.6015e-02],\n",
      "        [ 9.5856e-03, -4.4420e-01, -6.5390e-02],\n",
      "        [ 3.3841e-01, -3.9809e-01, -7.6968e-02],\n",
      "        [ 3.9878e-01, -4.3308e-01,  1.2600e-01],\n",
      "        [ 3.9355e-01,  4.4705e-01, -9.1760e-02],\n",
      "        [ 4.0266e-01, -3.3954e-01,  4.0282e-01],\n",
      "        [ 5.5706e-01,  1.6127e-01,  2.9384e-01],\n",
      "        [ 4.6580e-01, -2.3329e-01,  5.7803e-01],\n",
      "        [ 2.4380e-01,  3.6377e-01,  1.3817e-01],\n",
      "        [ 2.6807e-01,  2.7052e-01,  7.1881e-01],\n",
      "        [ 5.8756e-01,  2.0816e-03, -4.5628e-01],\n",
      "        [ 3.7350e-01, -2.1013e-01,  4.3944e-01],\n",
      "        [ 2.5510e-01,  1.3177e-01, -3.7595e-01],\n",
      "        [ 4.1705e-01, -1.8670e-01,  4.1648e-01],\n",
      "        [-1.8737e-01,  1.0557e-01,  7.6046e-01],\n",
      "        [-1.5372e-01, -4.8301e-01,  9.1753e-03],\n",
      "        [ 7.6721e-02, -2.9588e-01,  3.8012e-01],\n",
      "        [ 5.3235e-01, -5.5033e-01, -3.7938e-01],\n",
      "        [ 2.8128e-01,  1.3138e-01,  3.4876e-01],\n",
      "        [ 7.1201e-02, -7.2285e-01, -6.8711e-01],\n",
      "        [ 7.0825e-01, -2.5463e-01, -7.4232e-01],\n",
      "        [ 7.5552e-01, -4.2625e-01, -7.2741e-01],\n",
      "        [ 5.8023e-01,  3.1591e-02,  9.0009e-02],\n",
      "        [ 9.6117e-02,  4.1132e-02,  5.1783e-01],\n",
      "        [ 5.3629e-01,  2.7268e-02, -4.9293e-01],\n",
      "        [ 2.8543e-01,  7.6859e-02,  2.0141e-01],\n",
      "        [ 9.8701e-03, -5.5497e-01, -4.0275e-02],\n",
      "        [ 1.0711e-01,  7.8195e-02,  4.0535e-01],\n",
      "        [ 5.8516e-01,  4.4595e-02, -3.3146e-01],\n",
      "        [ 4.0696e-01, -4.7737e-01,  1.0862e-01],\n",
      "        [ 3.4338e-01, -4.7137e-01, -1.5654e-01],\n",
      "        [ 3.6005e-01, -1.8902e-02,  6.6197e-01],\n",
      "        [ 7.1735e-01, -2.1475e-01, -4.9783e-01],\n",
      "        [ 7.7491e-03, -4.5022e-01,  3.3797e-01],\n",
      "        [ 3.2048e-01, -2.9817e-01,  4.3672e-01],\n",
      "        [ 5.4947e-01, -3.7632e-01, -2.5788e-01],\n",
      "        [ 2.6608e-01, -5.9433e-01,  4.1722e-01],\n",
      "        [ 3.4929e-01,  1.9824e-01,  9.2470e-01],\n",
      "        [ 2.7723e-01,  7.8195e-02,  1.3807e-01],\n",
      "        [ 4.6425e-01,  3.7269e-01,  6.6845e-01],\n",
      "        [ 4.5307e-01, -4.7688e-01, -4.2549e-01],\n",
      "        [ 2.6423e-01,  6.8002e-02, -6.4018e-02],\n",
      "        [ 5.6117e-01, -1.8869e-01,  2.8079e-01],\n",
      "        [ 2.6871e-01, -5.9164e-01, -1.8984e-01],\n",
      "        [-4.9414e-01, -4.3930e-02,  1.1487e+00],\n",
      "        [ 5.2046e-01,  1.9064e-01, -1.2009e-01],\n",
      "        [ 1.6252e-01, -7.3161e-01,  4.9049e-02],\n",
      "        [ 4.5306e-01, -2.7384e-01,  3.6495e-01],\n",
      "        [ 2.6734e-01, -2.7350e-01,  2.6681e-01],\n",
      "        [-2.2864e-01, -1.1996e+00, -3.4089e-01],\n",
      "        [ 4.7846e-01,  3.2061e-01, -1.4209e-01],\n",
      "        [ 3.3122e-01, -3.9875e-01, -3.8897e-01],\n",
      "        [ 4.6420e-01, -1.5496e-02, -3.8959e-01],\n",
      "        [ 1.2328e-01,  2.6028e-01,  6.2378e-02],\n",
      "        [ 5.9944e-01,  7.5925e-02,  5.4554e-01],\n",
      "        [ 2.4261e-01, -6.0477e-01,  2.5573e-01],\n",
      "        [ 5.1468e-01,  5.0466e-01,  3.3061e-01],\n",
      "        [-1.5327e-01, -6.4414e-01,  3.3249e-01],\n",
      "        [ 2.0583e-01,  1.6017e-01,  4.8396e-01],\n",
      "        [ 5.3729e-01,  7.7347e-02, -2.9971e-01],\n",
      "        [ 6.6015e-01, -3.7266e-01, -2.8416e-01],\n",
      "        [ 4.7487e-01, -2.4743e-01,  3.2014e-01],\n",
      "        [ 3.7725e-01,  1.0480e-01,  9.1875e-01],\n",
      "        [ 3.1701e-01, -5.9409e-02,  7.1511e-02],\n",
      "        [ 4.4609e-01, -1.0123e-01,  1.8112e-01],\n",
      "        [ 6.1224e-01, -1.1784e-01, -6.1321e-02],\n",
      "        [ 1.9572e-01, -1.9914e-01,  5.4143e-01],\n",
      "        [ 2.9860e-01, -4.1176e-02,  1.0753e+00],\n",
      "        [-4.6085e-01, -8.1545e-01,  6.0670e-01],\n",
      "        [ 6.1540e-01,  1.3536e-01,  2.9074e-01],\n",
      "        [ 6.6118e-01, -1.9066e-01, -2.9165e-01],\n",
      "        [ 3.2382e-02, -5.9216e-01,  3.2559e-01],\n",
      "        [ 2.2800e-01,  2.8114e-02,  2.4819e-01],\n",
      "        [ 3.2469e-01, -3.3262e-01,  2.7349e-01],\n",
      "        [ 5.2815e-01,  1.8615e-01, -1.8175e-02],\n",
      "        [ 3.5515e-01, -3.7066e-01,  1.9997e-01],\n",
      "        [ 6.6875e-01, -1.7644e-01, -1.4616e-01],\n",
      "        [ 5.5550e-01,  2.7050e-01, -3.7990e-02],\n",
      "        [ 2.1120e-01, -1.2579e-01, -3.0602e-01],\n",
      "        [ 2.9665e-01, -1.5014e-01, -3.1355e-01],\n",
      "        [ 6.4757e-01, -1.9148e-01, -5.2886e-01],\n",
      "        [ 3.6851e-01, -4.5507e-01,  2.3585e-01],\n",
      "        [ 7.3426e-01, -1.8855e-01, -1.8510e-01],\n",
      "        [-1.0557e-01,  1.1427e-01,  1.0579e+00],\n",
      "        [ 5.2988e-01,  1.0612e-01,  4.3226e-01],\n",
      "        [-5.0638e-02, -5.9778e-01, -6.9687e-02],\n",
      "        [ 2.7135e-01, -1.3739e-01, -9.6587e-02],\n",
      "        [ 5.3714e-01, -4.6988e-01, -1.5953e-01],\n",
      "        [ 7.1735e-01, -2.1475e-01, -4.9783e-01],\n",
      "        [ 2.6480e-01,  2.2916e-01, -8.1265e-02],\n",
      "        [ 5.3052e-01, -5.9615e-01, -5.5975e-01],\n",
      "        [ 5.8459e-01, -1.6653e-01, -4.9467e-01],\n",
      "        [-8.9338e-02, -4.7843e-02,  1.1937e+00],\n",
      "        [ 6.2068e-01, -7.5698e-02, -3.9307e-01],\n",
      "        [ 3.1525e-01,  2.0218e-01,  4.1637e-01],\n",
      "        [-1.9210e-01, -3.3447e-01,  5.8411e-01],\n",
      "        [ 1.7193e-01, -6.0806e-01,  4.0158e-01],\n",
      "        [ 2.9959e-01, -1.8286e-01, -4.0697e-01],\n",
      "        [-1.1784e-02, -1.3004e-01,  9.4066e-01],\n",
      "        [-7.9657e-03,  3.8273e-01,  1.0934e+00],\n",
      "        [ 2.6038e-01,  6.2802e-01, -9.2606e-02],\n",
      "        [ 7.1452e-01, -3.2400e-01, -8.8959e-01],\n",
      "        [ 5.3729e-01,  7.7347e-02, -2.9971e-01],\n",
      "        [ 2.6423e-01,  6.8002e-02, -6.4018e-02],\n",
      "        [ 4.6581e-01, -2.6008e-01,  1.5493e-01],\n",
      "        [ 9.5208e-02, -3.0536e-01,  2.5083e-01],\n",
      "        [ 3.2469e-01, -3.3262e-01,  2.7349e-01],\n",
      "        [ 3.8998e-01, -8.1996e-02, -2.9656e-01],\n",
      "        [ 2.9506e-01, -5.3983e-02, -1.5418e-01],\n",
      "        [ 4.5141e-01, -1.9900e-01,  1.1342e-01],\n",
      "        [ 5.5976e-01,  1.0375e-01,  1.8548e-01],\n",
      "        [ 1.5902e-02,  1.1324e-01,  1.2718e+00],\n",
      "        [ 2.8857e-01,  7.4883e-01,  3.1061e-01],\n",
      "        [ 3.3224e-01, -3.1669e-01,  4.2066e-01],\n",
      "        [ 5.4801e-01, -1.8845e-01, -9.3857e-01],\n",
      "        [-8.1031e-01, -5.2124e-01,  1.2755e+00],\n",
      "        [ 3.0995e-01, -2.3146e-01,  7.2666e-02],\n",
      "        [ 2.6690e-01, -6.1933e-01, -1.0082e-01],\n",
      "        [ 2.9212e-01, -6.7445e-01, -2.2765e-01],\n",
      "        [ 6.8235e-01, -1.9922e-01,  1.0905e-02],\n",
      "        [ 3.9852e-01,  6.0499e-02,  2.5263e-01],\n",
      "        [ 2.9361e-01,  3.2427e-01,  6.4628e-01],\n",
      "        [ 2.8301e-01, -2.9612e-01,  2.8250e-01],\n",
      "        [ 4.4673e-02,  6.2867e-02,  4.8966e-01],\n",
      "        [ 1.8982e-01,  2.5979e-02,  1.4496e-03],\n",
      "        [ 4.8800e-01, -3.6186e-01, -1.6329e-01],\n",
      "        [ 2.2800e-01,  2.8114e-02,  2.4819e-01],\n",
      "        [ 5.0424e-01, -2.8842e-01,  5.4709e-02],\n",
      "        [ 3.6184e-01, -5.0404e-01,  7.1978e-02],\n",
      "        [-1.3612e-01,  3.8742e-01,  7.1800e-01],\n",
      "        [-3.7198e-01,  3.6689e-01,  1.4586e+00],\n",
      "        [ 1.4542e-01, -6.9116e-01,  3.0739e-01],\n",
      "        [ 4.3148e-01,  1.8994e-01,  2.8901e-01],\n",
      "        [ 5.8023e-01,  3.1591e-02,  9.0009e-02],\n",
      "        [ 6.2890e-01,  1.4732e-01,  5.9766e-01],\n",
      "        [-2.4583e-02, -1.2991e-01, -3.6735e-02],\n",
      "        [ 3.4433e-01, -4.8013e-01,  2.4348e-01],\n",
      "        [ 7.3894e-01, -4.1500e-01, -8.8795e-01],\n",
      "        [ 2.3282e-01, -4.6335e-01,  4.1663e-01],\n",
      "        [ 3.6898e-01, -6.8697e-02, -3.5392e-02]], grad_fn=<AddmmBackward0>) \n",
      "\n",
      "PairSampledLinear(\n",
      "  (dense): Linear(in_features=6, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "#### Pair Sampled Networks ####\n",
    "###############################\n",
    "\n",
    "\n",
    "class PairSampledLinear(FittableModule):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 in_dim: int, \n",
    "                 out_dim: int,\n",
    "                 sampling_method: Literal['uniform', 'gradient'] = 'gradient'\n",
    "                 ):\n",
    "        \"\"\"Dense MLP layer with pair sampled weights.\n",
    "\n",
    "        Args:\n",
    "            generator (torch.Generator): PRNG object.\n",
    "            in_dim (int): Input dimension.\n",
    "            out_dim (int): Output dimension.\n",
    "            sampling_method (str): Pair sampling method. Uniform or gradient-weighted.\n",
    "        \"\"\"\n",
    "        super(PairSampledLinear, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.dense = nn.Linear(in_dim, out_dim)\n",
    "        self.sampling_method = sampling_method\n",
    "\n",
    "\n",
    "    def fit(self, \n",
    "            X: Tensor, \n",
    "            y: Tensor,\n",
    "        ) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"Given forward-propagated training data X at the previous \n",
    "        hidden layer, and supervised target labels y, fit the weights\n",
    "        iteratively by letting rows of the weight matrix be given by\n",
    "        pairs of samples from X. See paper for more details.\n",
    "\n",
    "        Args:\n",
    "            X (Tensor): Forward-propagated activations of training data, shape (N, d).\n",
    "            y (Tensor): Training labels, shape (N, p).\n",
    "        \n",
    "        Returns:\n",
    "            Forwarded activations and labels [f(X), y].\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            N, d = X.shape\n",
    "            dtype = X.dtype\n",
    "            device = X.device\n",
    "            EPS = torch.tensor(0.1, dtype=dtype, device=device)\n",
    "\n",
    "            #obtain pair indices\n",
    "            n = 5*N\n",
    "            idx1 = torch.arange(0, n, dtype=torch.int32, device=device) % N\n",
    "            delta = torch.randint(1, N, size=(n,), dtype=torch.int32, device=device, generator=self.generator)\n",
    "            idx2 = (idx1 + delta) % N\n",
    "            dx = X[idx2] - X[idx1]\n",
    "            dists = torch.linalg.norm(dx, axis=1, keepdims=True)\n",
    "            dists = torch.maximum(dists, EPS)\n",
    "            \n",
    "            if self.sampling_method==\"gradient\":\n",
    "                #calculate 'gradients'\n",
    "                dy = y[idx2] - y[idx1]\n",
    "                y_norm = torch.linalg.norm(dy, axis=1, keepdims=True) #NOTE 2023 paper uses ord=inf instead of ord=2\n",
    "                grad = (y_norm / dists).reshape(-1) \n",
    "                p = grad/grad.sum()\n",
    "            elif self.sampling_method==\"uniform\":\n",
    "                p = torch.ones(n, dtype=dtype, device=device) / n\n",
    "            else:\n",
    "                raise ValueError(f\"sampling_method must be 'uniform' or 'gradient'. Given: {self.sampling_method}\")\n",
    "\n",
    "            #sample pairs\n",
    "            selected_idx = torch.multinomial(\n",
    "                p,\n",
    "                self.out_dim,\n",
    "                replacement=True,\n",
    "                generator=self.generator\n",
    "                )\n",
    "            idx1 = idx1[selected_idx]\n",
    "            dx = dx[selected_idx]\n",
    "            dists = dists[selected_idx]\n",
    "\n",
    "            #define weights and biases\n",
    "            weights = dx / (dists**2)\n",
    "            biases = -torch.einsum('ij,ij->i', weights, X[idx1]) - 0.5\n",
    "            self.dense.weight.data = weights\n",
    "            self.dense.bias.data = biases\n",
    "            return self(X), y\n",
    "    \n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense(X)\n",
    "    \n",
    "    \n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator().manual_seed(0)\n",
    "net = PairSampledLinear(g1, D, 3)\n",
    "net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print_name(out)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([273, 6]) out torch.float32\n",
      "tensor([[-0.0473, -0.7883,  0.1466,  3.5619, -1.3800, -0.7621],\n",
      "        [ 1.3652,  1.8986,  0.6492,  0.0685, -1.1746, -1.7752],\n",
      "        [-1.1149, -0.4199, -0.5711,  0.0608, -1.3669, -0.4968],\n",
      "        ...,\n",
      "        [ 0.4023, -3.2661,  0.1615,  0.3883, -1.4053,  0.8282],\n",
      "        [-1.3197,  0.0145, -0.5040,  0.0637, -1.2957,  0.0842],\n",
      "        [-0.7870, -1.4006,  1.4091,  0.2247, -1.4208,  0.0865]],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "SampledResBlock(\n",
      "  (sampled_linear): PairSampledLinear(\n",
      "    (dense): Linear(in_features=6, out_features=3, bias=True)\n",
      "  )\n",
      "  (activation): Tanh()\n",
      "  (upscale): Dense(\n",
      "    (dense): Linear(in_features=3, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "#### Sampled Bottleneck ResNet ####\n",
    "###################################\n",
    "\n",
    "\n",
    "class SampledResBlock(FittableModule):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 hidden_dim: int, \n",
    "                 activation_dim: int,\n",
    "                 activation: nn.Module = nn.Tanh(),\n",
    "                 sampling_method: Literal['uniform', 'gradient'] = 'gradient'\n",
    "                 ):\n",
    "        \"\"\"A sampled layer followed by activation and linear layer.\n",
    "        Equivalent to a 1-hidden-layer Sampled Neural Network.\n",
    "\n",
    "        Args:\n",
    "            generator (torch.Generator): PRNG object.\n",
    "            in_dim (int): Input dimension.\n",
    "            out_dim (int): Output dimension.\n",
    "            activation (nn.Module): Activation function.\n",
    "            sampling_method (str): Pair sampling method. Uniform or gradient-weighted.\n",
    "        \"\"\"\n",
    "        super(SampledResBlock, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.sampled_linear = PairSampledLinear(generator, hidden_dim, activation_dim, sampling_method)\n",
    "        self.activation = activation\n",
    "        self.upscale = Dense(generator, activation_dim, hidden_dim)\n",
    "    \n",
    "\n",
    "    def fit(self, X: Tensor, y: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        with torch.no_grad():\n",
    "            X0 = X\n",
    "            X, y = self.sampled_linear.fit(X, y)\n",
    "            X = self.activation(X)\n",
    "            X, y = self.upscale.fit(X, y)\n",
    "            return X0 + X, y\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X0 = X\n",
    "        X = self.sampled_linear(X)\n",
    "        X = self.activation(X)\n",
    "        X = self.upscale(X)\n",
    "        return X0 + X\n",
    "    \n",
    "    \n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator().manual_seed(0)\n",
    "net = SampledResBlock(g1, D, 3)\n",
    "net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print_name(out)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeCVModule()\n",
      "rmse test 0.45788816\n",
      "rmse train 0.38987496\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "### RidgeCV Layer ###\n",
    "#####################\n",
    "\n",
    "class RidgeCVModule(FittableModule):\n",
    "    def __init__(self, alphas=np.logspace(-1, 3, 10)):\n",
    "        \"\"\"RidgeCV layer using sklearn's RidgeCV. TODO dont use sklearn\"\"\"\n",
    "        super(RidgeCVModule, self).__init__()\n",
    "        self.ridge = RidgeCV(alphas=alphas)\n",
    "\n",
    "    def fit(self, X: Tensor, y: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"Fit the RidgeCV model. TODO dont use sklearn\"\"\"\n",
    "        X_np = X.detach().cpu().numpy().astype(np.float64)\n",
    "        y_np = y.detach().cpu().squeeze().numpy().astype(np.float64)\n",
    "        self.ridge.fit(X_np, y_np)\n",
    "        return self(X), y\n",
    "\n",
    "    def forward(self, X: Tensor) -> Tensor:\n",
    "        \"\"\"Forward pass through the RidgeCV model. TODO dont use sklearn\"\"\"\n",
    "        X_np = X.detach().cpu().numpy().astype(np.float64)\n",
    "        y_pred_np = self.ridge.predict(X_np)\n",
    "        return torch.tensor(y_pred_np, dtype=X.dtype, device=X.device).unsqueeze(1) #TODO unsqueeze???\n",
    "\n",
    "\n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator()\n",
    "net = RidgeCVModule()\n",
    "out_train, _ = net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print(net)\n",
    "\n",
    "print(\"rmse test\", mean_squared_error(y_test.detach().cpu().numpy(), out.detach().cpu().numpy()))\n",
    "print(\"rmse train\", mean_squared_error(y_train.detach().cpu().numpy(), out_train.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SampledResNet(\n",
      "  (upsample): PairSampledLinear(\n",
      "    (dense): Linear(in_features=6, out_features=600, bias=True)\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x SampledResBlock(\n",
      "      (sampled_linear): PairSampledLinear(\n",
      "        (dense): Linear(in_features=600, out_features=600, bias=True)\n",
      "      )\n",
      "      (activation): Tanh()\n",
      "      (upscale): Dense(\n",
      "        (dense): Linear(in_features=600, out_features=600, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output_layer): RidgeCVModule()\n",
      ")\n",
      "rmse test 0.37741318\n",
      "rmse train 0.28207216\n",
      "16.68100537200059\n"
     ]
    }
   ],
   "source": [
    "class SampledResNet(ResNetBase):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 in_dim: int,\n",
    "                 hidden_dim: int,\n",
    "                 activation_dim: int, #rename to bottleneck dim?\n",
    "                 n_blocks: int,\n",
    "                 activation: nn.Module = nn.Tanh(),\n",
    "                 upsample_module: Literal['dense', 'sampled', 'identity'] = 'dense',\n",
    "                 sampling_method: Literal['uniform', 'gradient'] = 'gradient'\n",
    "                 ):\n",
    "        \"\"\"A ResNet with sampled layers as bottleneck layers.\n",
    "        \"\"\"\n",
    "        if upsample_module==\"dense\":\n",
    "            upsample = Dense(generator, in_dim, hidden_dim)\n",
    "        elif upsample_module==\"sampled\":\n",
    "            upsample = PairSampledLinear(generator, in_dim, hidden_dim, sampling_method)\n",
    "        elif upsample_module==\"identity\":\n",
    "            upsample = Identity()\n",
    "        else:\n",
    "            raise ValueError(f\"upsample_module must be 'dense', 'sampled' or 'identity'. Given: {upsample_module}\")\n",
    "\n",
    "        blocks = [SampledResBlock(generator, \n",
    "                                hidden_dim, \n",
    "                                activation_dim,\n",
    "                                activation,\n",
    "                                sampling_method\n",
    "                                ) for _ in range(n_blocks)]\n",
    "        ridge = RidgeCVModule()\n",
    "        super(SampledResNet, self).__init__(upsample, blocks, ridge)\n",
    "\n",
    "\n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator().manual_seed(int(time.time()*10))\n",
    "net = SampledResNet(g1, D, 100*D, 100*D, 6, upsample_module='sampled', sampling_method='uniform')\n",
    "out_train, _ = net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print(net)\n",
    "\n",
    "print(\"rmse test\", mean_squared_error(y_test.detach().cpu().numpy(), out.detach().cpu().numpy()))\n",
    "print(\"rmse train\", mean_squared_error(y_train.detach().cpu().numpy(), out_train.detach().cpu().numpy()))\n",
    "print(net.output_layer.ridge.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([273, 6]) out torch.float32\n",
      "tensor([[-0.0473, -0.7883,  0.1466,  3.5619, -1.3800, -0.7621],\n",
      "        [ 1.3652,  1.8986,  0.6492,  0.0685, -1.1746, -1.7752],\n",
      "        [-1.1149, -0.4199, -0.5711,  0.0608, -1.3669, -0.4968],\n",
      "        ...,\n",
      "        [ 0.4023, -3.2661,  0.1615,  0.3883, -1.4053,  0.8282],\n",
      "        [-1.3197,  0.0145, -0.5040,  0.0637, -1.2957,  0.0842],\n",
      "        [-0.7870, -1.4006,  1.4091,  0.2247, -1.4208,  0.0865]],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "SampledResBlock(\n",
      "  (sampled_linear): PairSampledLinear(\n",
      "    (dense): Linear(in_features=6, out_features=3, bias=True)\n",
      "  )\n",
      "  (activation): Tanh()\n",
      "  (upscale): Dense(\n",
      "    (dense): Linear(in_features=3, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SampledAndActivation(FittableModule):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 in_dim: int,\n",
    "                 out_dim: int, \n",
    "                 activation: nn.Module = nn.Tanh(),\n",
    "                 sampling_method: Literal['uniform', 'gradient'] = 'gradient'\n",
    "                 ):\n",
    "        \"\"\"TODO\n",
    "        \"\"\"\n",
    "        super(SampledAndActivation, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.sampled_linear = PairSampledLinear(generator, in_dim, out_dim, sampling_method)\n",
    "        self.activation = activation\n",
    "    \n",
    "\n",
    "    def fit(self, X: Tensor, y: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        with torch.no_grad():\n",
    "            X, y = self.sampled_linear.fit(X, y)\n",
    "            X = self.activation(X)\n",
    "            return X, y\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.sampled_linear(X)\n",
    "        X = self.activation(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "class SampledODEBlock(FittableModule):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 hidden_dim: int, \n",
    "                 activation: nn.Module = nn.Tanh(),\n",
    "                 sampling_method: Literal['uniform', 'gradient'] = 'gradient'\n",
    "                 ):\n",
    "        \"\"\"TODO\n",
    "\n",
    "        Args:\n",
    "            generator (torch.Generator): PRNG object.\n",
    "            hidden_dim (int): Hidden size.\n",
    "            activation (nn.Module): Activation function.\n",
    "            sampling_method (str): Pair sampling method. Uniform or gradient-weighted.\n",
    "        \"\"\"\n",
    "        super(SampledODEBlock, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.sampled_linear = PairSampledLinear(generator, hidden_dim, hidden_dim, sampling_method)\n",
    "        self.activation = activation\n",
    "    \n",
    "\n",
    "    def fit(self, X: Tensor, y: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        with torch.no_grad():\n",
    "            X0 = X\n",
    "            X, y = self.sampled_linear.fit(X, y)\n",
    "            X = self.activation(X)\n",
    "            return X0 + X, y\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X0 = X\n",
    "        X = self.sampled_linear(X)\n",
    "        X = self.activation(X)\n",
    "        return X0 + X\n",
    "    \n",
    "    \n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator().manual_seed(0)\n",
    "net = SampledResBlock(g1, D, 3)\n",
    "net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print_name(out)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SampledEulerODE(\n",
      "  (upsample): SampledAndActivation(\n",
      "    (sampled_linear): PairSampledLinear(\n",
      "      (dense): Linear(in_features=6, out_features=600, bias=True)\n",
      "    )\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x SampledODEBlock(\n",
      "      (sampled_linear): PairSampledLinear(\n",
      "        (dense): Linear(in_features=600, out_features=600, bias=True)\n",
      "      )\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (output_layer): RidgeCVModule()\n",
      ")\n",
      "rmse test 0.3939432\n",
      "rmse train 0.30253765\n",
      "46.41588833612777\n"
     ]
    }
   ],
   "source": [
    "class SampledEulerODE(ResNetBase):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 in_dim: int,\n",
    "                 hidden_dim: int,\n",
    "                 n_blocks: int,\n",
    "                 activation: nn.Module = nn.Tanh(),\n",
    "                 upsample_module: Literal['dense', 'sampled', 'identity'] = 'dense',\n",
    "                 sampling_method: Literal['uniform', 'gradient'] = 'gradient'\n",
    "                 ):\n",
    "        \"\"\"A ResNet with sampled layers as bottleneck layers.\n",
    "        \"\"\"\n",
    "        if upsample_module==\"dense\":\n",
    "            upsample = Dense(generator, in_dim, hidden_dim)\n",
    "        elif upsample_module==\"sampled\":\n",
    "            upsample = SampledAndActivation(generator, in_dim, hidden_dim, activation, sampling_method)\n",
    "        elif upsample_module==\"identity\":\n",
    "            upsample = Identity()\n",
    "        else:\n",
    "            raise ValueError(f\"upsample_module must be 'dense', 'sampled' or 'identity'. Given: {upsample_module}\")\n",
    "        \n",
    "        blocks = [SampledODEBlock(generator,\n",
    "                                hidden_dim,\n",
    "                                activation,\n",
    "                                sampling_method\n",
    "                                ) for _ in range(n_blocks)]\n",
    "        ridge = RidgeCVModule()\n",
    "        super(SampledEulerODE, self).__init__(upsample, blocks, ridge)\n",
    "\n",
    "\n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator().manual_seed(int(time.time()*10))\n",
    "net = SampledEulerODE(g1, D, 100*D, 6, upsample_module='sampled', sampling_method='gradient')\n",
    "out_train, _ = net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print(net)\n",
    "\n",
    "print(\"rmse test\", mean_squared_error(y_test.detach().cpu().numpy(), out.detach().cpu().numpy()))\n",
    "print(\"rmse train\", mean_squared_error(y_train.detach().cpu().numpy(), out_train.detach().cpu().numpy()))\n",
    "print(net.output_layer.ridge.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWIM tabular model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_distribution_for_each_layer(\n",
    "        X_train: Array,\n",
    "        y_train: Array,\n",
    "        X_test: Array,\n",
    "        hidden_size: int,\n",
    "        n_layers: int,\n",
    "        ) -> Tuple[Array, Array]:\n",
    "    \"\"\"Looks at the distribution of neurons for each layer of a neural network model\n",
    "    (used to compare SWIM, residual sampling, and random feature networks).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the arrays to store the neuron distribution\n",
    "    train_layers= []\n",
    "    test_layers = []\n",
    "\n",
    "    model = SWIM_MLP(\n",
    "        jax.random.PRNGKey(0), \n",
    "        hidden_size, \n",
    "        n_layers,\n",
    "        add_residual=True,\n",
    "        sampling_method=\"gradient-weighted\",\n",
    "        #activation = jnp.tanh,\n",
    "        #residual_scaling_factor=1.0,\n",
    "        \n",
    "        )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    feat_test  = model.transform(X_train, only_last=False).reshape(n_layers, -1)\n",
    "    feat_train = model.transform(X_test, only_last=False).reshape(n_layers, -1)\n",
    "    \n",
    "    print(feat_test[1]-feat_test[1])\n",
    "\n",
    "    #features are shape (n_layers, n_samples, n_features)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(X_train.flatten(), bins=50, alpha=0.5, label='Train', density=True)\n",
    "    plt.hist(X_test.flatten(), bins=50, alpha=0.5, label='Test', density=True)\n",
    "    plt.title('Input Data Distribution')\n",
    "    plt.xlabel('Input Feature Value')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    for layer in range(n_layers):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(feat_train[layer], bins=50, alpha=0.5, label='Train', density=True)\n",
    "        plt.hist(feat_test[layer], bins=50, alpha=0.5, label='Test', density=True)\n",
    "        plt.title(f'Layer {layer + 1} Neuron Distribution')\n",
    "        plt.xlabel('Neuron Activation')\n",
    "        plt.ylabel('Probability Density')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    print(feat_test.shape)\n",
    "\n",
    "neuron_distribution_for_each_layer(X_train, y_train, X_test, 128, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to look at the distribution of weights (eigenvalues? absolute values of rows? distribution of (assuming iid) matrix entries?)\n",
    "\n",
    "distribution of neurons at each layer\n",
    "\n",
    "This is for both SWIM, Residual SWIM, random features, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
