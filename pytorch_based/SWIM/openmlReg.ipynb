{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikita/Code/zephyrox/.conda/lib/python3.10/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import openml\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn.functional import relu\n",
    "from torch.nn.functional import tanh\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from aeon.regression.sklearn import RotationForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "from aeon.datasets.tser_datasets import tser_soton\n",
    "from aeon.datasets import load_regression, load_classification\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from preprocessing.stream_transforms import normalize_mean_std_traindata, normalize_streams, augment_time, add_basepoint_zero\n",
    "from utils.utils import print_name, print_shape\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/35 Processed dataset 44956: abalone\n",
      " 2/35 Processed dataset 44957: airfoil_self_noise\n",
      " 3/35 Processed dataset 44958: auction_verification\n",
      " 4/35 Processed dataset 44959: concrete_compressive_strength\n",
      " 5/35 Processed dataset 44963: physiochemical_protein\n",
      " 6/35 Processed dataset 44964: superconductivity\n",
      " 7/35 Processed dataset 44965: geographical_origin_of_music\n",
      " 8/35 Processed dataset 44966: solar_flare\n",
      " 9/35 Processed dataset 44969: naval_propulsion_plant\n",
      " 10/35 Processed dataset 44971: white_wine\n",
      " 11/35 Processed dataset 44972: red_wine\n",
      " 12/35 Processed dataset 44973: grid_stability\n",
      " 13/35 Processed dataset 44974: video_transcoding\n",
      " 14/35 Processed dataset 44975: wave_energy\n",
      " 15/35 Processed dataset 44976: sarcos\n",
      " 16/35 Processed dataset 44977: california_housing\n",
      " 17/35 Processed dataset 44978: cpu_activity\n",
      " 18/35 Processed dataset 44979: diamonds\n",
      " 19/35 Processed dataset 44980: kin8nm\n",
      " 20/35 Processed dataset 44981: pumadyn32nh\n",
      " 21/35 Processed dataset 44983: miami_housing\n",
      " 22/35 Processed dataset 44984: cps88wages\n",
      " 23/35 Processed dataset 44987: socmob\n",
      " 24/35 Processed dataset 44989: kings_county\n",
      " 25/35 Processed dataset 44990: brazilian_houses\n",
      " 26/35 Processed dataset 44992: fps_benchmark\n",
      " 27/35 Processed dataset 44993: health_insurance\n",
      " 28/35 Processed dataset 45012: fifa\n",
      " 29/35 Processed dataset 41021: Moneyball\n",
      " 30/35 Processed dataset 44960: energy_efficiency\n",
      " 31/35 Processed dataset 44962: forest_fires\n",
      " 32/35 Processed dataset 44967: student_performance_por\n",
      " 33/35 Processed dataset 44970: QSAR_fish_toxicity\n",
      " 34/35 Processed dataset 44994: cars\n",
      " 35/35 Processed dataset 45402: space_ga\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>n_features</th>\n",
       "      <th>%_unique_y</th>\n",
       "      <th>n_unique_y</th>\n",
       "      <th>has_categorical</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44973</th>\n",
       "      <td>grid_stability</td>\n",
       "      <td>10000</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44975</th>\n",
       "      <td>wave_energy</td>\n",
       "      <td>72000</td>\n",
       "      <td>49</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>71993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44980</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8192</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>8191</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44981</th>\n",
       "      <td>pumadyn32nh</td>\n",
       "      <td>8192</td>\n",
       "      <td>33</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>8191</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45402</th>\n",
       "      <td>space_ga</td>\n",
       "      <td>3107</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999356</td>\n",
       "      <td>3105</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44958</th>\n",
       "      <td>auction_verification</td>\n",
       "      <td>2043</td>\n",
       "      <td>8</td>\n",
       "      <td>0.998042</td>\n",
       "      <td>2039</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44994</th>\n",
       "      <td>cars</td>\n",
       "      <td>804</td>\n",
       "      <td>18</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>798</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44957</th>\n",
       "      <td>airfoil_self_noise</td>\n",
       "      <td>1503</td>\n",
       "      <td>6</td>\n",
       "      <td>0.968729</td>\n",
       "      <td>1456</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44970</th>\n",
       "      <td>QSAR_fish_toxicity</td>\n",
       "      <td>908</td>\n",
       "      <td>7</td>\n",
       "      <td>0.910793</td>\n",
       "      <td>827</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44959</th>\n",
       "      <td>concrete_compressive_strength</td>\n",
       "      <td>1030</td>\n",
       "      <td>9</td>\n",
       "      <td>0.910680</td>\n",
       "      <td>938</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44960</th>\n",
       "      <td>energy_efficiency</td>\n",
       "      <td>768</td>\n",
       "      <td>9</td>\n",
       "      <td>0.764323</td>\n",
       "      <td>587</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44990</th>\n",
       "      <td>brazilian_houses</td>\n",
       "      <td>10692</td>\n",
       "      <td>10</td>\n",
       "      <td>0.537879</td>\n",
       "      <td>5751</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44962</th>\n",
       "      <td>forest_fires</td>\n",
       "      <td>517</td>\n",
       "      <td>13</td>\n",
       "      <td>0.485493</td>\n",
       "      <td>251</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44963</th>\n",
       "      <td>physiochemical_protein</td>\n",
       "      <td>45730</td>\n",
       "      <td>10</td>\n",
       "      <td>0.347759</td>\n",
       "      <td>15903</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44987</th>\n",
       "      <td>socmob</td>\n",
       "      <td>1156</td>\n",
       "      <td>6</td>\n",
       "      <td>0.312284</td>\n",
       "      <td>361</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41021</th>\n",
       "      <td>Moneyball</td>\n",
       "      <td>1232</td>\n",
       "      <td>15</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>374</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44976</th>\n",
       "      <td>sarcos</td>\n",
       "      <td>48933</td>\n",
       "      <td>22</td>\n",
       "      <td>0.233258</td>\n",
       "      <td>11414</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44979</th>\n",
       "      <td>diamonds</td>\n",
       "      <td>53940</td>\n",
       "      <td>10</td>\n",
       "      <td>0.215091</td>\n",
       "      <td>11602</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44984</th>\n",
       "      <td>cps88wages</td>\n",
       "      <td>28155</td>\n",
       "      <td>7</td>\n",
       "      <td>0.212040</td>\n",
       "      <td>5970</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44989</th>\n",
       "      <td>kings_county</td>\n",
       "      <td>21613</td>\n",
       "      <td>22</td>\n",
       "      <td>0.186369</td>\n",
       "      <td>4028</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44977</th>\n",
       "      <td>california_housing</td>\n",
       "      <td>20640</td>\n",
       "      <td>9</td>\n",
       "      <td>0.186143</td>\n",
       "      <td>3842</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44974</th>\n",
       "      <td>video_transcoding</td>\n",
       "      <td>68784</td>\n",
       "      <td>19</td>\n",
       "      <td>0.159339</td>\n",
       "      <td>10960</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44983</th>\n",
       "      <td>miami_housing</td>\n",
       "      <td>13932</td>\n",
       "      <td>16</td>\n",
       "      <td>0.151522</td>\n",
       "      <td>2111</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44964</th>\n",
       "      <td>superconductivity</td>\n",
       "      <td>21263</td>\n",
       "      <td>82</td>\n",
       "      <td>0.141419</td>\n",
       "      <td>3007</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44992</th>\n",
       "      <td>fps_benchmark</td>\n",
       "      <td>24624</td>\n",
       "      <td>44</td>\n",
       "      <td>0.108634</td>\n",
       "      <td>2675</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44965</th>\n",
       "      <td>geographical_origin_of_music</td>\n",
       "      <td>1059</td>\n",
       "      <td>117</td>\n",
       "      <td>0.029273</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44967</th>\n",
       "      <td>student_performance_por</td>\n",
       "      <td>649</td>\n",
       "      <td>31</td>\n",
       "      <td>0.026194</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44966</th>\n",
       "      <td>solar_flare</td>\n",
       "      <td>1066</td>\n",
       "      <td>11</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45012</th>\n",
       "      <td>fifa</td>\n",
       "      <td>19178</td>\n",
       "      <td>29</td>\n",
       "      <td>0.006935</td>\n",
       "      <td>133</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44978</th>\n",
       "      <td>cpu_activity</td>\n",
       "      <td>8192</td>\n",
       "      <td>22</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>56</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44956</th>\n",
       "      <td>abalone</td>\n",
       "      <td>4177</td>\n",
       "      <td>9</td>\n",
       "      <td>0.006703</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44969</th>\n",
       "      <td>naval_propulsion_plant</td>\n",
       "      <td>11934</td>\n",
       "      <td>15</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44972</th>\n",
       "      <td>red_wine</td>\n",
       "      <td>1599</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44993</th>\n",
       "      <td>health_insurance</td>\n",
       "      <td>22272</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>75</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44971</th>\n",
       "      <td>white_wine</td>\n",
       "      <td>4898</td>\n",
       "      <td>12</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     name  n_obs  n_features  %_unique_y  \\\n",
       "dataset_id                                                                 \n",
       "44973                      grid_stability  10000          13    1.000000   \n",
       "44975                         wave_energy  72000          49    0.999903   \n",
       "44980                              kin8nm   8192           9    0.999878   \n",
       "44981                         pumadyn32nh   8192          33    0.999878   \n",
       "45402                            space_ga   3107           7    0.999356   \n",
       "44958                auction_verification   2043           8    0.998042   \n",
       "44994                                cars    804          18    0.992537   \n",
       "44957                  airfoil_self_noise   1503           6    0.968729   \n",
       "44970                  QSAR_fish_toxicity    908           7    0.910793   \n",
       "44959       concrete_compressive_strength   1030           9    0.910680   \n",
       "44960                   energy_efficiency    768           9    0.764323   \n",
       "44990                    brazilian_houses  10692          10    0.537879   \n",
       "44962                        forest_fires    517          13    0.485493   \n",
       "44963              physiochemical_protein  45730          10    0.347759   \n",
       "44987                              socmob   1156           6    0.312284   \n",
       "41021                           Moneyball   1232          15    0.303571   \n",
       "44976                              sarcos  48933          22    0.233258   \n",
       "44979                            diamonds  53940          10    0.215091   \n",
       "44984                          cps88wages  28155           7    0.212040   \n",
       "44989                        kings_county  21613          22    0.186369   \n",
       "44977                  california_housing  20640           9    0.186143   \n",
       "44974                   video_transcoding  68784          19    0.159339   \n",
       "44983                       miami_housing  13932          16    0.151522   \n",
       "44964                   superconductivity  21263          82    0.141419   \n",
       "44992                       fps_benchmark  24624          44    0.108634   \n",
       "44965        geographical_origin_of_music   1059         117    0.029273   \n",
       "44967             student_performance_por    649          31    0.026194   \n",
       "44966                         solar_flare   1066          11    0.007505   \n",
       "45012                                fifa  19178          29    0.006935   \n",
       "44978                        cpu_activity   8192          22    0.006836   \n",
       "44956                             abalone   4177           9    0.006703   \n",
       "44969              naval_propulsion_plant  11934          15    0.004274   \n",
       "44972                            red_wine   1599          12    0.003752   \n",
       "44993                    health_insurance  22272          12    0.003367   \n",
       "44971                          white_wine   4898          12    0.001429   \n",
       "\n",
       "            n_unique_y  has_categorical  \n",
       "dataset_id                               \n",
       "44973            10000            False  \n",
       "44975            71993            False  \n",
       "44980             8191            False  \n",
       "44981             8191            False  \n",
       "45402             3105            False  \n",
       "44958             2039             True  \n",
       "44994              798            False  \n",
       "44957             1456            False  \n",
       "44970              827            False  \n",
       "44959              938            False  \n",
       "44960              587            False  \n",
       "44990             5751             True  \n",
       "44962              251             True  \n",
       "44963            15903            False  \n",
       "44987              361             True  \n",
       "41021              374             True  \n",
       "44976            11414            False  \n",
       "44979            11602             True  \n",
       "44984             5970             True  \n",
       "44989             4028             True  \n",
       "44977             3842            False  \n",
       "44974            10960             True  \n",
       "44983             2111            False  \n",
       "44964             3007            False  \n",
       "44992             2675             True  \n",
       "44965               31            False  \n",
       "44967               17             True  \n",
       "44966                8             True  \n",
       "45012              133             True  \n",
       "44978               56            False  \n",
       "44956               28             True  \n",
       "44969               51            False  \n",
       "44972                6            False  \n",
       "44993               75             True  \n",
       "44971                7            False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the collection with ID 353\n",
    "collection = openml.study.get_suite(353)\n",
    "dataset_ids = collection.data\n",
    "metadata_list = []\n",
    "\n",
    "# Fetch and process each dataset\n",
    "for i, dataset_id in enumerate(dataset_ids):\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        target=dataset.default_target_attribute\n",
    "    )\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)[..., None]\n",
    "    \n",
    "    # Determine if the dataset has categorical features\n",
    "    has_categorical = any(categorical_indicator)\n",
    "    \n",
    "    # Extract the required metadata\n",
    "    metadata = {\n",
    "        'dataset_id': dataset.id,\n",
    "        'name': dataset.name,\n",
    "        'n_obs': int(dataset.qualities['NumberOfInstances']),\n",
    "        'n_features': int(dataset.qualities['NumberOfFeatures']),\n",
    "        '%_unique_y': len(np.unique(y))/len(y),\n",
    "        'n_unique_y': len(np.unique(y)),\n",
    "        'has_categorical': has_categorical\n",
    "    }\n",
    "    \n",
    "    metadata_list.append(metadata)\n",
    "    print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset.id}: {dataset.name}\")\n",
    "\n",
    "# Create a DataFrame from the metadata list\n",
    "df_metadata = pd.DataFrame(metadata_list).sort_values('%_unique_y', ascending=False).set_index(\"dataset_id\")\n",
    "df_metadata.sort_values('%_unique_y', ascending=True)\n",
    "\n",
    "# Display the metadata DataFrame\n",
    "df_metadata.loc[44962, \"has_categorical\"] = True\n",
    "df_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_openml_dataset(dataset_id, \n",
    "                        normalize_X:bool = True,\n",
    "                        normalize_y:bool = True,\n",
    "                        train_test_size:float = 0.7,\n",
    "                        split_seed:int = 0,\n",
    "                        device=\"cpu\",\n",
    "                        ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # Fetch dataset from OpenML by its ID\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    df, _, categorical_indicator, attribute_names = dataset.get_data()\n",
    "    df.dropna(inplace=True)\n",
    "    y = np.array(df.pop(dataset.default_target_attribute))[..., None]\n",
    "    X = np.array(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_test_size, random_state=split_seed)\n",
    "\n",
    "    #normalize\n",
    "    if normalize_X:\n",
    "        X_train, X_test = normalize_mean_std_traindata(X_train, X_test)\n",
    "        X_train = np.clip(X_train, -3, 3)\n",
    "        X_test = np.clip(X_test, -3, 3)\n",
    "    if normalize_y:\n",
    "        y_train, y_test = normalize_mean_std_traindata(y_train, y_test)\n",
    "\n",
    "    return (Tensor(X_train.astype(np.float32)).to(device), \n",
    "            Tensor(X_test.astype(np.float32)).to(device), \n",
    "            Tensor(y_train.astype(np.float32)).to(device), \n",
    "            Tensor(y_test.astype(np.float32)).to(device))\n",
    "\n",
    "#dataset_id = 44971  # Replace with the dataset ID you want\n",
    "dataset_id = 44971 #44970\n",
    "X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id, False, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Module for sampled networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "##### Base classes                                          #####\n",
    "##### - FittableModule: A nn.Module with .fit(X, y) support #####\n",
    "##### - ResNetBase: which interatively calls .fit(X, y)     #####\n",
    "#################################################################\n",
    "\n",
    "class FittableModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FittableModule, self).__init__()\n",
    "    \n",
    "\n",
    "    def fit(self, \n",
    "            X: Optional[Tensor] = None, \n",
    "            y: Optional[Tensor] = None,\n",
    "        ) -> Tuple[Optional[Tensor], Optional[Tensor]]:\n",
    "        \"\"\"Given neurons of the previous layer, and target labels, fit the \n",
    "        module. Returns the forwarded activations and labels [f(X), y].\n",
    "\n",
    "        Args:\n",
    "            X (Optional[Tensor]): Forward-propagated activations of training data, shape (N, d).\n",
    "            y (Optional[Tensor]): Training labels, shape (N, p).\n",
    "        \n",
    "        Returns:\n",
    "            Forwarded activations and labels [f(X), y].\n",
    "        \"\"\"\n",
    "        return self(X), y\n",
    "\n",
    "\n",
    "\n",
    "class ResNetBase(FittableModule):\n",
    "    def __init__(self,\n",
    "                upsample:FittableModule,\n",
    "                blocks:List[FittableModule],\n",
    "                output_layer:FittableModule,\n",
    "                ):\n",
    "        \"\"\"Residual Network base class, with fit method for non-SGD training/initialization.\n",
    "\n",
    "        Args:\n",
    "            upsample (FittableModule): _description_\n",
    "            blocks (List[FittableModule]): _description_\n",
    "            output_layer (FittableModule): _description_\n",
    "        \"\"\"\n",
    "        super(ResNetBase, self).__init__()\n",
    "        self.upsample = upsample\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "        self.output_layer = output_layer\n",
    "\n",
    "    \n",
    "    def fit(self, X:Tensor, y:Tensor):\n",
    "        # X shape (N, d)\n",
    "        # y shape (N, p)\n",
    "        X, y = self.upsample.fit(X, y)\n",
    "        for block in self.blocks:\n",
    "            X, y = block.fit(X, y)\n",
    "        X, y = self.output_layer.fit(X, y)\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        # x shape (N, d)\n",
    "        x = self.upsample(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1470, 3]) out torch.float32\n",
      "tensor([[-15.0697,  -1.0931,  29.7537],\n",
      "        [-11.4016,  -7.3552,  30.6810],\n",
      "        [ -5.4838,  -9.1904,  20.7735],\n",
      "        ...,\n",
      "        [  0.9532, -14.4864,  15.1146],\n",
      "        [  0.7565, -25.6293,  27.8604],\n",
      "        [-11.9715,  -7.1950,  33.1178]], grad_fn=<AddmmBackward0>) \n",
      "\n",
      "Dense(\n",
      "  (dense): Linear(in_features=11, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "######## Dense Layer ########\n",
    "#############################\n",
    "\n",
    "\n",
    "class Dense(FittableModule):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 in_dim: int,\n",
    "                 out_dim: int,\n",
    "                 ):\n",
    "        \"\"\"Dense MLP layer with LeCun weight initialization,\n",
    "        Gaussan bias initialization.\"\"\"\n",
    "        super(Dense, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.dense = nn.Linear(in_dim, out_dim)\n",
    "    \n",
    "    def fit(self, X:Tensor, y:Tensor):\n",
    "        with torch.no_grad():\n",
    "            nn.init.normal_(self.dense.weight, mean=0, std=self.in_dim**-0.5, generator=self.generator)\n",
    "            nn.init.normal_(self.dense.bias, mean=0, std=self.in_dim**-0.25, generator=self.generator)\n",
    "            return self(X), y\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.dense(X)\n",
    "    \n",
    "\n",
    "class Identity(FittableModule):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    \n",
    "    def fit(self, X:Tensor, y:Tensor):\n",
    "        return X, y\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return X\n",
    "\n",
    "\n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator().manual_seed(0)\n",
    "net = Dense(g1, D, 3)\n",
    "net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print_name(out)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1470, 3]) out torch.float32\n",
      "tensor([[-2.1594, -0.4847,  2.5945],\n",
      "        [ 1.8891, -0.1554,  1.1345],\n",
      "        [ 0.9068,  0.9833, -2.2117],\n",
      "        ...,\n",
      "        [ 2.5997,  1.8578, -5.1088],\n",
      "        [ 9.5946,  0.9112, -3.4865],\n",
      "        [ 2.3178, -0.3220,  1.5852]], grad_fn=<AddmmBackward0>) \n",
      "\n",
      "PairSampledLinear(\n",
      "  (dense): Linear(in_features=11, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "#### Pair Sampled Networks ####\n",
    "###############################\n",
    "\n",
    "\n",
    "class PairSampledLinear(FittableModule):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 in_dim: int, \n",
    "                 out_dim: int,\n",
    "                 sampling_method: Literal['uniform', 'gradient'] = 'gradient'\n",
    "                 ):\n",
    "        \"\"\"Dense MLP layer with pair sampled weights.\n",
    "\n",
    "        Args:\n",
    "            generator (torch.Generator): PRNG object.\n",
    "            in_dim (int): Input dimension.\n",
    "            out_dim (int): Output dimension.\n",
    "            sampling_method (str): Pair sampling method. Uniform or gradient-weighted.\n",
    "        \"\"\"\n",
    "        super(PairSampledLinear, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.dense = nn.Linear(in_dim, out_dim)\n",
    "        self.sampling_method = sampling_method\n",
    "\n",
    "\n",
    "    def fit(self, \n",
    "            X: Tensor, \n",
    "            y: Tensor,\n",
    "        ) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"Given forward-propagated training data X at the previous \n",
    "        hidden layer, and supervised target labels y, fit the weights\n",
    "        iteratively by letting rows of the weight matrix be given by\n",
    "        pairs of samples from X. See paper for more details.\n",
    "\n",
    "        Args:\n",
    "            X (Tensor): Forward-propagated activations of training data, shape (N, d).\n",
    "            y (Tensor): Training labels, shape (N, p).\n",
    "        \n",
    "        Returns:\n",
    "            Forwarded activations and labels [f(X), y].\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            N, d = X.shape\n",
    "            dtype = X.dtype\n",
    "            device = X.device\n",
    "            EPS = torch.tensor(0.1, dtype=dtype, device=device)\n",
    "\n",
    "            #obtain pair indices\n",
    "            n = 5*N\n",
    "            idx1 = torch.arange(0, n, dtype=torch.int32, device=device) % N\n",
    "            delta = torch.randint(1, N, size=(n,), dtype=torch.int32, device=device, generator=self.generator)\n",
    "            idx2 = (idx1 + delta) % N\n",
    "            dx = X[idx2] - X[idx1]\n",
    "            dists = torch.linalg.norm(dx, axis=1, keepdims=True)\n",
    "            dists = torch.maximum(dists, EPS)\n",
    "            \n",
    "            if self.sampling_method==\"gradient\":\n",
    "                #calculate 'gradients'\n",
    "                dy = y[idx2] - y[idx1]\n",
    "                y_norm = torch.linalg.norm(dy, axis=1, keepdims=True) #NOTE 2023 paper uses ord=inf instead of ord=2\n",
    "                grad = (y_norm / dists).reshape(-1) \n",
    "                p = grad/grad.sum()\n",
    "            elif self.sampling_method==\"uniform\":\n",
    "                p = torch.ones(n, dtype=dtype, device=device) / n\n",
    "            else:\n",
    "                raise ValueError(f\"sampling_method must be 'uniform' or 'gradient'. Given: {self.sampling_method}\")\n",
    "\n",
    "            #sample pairs\n",
    "            selected_idx = torch.multinomial(\n",
    "                p,\n",
    "                self.out_dim,\n",
    "                replacement=True,\n",
    "                generator=self.generator\n",
    "                )\n",
    "            idx1 = idx1[selected_idx]\n",
    "            dx = dx[selected_idx]\n",
    "            dists = dists[selected_idx]\n",
    "\n",
    "            #define weights and biases\n",
    "            weights = dx / (dists**2)\n",
    "            biases = -torch.einsum('ij,ij->i', weights, X[idx1]) - 0.5\n",
    "            self.dense.weight.data = weights\n",
    "            self.dense.bias.data = biases\n",
    "            return self(X), y\n",
    "    \n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense(X)\n",
    "    \n",
    "    \n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator().manual_seed(0)\n",
    "net = PairSampledLinear(g1, D, 3)\n",
    "net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print_name(out)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1470, 11]) out torch.float32\n",
      "tensor([[ 6.1840, -2.1159,  0.0658,  ...,  3.1860,  1.2747,  9.8982],\n",
      "        [ 5.8258, -0.8377, -1.6582,  ...,  3.4401,  0.3498,  9.0981],\n",
      "        [ 8.0582, -0.1792, -0.7648,  ...,  3.9503, -0.9390, 11.5953],\n",
      "        ...,\n",
      "        [ 6.4635,  0.1345, -1.4293,  ...,  3.9751, -1.0798, 12.2668],\n",
      "        [ 6.5396,  0.0611, -1.4934,  ...,  4.1369, -1.0826, 11.0263],\n",
      "        [ 5.6176, -0.6594, -1.4017,  ...,  3.6212,  0.3895, 11.4360]],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "SampledResBlock(\n",
      "  (sampled_linear): PairSampledLinear(\n",
      "    (dense): Linear(in_features=11, out_features=3, bias=True)\n",
      "  )\n",
      "  (activation): Tanh()\n",
      "  (upscale): Dense(\n",
      "    (dense): Linear(in_features=3, out_features=11, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "#### Sampled Bottleneck ResNet ####\n",
    "###################################\n",
    "\n",
    "\n",
    "class SampledResBlock(FittableModule):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 hidden_dim: int, \n",
    "                 activation_dim: int,\n",
    "                 activation: nn.Module = nn.Tanh(),\n",
    "                 sampling_method: Literal['uniform', 'gradient'] = 'gradient'\n",
    "                 ):\n",
    "        \"\"\"A sampled layer followed by activation and linear layer.\n",
    "        Equivalent to a 1-hidden-layer Sampled Neural Network.\n",
    "\n",
    "        Args:\n",
    "            generator (torch.Generator): PRNG object.\n",
    "            in_dim (int): Input dimension.\n",
    "            out_dim (int): Output dimension.\n",
    "            activation (nn.Module): Activation function.\n",
    "            sampling_method (str): Pair sampling method. Uniform or gradient-weighted.\n",
    "        \"\"\"\n",
    "        super(SampledResBlock, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.sampled_linear = PairSampledLinear(generator, hidden_dim, activation_dim, sampling_method)\n",
    "        self.activation = activation\n",
    "        self.upscale = Dense(generator, activation_dim, hidden_dim)\n",
    "    \n",
    "\n",
    "    def fit(self, X: Tensor, y: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        with torch.no_grad():\n",
    "            X0 = X\n",
    "            X, y = self.sampled_linear.fit(X, y)\n",
    "            X = self.activation(X)\n",
    "            X, y = self.upscale.fit(X, y)\n",
    "            return X0 + X, y\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X0 = X\n",
    "        X = self.sampled_linear(X)\n",
    "        X = self.activation(X)\n",
    "        X = self.upscale(X)\n",
    "        return X0 + X\n",
    "    \n",
    "    \n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator().manual_seed(0)\n",
    "net = SampledResBlock(g1, D, 3)\n",
    "net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print_name(out)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeCVModule()\n",
      "rmse test 0.7801164\n",
      "rmse train 0.7448608\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "### RidgeCV Layer ###\n",
    "#####################\n",
    "\n",
    "class RidgeCVModule(FittableModule):\n",
    "    def __init__(self, alphas=np.logspace(-1, 3, 10)):\n",
    "        \"\"\"RidgeCV layer using sklearn's RidgeCV. TODO dont use sklearn\"\"\"\n",
    "        super(RidgeCVModule, self).__init__()\n",
    "        self.ridge = RidgeCV(alphas=alphas)\n",
    "\n",
    "    def fit(self, X: Tensor, y: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"Fit the RidgeCV model. TODO dont use sklearn\"\"\"\n",
    "        X_np = X.detach().cpu().numpy().astype(np.float64)\n",
    "        y_np = y.detach().cpu().squeeze().numpy().astype(np.float64)\n",
    "        self.ridge.fit(X_np, y_np)\n",
    "        return self(X), y\n",
    "\n",
    "    def forward(self, X: Tensor) -> Tensor:\n",
    "        \"\"\"Forward pass through the RidgeCV model. TODO dont use sklearn\"\"\"\n",
    "        X_np = X.detach().cpu().numpy().astype(np.float64)\n",
    "        y_pred_np = self.ridge.predict(X_np)\n",
    "        return torch.tensor(y_pred_np, dtype=X.dtype, device=X.device).unsqueeze(1) #TODO unsqueeze???\n",
    "\n",
    "\n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator()\n",
    "net = RidgeCVModule()\n",
    "out_train, _ = net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print(net)\n",
    "\n",
    "print(\"rmse test\", root_mean_squared_error(y_test, out))\n",
    "print(\"rmse train\", root_mean_squared_error(y_train, out_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SampledResNet(\n",
      "  (upsample): PairSampledLinear(\n",
      "    (dense): Linear(in_features=11, out_features=1100, bias=True)\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x SampledResBlock(\n",
      "      (sampled_linear): PairSampledLinear(\n",
      "        (dense): Linear(in_features=1100, out_features=1100, bias=True)\n",
      "      )\n",
      "      (activation): Tanh()\n",
      "      (upscale): Dense(\n",
      "        (dense): Linear(in_features=1100, out_features=1100, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output_layer): RidgeCVModule()\n",
      ")\n",
      "rmse test 0.77934337\n",
      "rmse train 0.7257692\n",
      "16.68100537200059\n"
     ]
    }
   ],
   "source": [
    "class SampledResNet(ResNetBase):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 in_dim: int,\n",
    "                 hidden_dim: int,\n",
    "                 activation_dim: int, #rename to bottleneck dim?\n",
    "                 n_blocks: int,\n",
    "                 activation: nn.Module = nn.Tanh(),\n",
    "                 upsample_module: Literal['dense', 'sampled', 'identity'] = 'dense',\n",
    "                 sampling_method: Literal['uniform', 'gradient'] = 'gradient'\n",
    "                 ):\n",
    "        \"\"\"A ResNet with sampled layers as bottleneck layers.\n",
    "        \"\"\"\n",
    "        if upsample_module==\"dense\":\n",
    "            upsample = Dense(generator, in_dim, hidden_dim)\n",
    "        elif upsample_module==\"sampled\":\n",
    "            upsample = PairSampledLinear(generator, in_dim, hidden_dim, sampling_method)\n",
    "        elif upsample_module==\"identity\":\n",
    "            upsample = Identity()\n",
    "        else:\n",
    "            raise ValueError(f\"upsample_module must be 'dense', 'sampled' or 'identity'. Given: {upsample_module}\")\n",
    "\n",
    "        blocks = [SampledResBlock(generator, \n",
    "                                hidden_dim, \n",
    "                                activation_dim,\n",
    "                                activation,\n",
    "                                sampling_method\n",
    "                                ) for _ in range(n_blocks)]\n",
    "        ridge = RidgeCVModule()\n",
    "        super(SampledResNet, self).__init__(upsample, blocks, ridge)\n",
    "\n",
    "\n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator().manual_seed(int(time.time()*10))\n",
    "net = SampledResNet(g1, D, 100*D, 100*D, 6, upsample_module='sampled', sampling_method='uniform')\n",
    "out_train, _ = net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print(net)\n",
    "\n",
    "print(\"rmse test\", root_mean_squared_error(y_test.detach().cpu().numpy(), out.detach().cpu().numpy()))\n",
    "print(\"rmse train\", root_mean_squared_error(y_train.detach().cpu().numpy(), out_train.detach().cpu().numpy()))\n",
    "print(net.output_layer.ridge.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1470, 22]) out torch.float32\n",
      "tensor([[-0.9737, -0.4500,  0.9889,  ..., -1.0000,  0.8248,  0.8880],\n",
      "        [ 0.9553, -0.1542,  0.8126,  ..., -1.0000,  0.9140,  0.9160],\n",
      "        [ 0.7196,  0.7545, -0.9763,  ..., -0.9693, -0.4671, -0.3324],\n",
      "        ...,\n",
      "        [ 0.9890,  0.9525, -0.9999,  ...,  0.1547, -0.9100, -0.8899],\n",
      "        [ 1.0000,  0.7217, -0.9981,  ..., -1.0000,  0.9407,  0.7410],\n",
      "        [ 0.9808, -0.3113,  0.9194,  ..., -1.0000,  0.9560,  0.9517]],\n",
      "       grad_fn=<TanhBackward0>) \n",
      "\n",
      "SampledAndActivation(\n",
      "  (sampled_linear): PairSampledLinear(\n",
      "    (dense): Linear(in_features=11, out_features=22, bias=True)\n",
      "  )\n",
      "  (activation): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SampledAndActivation(FittableModule):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 in_dim: int,\n",
    "                 out_dim: int, \n",
    "                 activation: nn.Module = nn.Tanh(),\n",
    "                 sampling_method: Literal['uniform', 'gradient'] = 'gradient'\n",
    "                 ):\n",
    "        \"\"\"TODO\n",
    "        \"\"\"\n",
    "        super(SampledAndActivation, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.sampled_linear = PairSampledLinear(generator, in_dim, out_dim, sampling_method)\n",
    "        self.activation = activation\n",
    "    \n",
    "\n",
    "    def fit(self, X: Tensor, y: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        with torch.no_grad():\n",
    "            X, y = self.sampled_linear.fit(X, y)\n",
    "            X = self.activation(X)\n",
    "            return X, y\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.sampled_linear(X)\n",
    "        X = self.activation(X)\n",
    "        return X\n",
    "\n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator().manual_seed(0)\n",
    "net = SampledAndActivation(g1, D, 2*D)\n",
    "net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print_name(out)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1470, 11]) out torch.float32\n",
      "tensor([[ 6.3263, -0.1300,  1.3389,  ...,  4.2321,  1.4003, 10.2280],\n",
      "        [ 7.9553,  0.1558,  1.0726,  ...,  4.1209,  1.3236,  9.2552],\n",
      "        [ 8.3196,  0.8945, -0.2363,  ...,  2.0734,  1.1889, 11.4235],\n",
      "        ...,\n",
      "        [ 6.9890,  1.1525, -0.7399,  ...,  2.1400,  0.7127, 12.4013],\n",
      "        [ 7.1000,  0.9517, -0.7281,  ...,  2.7937, -0.3981,  9.8153],\n",
      "        [ 7.8808,  0.2687,  1.4994,  ...,  4.2782,  1.3030, 11.5181]],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "SampledODEBlock(\n",
      "  (sampled_linear): PairSampledLinear(\n",
      "    (dense): Linear(in_features=11, out_features=11, bias=True)\n",
      "  )\n",
      "  (activation): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SampledODEBlock(FittableModule):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 hidden_dim: int, \n",
    "                 activation: nn.Module = nn.Tanh(),\n",
    "                 sampling_method: Literal['uniform', 'gradient'] = 'gradient'\n",
    "                 ):\n",
    "        \"\"\"TODO\n",
    "\n",
    "        Args:\n",
    "            generator (torch.Generator): PRNG object.\n",
    "            hidden_dim (int): Hidden size.\n",
    "            activation (nn.Module): Activation function.\n",
    "            sampling_method (str): Pair sampling method. Uniform or gradient-weighted.\n",
    "        \"\"\"\n",
    "        super(SampledODEBlock, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.sampled_linear = PairSampledLinear(generator, hidden_dim, hidden_dim, sampling_method)\n",
    "        self.activation = activation\n",
    "    \n",
    "\n",
    "    def fit(self, X: Tensor, y: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        with torch.no_grad():\n",
    "            X0 = X\n",
    "            X, y = self.sampled_linear.fit(X, y)\n",
    "            X = self.activation(X)\n",
    "            return X0 + X, y\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X0 = X\n",
    "        X = self.sampled_linear(X)\n",
    "        X = self.activation(X)\n",
    "        return X0 + X\n",
    "    \n",
    "    \n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator().manual_seed(0)\n",
    "net = SampledODEBlock(g1, D)\n",
    "net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print_name(out)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SampledEulerODE(\n",
      "  (upsample): SampledAndActivation(\n",
      "    (sampled_linear): PairSampledLinear(\n",
      "      (dense): Linear(in_features=11, out_features=1100, bias=True)\n",
      "    )\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x SampledODEBlock(\n",
      "      (sampled_linear): PairSampledLinear(\n",
      "        (dense): Linear(in_features=1100, out_features=1100, bias=True)\n",
      "      )\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (output_layer): RidgeCVModule()\n",
      ")\n",
      "rmse test 0.79153246\n",
      "rmse train 0.6922127\n",
      "2.1544346900318834\n"
     ]
    }
   ],
   "source": [
    "class SampledEulerODE(ResNetBase):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 in_dim: int,\n",
    "                 hidden_dim: int,\n",
    "                 n_blocks: int,\n",
    "                 activation: nn.Module = nn.Tanh(),\n",
    "                 upsample_module: Literal['dense', 'sampled', 'identity'] = 'dense',\n",
    "                 sampling_method: Literal['uniform', 'gradient'] = 'gradient'\n",
    "                 ):\n",
    "        \"\"\"A ResNet with sampled layers as bottleneck layers.\"\"\"\n",
    "        if upsample_module==\"dense\":\n",
    "            upsample = Dense(generator, in_dim, hidden_dim)\n",
    "        elif upsample_module==\"sampled\":\n",
    "            upsample = SampledAndActivation(generator, in_dim, hidden_dim, activation, sampling_method)\n",
    "        elif upsample_module==\"identity\":\n",
    "            upsample = Identity()\n",
    "        else:\n",
    "            raise ValueError(f\"upsample_module must be 'dense', 'sampled' or 'identity'. Given: {upsample_module}\")\n",
    "        \n",
    "        blocks = [SampledODEBlock(generator,\n",
    "                                hidden_dim,\n",
    "                                activation,\n",
    "                                sampling_method\n",
    "                                ) for _ in range(n_blocks)]\n",
    "        ridge = RidgeCVModule()\n",
    "        super(SampledEulerODE, self).__init__(upsample, blocks, ridge)\n",
    "\n",
    "\n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator().manual_seed(int(time.time()*10))\n",
    "net = SampledEulerODE(g1, D, 100*D, 6, upsample_module='sampled', sampling_method='gradient')\n",
    "out_train, _ = net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print(net)\n",
    "\n",
    "print(\"rmse test\", root_mean_squared_error(y_test.detach().cpu().numpy(), out.detach().cpu().numpy()))\n",
    "print(\"rmse train\", root_mean_squared_error(y_train.detach().cpu().numpy(), out_train.detach().cpu().numpy()))\n",
    "print(net.output_layer.ridge.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomFeatureODE(\n",
      "  (upsample): LinearAndActivation(\n",
      "    (linear): Dense(\n",
      "      (dense): Linear(in_features=11, out_features=1100, bias=True)\n",
      "    )\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x RandomFeatBlock(\n",
      "      (linear): Dense(\n",
      "        (dense): Linear(in_features=1100, out_features=1100, bias=True)\n",
      "      )\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (output_layer): RidgeCVModule()\n",
      ")\n",
      "rmse test 0.7666988\n",
      "rmse train 0.6866741\n",
      "46.41588833612777\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "### Random Feature ResNet ###\n",
    "#############################\n",
    "class LinearAndActivation(FittableModule):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 in_dim: int,\n",
    "                 out_dim: int, \n",
    "                 activation: nn.Module = nn.Tanh(),\n",
    "                 ):\n",
    "        \"\"\"TODO\n",
    "        \"\"\"\n",
    "        super(LinearAndActivation, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.linear = Dense(generator, in_dim, out_dim)\n",
    "        self.activation = activation\n",
    "    \n",
    "\n",
    "    def fit(self, X: Tensor, y: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        with torch.no_grad():\n",
    "            X, y = self.linear.fit(X, y)\n",
    "            X = self.activation(X)\n",
    "            return X, y\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        X = self.activation(X)\n",
    "        return X\n",
    "    \n",
    "\n",
    "class RandomFeatBlock(FittableModule):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 hidden_dim: int, \n",
    "                 activation: nn.Module = nn.Tanh(),\n",
    "                 ):\n",
    "        \"\"\"TODO\n",
    "\n",
    "        Args:\n",
    "            generator (torch.Generator): PRNG object.\n",
    "            hidden_dim (int): Hidden size.\n",
    "            activation (nn.Module): Activation function.\n",
    "        \"\"\"\n",
    "        super(RandomFeatBlock, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.linear = Dense(generator, hidden_dim, hidden_dim)\n",
    "        self.activation = activation\n",
    "    \n",
    "\n",
    "    def fit(self, X: Tensor, y: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        with torch.no_grad():\n",
    "            X0 = X\n",
    "            X, y = self.linear.fit(X, y)\n",
    "            X = self.activation(X)\n",
    "            return X0 + X, y\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X0 = X\n",
    "        X = self.linear(X)\n",
    "        X = self.activation(X)\n",
    "        return X0 + X\n",
    "\n",
    "\n",
    "class RandomFeatureODE(ResNetBase):\n",
    "    def __init__(self,\n",
    "                 generator: torch.Generator,\n",
    "                 in_dim: int,\n",
    "                 hidden_dim: int,\n",
    "                 n_blocks: int,\n",
    "                 activation: nn.Module = nn.Tanh(),\n",
    "                 ):\n",
    "        \"\"\"A ResNet random feature MLP.\"\"\"\n",
    "        upsample = LinearAndActivation(generator, in_dim, hidden_dim, activation)\n",
    "        blocks = [RandomFeatBlock(generator,\n",
    "                                hidden_dim,\n",
    "                                activation,\n",
    "                                ) for _ in range(n_blocks)]\n",
    "        ridge = RidgeCVModule()\n",
    "        super(RandomFeatureODE, self).__init__(upsample, blocks, ridge)\n",
    "\n",
    "\n",
    "D = X_train.shape[1]\n",
    "g1 = torch.Generator().manual_seed(int(time.time()*10))\n",
    "net = RandomFeatureODE(g1, D, 100*D, 6)\n",
    "out_train, _ = net.fit(X_train, y_train)\n",
    "out = net(X_test)\n",
    "print(net)\n",
    "\n",
    "print(\"rmse test\", root_mean_squared_error(y_test.detach().cpu().numpy(), out.detach().cpu().numpy()))\n",
    "print(\"rmse train\", root_mean_squared_error(y_train.detach().cpu().numpy(), out_train.detach().cpu().numpy()))\n",
    "print(net.output_layer.ridge.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def get_activation(name, activations):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "\n",
    "def register_hooks(model, activations):\n",
    "    for name, layer in model.named_modules():\n",
    "        print(name)\n",
    "        if \".dense\" not in name:\n",
    "            layer.register_forward_hook(get_activation(name, activations))\n",
    "\n",
    "\n",
    "\n",
    "def neuron_distribution_for_each_layer(X_train, y_train, X_test):\n",
    "    D = X_train.shape[1]\n",
    "    n_layers = 2\n",
    "    g1 = torch.Generator().manual_seed(0)\n",
    "    model = SampledEulerODE(g1, D, 10*D, n_layers, upsample_module='sampled', sampling_method='gradient')\n",
    "    #model = SampledResNet(g1, D, 10*D, 10*D, n_layers, upsample_module='sampled', sampling_method='gradient')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    activations = {}\n",
    "    register_hooks(model, activations)\n",
    "    \n",
    "    # Forward pass\n",
    "    model(X_test)\n",
    "    \n",
    "    # Plot input data distribution\n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "    fig.add_trace(go.Histogram(x=X_train.flatten().cpu().numpy(), nbinsx=50, name='Train', histnorm='probability density', opacity=0.5))\n",
    "    fig.add_trace(go.Histogram(x=X_test.flatten().cpu().numpy(), nbinsx=50, name='Test', histnorm='probability density', opacity=0.5))\n",
    "    fig.update_layout(title_text='Input Data Distribution', xaxis_title='Input Feature Value', yaxis_title='Probability Density', barmode='overlay')\n",
    "    fig.show()\n",
    "\n",
    "    # Plot activations\n",
    "    for name, activation in activations.items():\n",
    "        fig = make_subplots(rows=1, cols=1)\n",
    "        fig.add_trace(go.Histogram(x=activation.flatten().cpu().numpy(), nbinsx=50, name='Activation', histnorm='probability density', opacity=0.5))\n",
    "        fig.update_layout(title_text=f'Activations at Layer: {name}', xaxis_title='Activation Value', yaxis_title='Probability Density', barmode='overlay')\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "neuron_distribution_for_each_layer(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit on a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_allmodels_1dataset(\n",
    "        generator: torch.Generator,\n",
    "        X_train: Tensor,\n",
    "        y_train: Tensor,\n",
    "        X_test: Tensor,\n",
    "        y_test: Tensor,\n",
    "        ):\n",
    "    \n",
    "    D = X_train.shape[1]\n",
    "    hidden_size = 512\n",
    "    activation_dim = 2*hidden_size\n",
    "    n_blocks = 3\n",
    "\n",
    "   # (name, model, kwargs)\n",
    "    model_list = [\n",
    "        [\"Tabular RidgeCV\", RidgeCVModule, {}],\n",
    "\n",
    "        [\"Rand Proj\", SampledResNet, \n",
    "                {\"generator\": generator, \n",
    "                \"in_dim\": D, \n",
    "                \"hidden_dim\": hidden_size, \n",
    "                \"activation_dim\": None, \n",
    "                \"n_blocks\": 0, \n",
    "                \"upsample_module\": \"dense\"}],\n",
    "\n",
    "        [\"1-Layer SampledNet Uniform\", SampledResNet,  ####TODO change to SampledAndActivation\n",
    "                {\"generator\": generator, \n",
    "                \"in_dim\": D, \n",
    "                \"hidden_dim\": hidden_size, \n",
    "                \"activation_dim\": None, \n",
    "                \"n_blocks\": 0, \n",
    "                \"upsample_module\": \"sampled\",\n",
    "                \"sampling_method\": \"uniform\"}],\n",
    "\n",
    "        [\"1-Layer SampledNet Gradient\", SampledResNet, \n",
    "                {\"generator\": generator, \n",
    "                \"in_dim\": D, \n",
    "                \"hidden_dim\": hidden_size, \n",
    "                \"activation_dim\": None, \n",
    "                \"n_blocks\": 0, \n",
    "                \"upsample_module\": \"sampled\",\n",
    "                \"sampling_method\": \"gradient\"}],\n",
    "\n",
    "        [\"Sampled ResNet Uniform\", SampledResNet,\n",
    "                {\"generator\": generator, \n",
    "                \"in_dim\": D, \n",
    "                \"hidden_dim\": hidden_size, \n",
    "                \"activation_dim\": activation_dim, \n",
    "                \"n_blocks\": n_blocks, \n",
    "                \"upsample_module\": \"sampled\",\n",
    "                \"sampling_method\": \"uniform\"}],\n",
    "\n",
    "        [\"Sampled ResNet Gradient\", SampledResNet,\n",
    "                {\"generator\": generator, \n",
    "                \"in_dim\": D, \n",
    "                \"hidden_dim\": hidden_size, \n",
    "                \"activation_dim\": activation_dim, \n",
    "                \"n_blocks\": n_blocks, \n",
    "                \"upsample_module\": \"sampled\",\n",
    "                \"sampling_method\": \"gradient\"}],\n",
    "\n",
    "        [\"Sampled EulerODE Uniform\", SampledEulerODE,\n",
    "                {\"generator\": generator, \n",
    "                \"in_dim\": D, \n",
    "                \"hidden_dim\": hidden_size, \n",
    "                \"n_blocks\": n_blocks, \n",
    "                \"upsample_module\": \"sampled\",\n",
    "                \"sampling_method\": \"uniform\"}],\n",
    "\n",
    "        [\"Sampled EulerODE Gradient\", SampledEulerODE,\n",
    "                {\"generator\": generator, \n",
    "                \"in_dim\": D, \n",
    "                \"hidden_dim\": hidden_size, \n",
    "                \"n_blocks\": n_blocks, \n",
    "                \"upsample_module\": \"sampled\",\n",
    "                \"sampling_method\": \"gradient\"}],\n",
    "\n",
    "        [\"Random Feature ODE\", RandomFeatureODE,\n",
    "                {\"generator\": generator, \n",
    "                \"in_dim\": D, \n",
    "                \"hidden_dim\": hidden_size, \n",
    "                \"n_blocks\": n_blocks}],\n",
    "                \n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    model_names = []\n",
    "    for name, model, model_args in model_list:\n",
    "        t0 = time.perf_counter()\n",
    "        model = model(**model_args).to(X_train.device)\n",
    "        pred_train, _ = model.fit(X_train, y_train)\n",
    "        t1 = time.perf_counter()\n",
    "        pred_test = model(X_test)\n",
    "        t2 = time.perf_counter()\n",
    "        rmse_train = root_mean_squared_error(y_train.cpu(), pred_train.cpu()) \n",
    "        rmse_test = root_mean_squared_error(y_test.cpu(), pred_test.cpu())\n",
    "\n",
    "        result = np.array( [rmse_train, rmse_test, t1-t0, t2-t1] )\n",
    "        results.append( result )\n",
    "        model_names.append( name )\n",
    "\n",
    "    return model_names, results\n",
    "\n",
    "\n",
    "\n",
    "def run_all_experiments(\n",
    "        dataset_ids: List,\n",
    "        name_save: str = \"PLACEHOLDER\",\n",
    "        ):\n",
    "#     # Fetch the collection with ID 353\n",
    "#     collection = openml.study.get_suite(353)\n",
    "#     dataset_ids = collection.data\n",
    "\n",
    "    # Fetch and process each dataset\n",
    "    experiments = {}\n",
    "    for i, dataset_id in enumerate(dataset_ids):\n",
    "        print(dataset_id)\n",
    "        device = \"cuda\"\n",
    "        X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id, split_seed=0, device=device)\n",
    "        generator = torch.Generator(device=device).manual_seed(0)\n",
    "        results = run_allmodels_1dataset(\n",
    "            generator, X_train, y_train, X_test, y_test, \n",
    "            )\n",
    "        experiments[dataset_id] = results\n",
    "        print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset_id}\")\n",
    "\n",
    "    # Save results\n",
    "    # Assuming experiments is a dict where keys are dataset names and values are tuples (model_names, results)\n",
    "    attributes = [\"RMSE_train\", \"RMSE_test\", \"t_fit\", \"t_feat\"]\n",
    "    data_list = []\n",
    "    # Process the data\n",
    "    for dataset_name, (model_names, results) in experiments.items():\n",
    "        dataset_data = {}\n",
    "        for attr_idx, attribute in enumerate(attributes):\n",
    "            for model_idx, model_name in enumerate(model_names):\n",
    "                dataset_data[(attribute, model_name)] = results[model_idx][attr_idx]\n",
    "        data_list.append(pd.DataFrame(dataset_data, index=[dataset_name]))\n",
    "\n",
    "    # Combine all datasets into a single DataFrame\n",
    "    df = pd.concat(data_list)\n",
    "    df = df.sort_index(axis=1)\n",
    "    print(df)\n",
    "    df.to_pickle(f\"OpenML_reg_{name_save}.pkl\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44973\n",
      " 1/20 Processed dataset 44973\n",
      "44975\n",
      " 2/20 Processed dataset 44975\n",
      "44980\n",
      " 3/20 Processed dataset 44980\n",
      "44981\n",
      " 4/20 Processed dataset 44981\n",
      "45402\n",
      " 5/20 Processed dataset 45402\n",
      "44994\n",
      " 6/20 Processed dataset 44994\n",
      "44957\n",
      " 7/20 Processed dataset 44957\n",
      "44970\n",
      " 8/20 Processed dataset 44970\n",
      "44959\n",
      " 9/20 Processed dataset 44959\n",
      "44960\n",
      " 10/20 Processed dataset 44960\n",
      "44963\n",
      " 11/20 Processed dataset 44963\n",
      "44976\n",
      " 12/20 Processed dataset 44976\n",
      "44977\n",
      " 13/20 Processed dataset 44977\n",
      "44983\n",
      " 14/20 Processed dataset 44983\n",
      "44964\n",
      " 15/20 Processed dataset 44964\n",
      "44965\n",
      " 16/20 Processed dataset 44965\n",
      "44978\n",
      " 17/20 Processed dataset 44978\n",
      "44969\n",
      " 18/20 Processed dataset 44969\n",
      "44972\n",
      " 19/20 Processed dataset 44972\n",
      "44971\n",
      " 20/20 Processed dataset 44971\n",
      "                        RMSE_test                                       \\\n",
      "      1-Layer SampledNet Gradient 1-Layer SampledNet Uniform Rand Proj   \n",
      "44973                    0.595157                   0.595159  0.595159   \n",
      "44975                    0.006491                   0.006491  0.006491   \n",
      "44980                    0.771309                   0.771331  0.771314   \n",
      "44981                    0.904397                   0.904818  0.904248   \n",
      "45402                    0.707004                   0.706447  0.706434   \n",
      "44994                    0.296740                   0.296623  0.296760   \n",
      "44957                    0.674052                   0.674364  0.674497   \n",
      "44970                    0.667694                   0.666439  0.666413   \n",
      "44959                    0.542102                   0.542124  0.542091   \n",
      "44960                    0.305280                   0.306052  0.304332   \n",
      "44963                    0.839763                   0.839763  0.839762   \n",
      "44976                    0.294862                   0.294862  0.294862   \n",
      "44977                    0.587713                   0.587714  0.587718   \n",
      "44983                    0.586479                   0.586480  0.586517   \n",
      "44964                    0.528415                   0.529091  0.517317   \n",
      "44965                    0.918889                   0.922791  0.912971   \n",
      "44978                    0.323723                   0.323664  0.323552   \n",
      "44969                    0.455312                   0.457275  0.399215   \n",
      "44972                    0.766537                   0.766897  0.766484   \n",
      "44971                    0.878150                   0.878165  0.878167   \n",
      "\n",
      "                                                                             \\\n",
      "      Random Feature ODE Sampled EulerODE Gradient Sampled EulerODE Uniform   \n",
      "44973           0.340580                  0.265267                 0.262816   \n",
      "44975           0.140689                  0.011393                 0.013024   \n",
      "44980           0.422342                  0.425118                 0.440368   \n",
      "44981           0.906131                  0.905082                 0.904194   \n",
      "45402           0.555939                  0.593257                 0.596652   \n",
      "44994           0.215857                  0.225381                 0.226724   \n",
      "44957           0.332879                  0.295786                 0.382020   \n",
      "44970           0.609266                  0.632369                 0.632836   \n",
      "44959           0.362881                  0.331210                 0.347704   \n",
      "44960           0.104895                  0.112107                 0.155929   \n",
      "44963           0.716268                  0.740217                 0.749506   \n",
      "44976           0.215308                  0.200758                 0.203788   \n",
      "44977           0.492622                  0.505668                 0.508187   \n",
      "44983           0.368646                  0.348441                 0.344054   \n",
      "44964           0.437937                  0.412748                 0.433556   \n",
      "44965           0.882181                  0.901263                 0.904077   \n",
      "44978           0.220391                  0.147549                 0.160053   \n",
      "44969           0.012125                  0.033941                 0.104237   \n",
      "44972           0.754416                  0.770870                 0.769193   \n",
      "44971           0.823269                  0.823599                 0.817295   \n",
      "\n",
      "                                                                      \\\n",
      "      Sampled ResNet Gradient Sampled ResNet Uniform Tabular RidgeCV   \n",
      "44973                0.274106               0.273519        0.595158   \n",
      "44975                0.009447               0.010734        0.006491   \n",
      "44980                0.392726               0.457173        0.771311   \n",
      "44981                0.903146               0.903209        0.904478   \n",
      "45402                0.593615               0.615447        0.706690   \n",
      "44994                0.311644               0.256188        0.296725   \n",
      "44957                0.291586               0.346770        0.674484   \n",
      "44970                0.625500               0.627493        0.666021   \n",
      "44959                0.346756               0.360977        0.542088   \n",
      "44960                0.099897               0.114104        0.304327   \n",
      "44963                0.745673               0.763325        0.839762   \n",
      "44976                0.203216               0.206749        0.294862   \n",
      "44977                0.519461               0.522745        0.587720   \n",
      "44983                0.347415               0.347266        0.586507   \n",
      "44964                0.426783               0.439831        0.517322   \n",
      "44965                0.901693               0.895627        0.914663   \n",
      "44978                0.145443               0.156640        0.323560   \n",
      "44969                0.014478               0.033186        0.413739   \n",
      "44972                0.771494               0.775350        0.766536   \n",
      "44971                0.825090               0.822749        0.878211   \n",
      "\n",
      "                       RMSE_train  ...          t_feat  \\\n",
      "      1-Layer SampledNet Gradient  ... Tabular RidgeCV   \n",
      "44973                    0.594543  ...        0.000989   \n",
      "44975                    0.006807  ...        0.015274   \n",
      "44980                    0.761382  ...        0.000885   \n",
      "44981                    0.917619  ...        0.001368   \n",
      "45402                    0.636660  ...        0.000312   \n",
      "44994                    0.298746  ...        0.000326   \n",
      "44957                    0.689486  ...        0.000398   \n",
      "44970                    0.623745  ...        0.000282   \n",
      "44959                    0.587679  ...        0.000287   \n",
      "44960                    0.287332  ...        0.000273   \n",
      "44963                    0.839653  ...        0.000967   \n",
      "44976                    0.299714  ...        0.007894   \n",
      "44977                    0.579844  ...        0.001750   \n",
      "44983                    0.558920  ...        0.000539   \n",
      "44964                    0.527542  ...        0.002158   \n",
      "44965                    0.860496  ...        0.000879   \n",
      "44978                    0.316859  ...        0.001248   \n",
      "44969                    0.446160  ...        0.001039   \n",
      "44972                    0.789319  ...        0.000339   \n",
      "44971                    0.838350  ...        0.000371   \n",
      "\n",
      "                            t_fit                                       \\\n",
      "      1-Layer SampledNet Gradient 1-Layer SampledNet Uniform Rand Proj   \n",
      "44973                    1.348948                   1.153801  1.269893   \n",
      "44975                    6.640887                   6.861540  7.586293   \n",
      "44980                    0.684261                   0.643247  0.704401   \n",
      "44981                    0.683061                   0.706151  0.715020   \n",
      "45402                    0.357183                   0.384122  0.352507   \n",
      "44994                    0.169758                   0.177873  0.225159   \n",
      "44957                    0.226856                   0.258456  0.258957   \n",
      "44970                    0.169073                   0.210603  0.192638   \n",
      "44959                    0.196756                   0.218997  0.197776   \n",
      "44960                    0.207350                   0.186880  0.118883   \n",
      "44963                    4.087139                   4.113773  4.108301   \n",
      "44976                    4.386805                   4.412602  4.603976   \n",
      "44977                    1.704910                   1.693120  1.787471   \n",
      "44983                    1.362774                   1.146800  1.224869   \n",
      "44964                    1.739051                   1.677194  1.671669   \n",
      "44965                    0.198519                   0.223081  0.187666   \n",
      "44978                    0.694534                   0.678560  0.874726   \n",
      "44969                    1.015533                   0.987846  1.031700   \n",
      "44972                    0.350499                   0.256285  0.326093   \n",
      "44971                    0.501070                   0.504026  0.523274   \n",
      "\n",
      "                                                                             \\\n",
      "      Random Feature ODE Sampled EulerODE Gradient Sampled EulerODE Uniform   \n",
      "44973           1.649985                  0.974434                 1.013453   \n",
      "44975           6.671903                  6.953238                 6.668116   \n",
      "44980           0.695290                  0.679370                 0.641010   \n",
      "44981           0.633572                  0.672336                 0.689704   \n",
      "45402           0.336089                  0.387642                 0.345023   \n",
      "44994           0.186932                  0.184228                 0.133652   \n",
      "44957           0.265192                  0.199013                 0.242993   \n",
      "44970           0.164729                  0.173500                 0.174261   \n",
      "44959           0.196601                  0.179508                 0.181714   \n",
      "44960           0.161881                  0.210007                 0.240221   \n",
      "44963           4.026799                  4.126841                 4.138351   \n",
      "44976           4.608124                  4.527428                 4.443512   \n",
      "44977           1.697954                  1.691458                 1.699902   \n",
      "44983           1.124959                  1.133193                 1.126250   \n",
      "44964           1.867097                  1.771377                 1.780905   \n",
      "44965           0.241369                  0.219469                 0.224255   \n",
      "44978           0.734671                  0.756588                 0.702576   \n",
      "44969           1.030491                  0.933103                 0.993429   \n",
      "44972           0.305879                  0.240524                 0.244902   \n",
      "44971           0.500311                  0.485174                 0.499080   \n",
      "\n",
      "                                                                      \n",
      "      Sampled ResNet Gradient Sampled ResNet Uniform Tabular RidgeCV  \n",
      "44973                1.656375               1.336837        0.021568  \n",
      "44975                6.732856               6.719438        0.567887  \n",
      "44980                0.696140               0.718928        0.023043  \n",
      "44981                0.699537               0.759174        0.061516  \n",
      "45402                0.350022               0.421070        0.011551  \n",
      "44994                0.192889               0.188467        0.021471  \n",
      "44957                0.237008               0.225692        0.003265  \n",
      "44970                0.162065               0.250307        0.002859  \n",
      "44959                0.169238               0.247462        0.003169  \n",
      "44960                0.217899               0.166685        0.002824  \n",
      "44963                4.119126               4.205495        0.082731  \n",
      "44976                4.543556               4.638810        0.166540  \n",
      "44977                1.767682               1.771075        0.039875  \n",
      "44983                1.149540               1.192606        0.031689  \n",
      "44964                1.802348               1.829578        0.313549  \n",
      "44965                0.218693               0.203323        0.032085  \n",
      "44978                0.702984               0.709211        0.043122  \n",
      "44969                0.996159               0.998527        0.045086  \n",
      "44972                0.237412               0.289097        0.014406  \n",
      "44971                0.552105               0.529770        0.014268  \n",
      "\n",
      "[20 rows x 36 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"9\" halign=\"left\">RMSE_test</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>...</th>\n",
       "      <th>t_feat</th>\n",
       "      <th colspan=\"9\" halign=\"left\">t_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>1-Layer SampledNet Gradient</th>\n",
       "      <th>1-Layer SampledNet Uniform</th>\n",
       "      <th>Rand Proj</th>\n",
       "      <th>Random Feature ODE</th>\n",
       "      <th>Sampled EulerODE Gradient</th>\n",
       "      <th>Sampled EulerODE Uniform</th>\n",
       "      <th>Sampled ResNet Gradient</th>\n",
       "      <th>Sampled ResNet Uniform</th>\n",
       "      <th>Tabular RidgeCV</th>\n",
       "      <th>1-Layer SampledNet Gradient</th>\n",
       "      <th>...</th>\n",
       "      <th>Tabular RidgeCV</th>\n",
       "      <th>1-Layer SampledNet Gradient</th>\n",
       "      <th>1-Layer SampledNet Uniform</th>\n",
       "      <th>Rand Proj</th>\n",
       "      <th>Random Feature ODE</th>\n",
       "      <th>Sampled EulerODE Gradient</th>\n",
       "      <th>Sampled EulerODE Uniform</th>\n",
       "      <th>Sampled ResNet Gradient</th>\n",
       "      <th>Sampled ResNet Uniform</th>\n",
       "      <th>Tabular RidgeCV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44973</th>\n",
       "      <td>0.595157</td>\n",
       "      <td>0.595159</td>\n",
       "      <td>0.595159</td>\n",
       "      <td>0.340580</td>\n",
       "      <td>0.265267</td>\n",
       "      <td>0.262816</td>\n",
       "      <td>0.274106</td>\n",
       "      <td>0.273519</td>\n",
       "      <td>0.595158</td>\n",
       "      <td>0.594543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>1.348948</td>\n",
       "      <td>1.153801</td>\n",
       "      <td>1.269893</td>\n",
       "      <td>1.649985</td>\n",
       "      <td>0.974434</td>\n",
       "      <td>1.013453</td>\n",
       "      <td>1.656375</td>\n",
       "      <td>1.336837</td>\n",
       "      <td>0.021568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44975</th>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.140689</td>\n",
       "      <td>0.011393</td>\n",
       "      <td>0.013024</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>0.010734</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>6.640887</td>\n",
       "      <td>6.861540</td>\n",
       "      <td>7.586293</td>\n",
       "      <td>6.671903</td>\n",
       "      <td>6.953238</td>\n",
       "      <td>6.668116</td>\n",
       "      <td>6.732856</td>\n",
       "      <td>6.719438</td>\n",
       "      <td>0.567887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44980</th>\n",
       "      <td>0.771309</td>\n",
       "      <td>0.771331</td>\n",
       "      <td>0.771314</td>\n",
       "      <td>0.422342</td>\n",
       "      <td>0.425118</td>\n",
       "      <td>0.440368</td>\n",
       "      <td>0.392726</td>\n",
       "      <td>0.457173</td>\n",
       "      <td>0.771311</td>\n",
       "      <td>0.761382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.684261</td>\n",
       "      <td>0.643247</td>\n",
       "      <td>0.704401</td>\n",
       "      <td>0.695290</td>\n",
       "      <td>0.679370</td>\n",
       "      <td>0.641010</td>\n",
       "      <td>0.696140</td>\n",
       "      <td>0.718928</td>\n",
       "      <td>0.023043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44981</th>\n",
       "      <td>0.904397</td>\n",
       "      <td>0.904818</td>\n",
       "      <td>0.904248</td>\n",
       "      <td>0.906131</td>\n",
       "      <td>0.905082</td>\n",
       "      <td>0.904194</td>\n",
       "      <td>0.903146</td>\n",
       "      <td>0.903209</td>\n",
       "      <td>0.904478</td>\n",
       "      <td>0.917619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.683061</td>\n",
       "      <td>0.706151</td>\n",
       "      <td>0.715020</td>\n",
       "      <td>0.633572</td>\n",
       "      <td>0.672336</td>\n",
       "      <td>0.689704</td>\n",
       "      <td>0.699537</td>\n",
       "      <td>0.759174</td>\n",
       "      <td>0.061516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45402</th>\n",
       "      <td>0.707004</td>\n",
       "      <td>0.706447</td>\n",
       "      <td>0.706434</td>\n",
       "      <td>0.555939</td>\n",
       "      <td>0.593257</td>\n",
       "      <td>0.596652</td>\n",
       "      <td>0.593615</td>\n",
       "      <td>0.615447</td>\n",
       "      <td>0.706690</td>\n",
       "      <td>0.636660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.357183</td>\n",
       "      <td>0.384122</td>\n",
       "      <td>0.352507</td>\n",
       "      <td>0.336089</td>\n",
       "      <td>0.387642</td>\n",
       "      <td>0.345023</td>\n",
       "      <td>0.350022</td>\n",
       "      <td>0.421070</td>\n",
       "      <td>0.011551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44994</th>\n",
       "      <td>0.296740</td>\n",
       "      <td>0.296623</td>\n",
       "      <td>0.296760</td>\n",
       "      <td>0.215857</td>\n",
       "      <td>0.225381</td>\n",
       "      <td>0.226724</td>\n",
       "      <td>0.311644</td>\n",
       "      <td>0.256188</td>\n",
       "      <td>0.296725</td>\n",
       "      <td>0.298746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.169758</td>\n",
       "      <td>0.177873</td>\n",
       "      <td>0.225159</td>\n",
       "      <td>0.186932</td>\n",
       "      <td>0.184228</td>\n",
       "      <td>0.133652</td>\n",
       "      <td>0.192889</td>\n",
       "      <td>0.188467</td>\n",
       "      <td>0.021471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44957</th>\n",
       "      <td>0.674052</td>\n",
       "      <td>0.674364</td>\n",
       "      <td>0.674497</td>\n",
       "      <td>0.332879</td>\n",
       "      <td>0.295786</td>\n",
       "      <td>0.382020</td>\n",
       "      <td>0.291586</td>\n",
       "      <td>0.346770</td>\n",
       "      <td>0.674484</td>\n",
       "      <td>0.689486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.226856</td>\n",
       "      <td>0.258456</td>\n",
       "      <td>0.258957</td>\n",
       "      <td>0.265192</td>\n",
       "      <td>0.199013</td>\n",
       "      <td>0.242993</td>\n",
       "      <td>0.237008</td>\n",
       "      <td>0.225692</td>\n",
       "      <td>0.003265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44970</th>\n",
       "      <td>0.667694</td>\n",
       "      <td>0.666439</td>\n",
       "      <td>0.666413</td>\n",
       "      <td>0.609266</td>\n",
       "      <td>0.632369</td>\n",
       "      <td>0.632836</td>\n",
       "      <td>0.625500</td>\n",
       "      <td>0.627493</td>\n",
       "      <td>0.666021</td>\n",
       "      <td>0.623745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.169073</td>\n",
       "      <td>0.210603</td>\n",
       "      <td>0.192638</td>\n",
       "      <td>0.164729</td>\n",
       "      <td>0.173500</td>\n",
       "      <td>0.174261</td>\n",
       "      <td>0.162065</td>\n",
       "      <td>0.250307</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44959</th>\n",
       "      <td>0.542102</td>\n",
       "      <td>0.542124</td>\n",
       "      <td>0.542091</td>\n",
       "      <td>0.362881</td>\n",
       "      <td>0.331210</td>\n",
       "      <td>0.347704</td>\n",
       "      <td>0.346756</td>\n",
       "      <td>0.360977</td>\n",
       "      <td>0.542088</td>\n",
       "      <td>0.587679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.196756</td>\n",
       "      <td>0.218997</td>\n",
       "      <td>0.197776</td>\n",
       "      <td>0.196601</td>\n",
       "      <td>0.179508</td>\n",
       "      <td>0.181714</td>\n",
       "      <td>0.169238</td>\n",
       "      <td>0.247462</td>\n",
       "      <td>0.003169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44960</th>\n",
       "      <td>0.305280</td>\n",
       "      <td>0.306052</td>\n",
       "      <td>0.304332</td>\n",
       "      <td>0.104895</td>\n",
       "      <td>0.112107</td>\n",
       "      <td>0.155929</td>\n",
       "      <td>0.099897</td>\n",
       "      <td>0.114104</td>\n",
       "      <td>0.304327</td>\n",
       "      <td>0.287332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.207350</td>\n",
       "      <td>0.186880</td>\n",
       "      <td>0.118883</td>\n",
       "      <td>0.161881</td>\n",
       "      <td>0.210007</td>\n",
       "      <td>0.240221</td>\n",
       "      <td>0.217899</td>\n",
       "      <td>0.166685</td>\n",
       "      <td>0.002824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44963</th>\n",
       "      <td>0.839763</td>\n",
       "      <td>0.839763</td>\n",
       "      <td>0.839762</td>\n",
       "      <td>0.716268</td>\n",
       "      <td>0.740217</td>\n",
       "      <td>0.749506</td>\n",
       "      <td>0.745673</td>\n",
       "      <td>0.763325</td>\n",
       "      <td>0.839762</td>\n",
       "      <td>0.839653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>4.087139</td>\n",
       "      <td>4.113773</td>\n",
       "      <td>4.108301</td>\n",
       "      <td>4.026799</td>\n",
       "      <td>4.126841</td>\n",
       "      <td>4.138351</td>\n",
       "      <td>4.119126</td>\n",
       "      <td>4.205495</td>\n",
       "      <td>0.082731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44976</th>\n",
       "      <td>0.294862</td>\n",
       "      <td>0.294862</td>\n",
       "      <td>0.294862</td>\n",
       "      <td>0.215308</td>\n",
       "      <td>0.200758</td>\n",
       "      <td>0.203788</td>\n",
       "      <td>0.203216</td>\n",
       "      <td>0.206749</td>\n",
       "      <td>0.294862</td>\n",
       "      <td>0.299714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>4.386805</td>\n",
       "      <td>4.412602</td>\n",
       "      <td>4.603976</td>\n",
       "      <td>4.608124</td>\n",
       "      <td>4.527428</td>\n",
       "      <td>4.443512</td>\n",
       "      <td>4.543556</td>\n",
       "      <td>4.638810</td>\n",
       "      <td>0.166540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44977</th>\n",
       "      <td>0.587713</td>\n",
       "      <td>0.587714</td>\n",
       "      <td>0.587718</td>\n",
       "      <td>0.492622</td>\n",
       "      <td>0.505668</td>\n",
       "      <td>0.508187</td>\n",
       "      <td>0.519461</td>\n",
       "      <td>0.522745</td>\n",
       "      <td>0.587720</td>\n",
       "      <td>0.579844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>1.704910</td>\n",
       "      <td>1.693120</td>\n",
       "      <td>1.787471</td>\n",
       "      <td>1.697954</td>\n",
       "      <td>1.691458</td>\n",
       "      <td>1.699902</td>\n",
       "      <td>1.767682</td>\n",
       "      <td>1.771075</td>\n",
       "      <td>0.039875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44983</th>\n",
       "      <td>0.586479</td>\n",
       "      <td>0.586480</td>\n",
       "      <td>0.586517</td>\n",
       "      <td>0.368646</td>\n",
       "      <td>0.348441</td>\n",
       "      <td>0.344054</td>\n",
       "      <td>0.347415</td>\n",
       "      <td>0.347266</td>\n",
       "      <td>0.586507</td>\n",
       "      <td>0.558920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>1.362774</td>\n",
       "      <td>1.146800</td>\n",
       "      <td>1.224869</td>\n",
       "      <td>1.124959</td>\n",
       "      <td>1.133193</td>\n",
       "      <td>1.126250</td>\n",
       "      <td>1.149540</td>\n",
       "      <td>1.192606</td>\n",
       "      <td>0.031689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44964</th>\n",
       "      <td>0.528415</td>\n",
       "      <td>0.529091</td>\n",
       "      <td>0.517317</td>\n",
       "      <td>0.437937</td>\n",
       "      <td>0.412748</td>\n",
       "      <td>0.433556</td>\n",
       "      <td>0.426783</td>\n",
       "      <td>0.439831</td>\n",
       "      <td>0.517322</td>\n",
       "      <td>0.527542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>1.739051</td>\n",
       "      <td>1.677194</td>\n",
       "      <td>1.671669</td>\n",
       "      <td>1.867097</td>\n",
       "      <td>1.771377</td>\n",
       "      <td>1.780905</td>\n",
       "      <td>1.802348</td>\n",
       "      <td>1.829578</td>\n",
       "      <td>0.313549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44965</th>\n",
       "      <td>0.918889</td>\n",
       "      <td>0.922791</td>\n",
       "      <td>0.912971</td>\n",
       "      <td>0.882181</td>\n",
       "      <td>0.901263</td>\n",
       "      <td>0.904077</td>\n",
       "      <td>0.901693</td>\n",
       "      <td>0.895627</td>\n",
       "      <td>0.914663</td>\n",
       "      <td>0.860496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.198519</td>\n",
       "      <td>0.223081</td>\n",
       "      <td>0.187666</td>\n",
       "      <td>0.241369</td>\n",
       "      <td>0.219469</td>\n",
       "      <td>0.224255</td>\n",
       "      <td>0.218693</td>\n",
       "      <td>0.203323</td>\n",
       "      <td>0.032085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44978</th>\n",
       "      <td>0.323723</td>\n",
       "      <td>0.323664</td>\n",
       "      <td>0.323552</td>\n",
       "      <td>0.220391</td>\n",
       "      <td>0.147549</td>\n",
       "      <td>0.160053</td>\n",
       "      <td>0.145443</td>\n",
       "      <td>0.156640</td>\n",
       "      <td>0.323560</td>\n",
       "      <td>0.316859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.678560</td>\n",
       "      <td>0.874726</td>\n",
       "      <td>0.734671</td>\n",
       "      <td>0.756588</td>\n",
       "      <td>0.702576</td>\n",
       "      <td>0.702984</td>\n",
       "      <td>0.709211</td>\n",
       "      <td>0.043122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44969</th>\n",
       "      <td>0.455312</td>\n",
       "      <td>0.457275</td>\n",
       "      <td>0.399215</td>\n",
       "      <td>0.012125</td>\n",
       "      <td>0.033941</td>\n",
       "      <td>0.104237</td>\n",
       "      <td>0.014478</td>\n",
       "      <td>0.033186</td>\n",
       "      <td>0.413739</td>\n",
       "      <td>0.446160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>1.015533</td>\n",
       "      <td>0.987846</td>\n",
       "      <td>1.031700</td>\n",
       "      <td>1.030491</td>\n",
       "      <td>0.933103</td>\n",
       "      <td>0.993429</td>\n",
       "      <td>0.996159</td>\n",
       "      <td>0.998527</td>\n",
       "      <td>0.045086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44972</th>\n",
       "      <td>0.766537</td>\n",
       "      <td>0.766897</td>\n",
       "      <td>0.766484</td>\n",
       "      <td>0.754416</td>\n",
       "      <td>0.770870</td>\n",
       "      <td>0.769193</td>\n",
       "      <td>0.771494</td>\n",
       "      <td>0.775350</td>\n",
       "      <td>0.766536</td>\n",
       "      <td>0.789319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.350499</td>\n",
       "      <td>0.256285</td>\n",
       "      <td>0.326093</td>\n",
       "      <td>0.305879</td>\n",
       "      <td>0.240524</td>\n",
       "      <td>0.244902</td>\n",
       "      <td>0.237412</td>\n",
       "      <td>0.289097</td>\n",
       "      <td>0.014406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44971</th>\n",
       "      <td>0.878150</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.878167</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.823599</td>\n",
       "      <td>0.817295</td>\n",
       "      <td>0.825090</td>\n",
       "      <td>0.822749</td>\n",
       "      <td>0.878211</td>\n",
       "      <td>0.838350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.501070</td>\n",
       "      <td>0.504026</td>\n",
       "      <td>0.523274</td>\n",
       "      <td>0.500311</td>\n",
       "      <td>0.485174</td>\n",
       "      <td>0.499080</td>\n",
       "      <td>0.552105</td>\n",
       "      <td>0.529770</td>\n",
       "      <td>0.014268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        RMSE_test                                       \\\n",
       "      1-Layer SampledNet Gradient 1-Layer SampledNet Uniform Rand Proj   \n",
       "44973                    0.595157                   0.595159  0.595159   \n",
       "44975                    0.006491                   0.006491  0.006491   \n",
       "44980                    0.771309                   0.771331  0.771314   \n",
       "44981                    0.904397                   0.904818  0.904248   \n",
       "45402                    0.707004                   0.706447  0.706434   \n",
       "44994                    0.296740                   0.296623  0.296760   \n",
       "44957                    0.674052                   0.674364  0.674497   \n",
       "44970                    0.667694                   0.666439  0.666413   \n",
       "44959                    0.542102                   0.542124  0.542091   \n",
       "44960                    0.305280                   0.306052  0.304332   \n",
       "44963                    0.839763                   0.839763  0.839762   \n",
       "44976                    0.294862                   0.294862  0.294862   \n",
       "44977                    0.587713                   0.587714  0.587718   \n",
       "44983                    0.586479                   0.586480  0.586517   \n",
       "44964                    0.528415                   0.529091  0.517317   \n",
       "44965                    0.918889                   0.922791  0.912971   \n",
       "44978                    0.323723                   0.323664  0.323552   \n",
       "44969                    0.455312                   0.457275  0.399215   \n",
       "44972                    0.766537                   0.766897  0.766484   \n",
       "44971                    0.878150                   0.878165  0.878167   \n",
       "\n",
       "                                                                             \\\n",
       "      Random Feature ODE Sampled EulerODE Gradient Sampled EulerODE Uniform   \n",
       "44973           0.340580                  0.265267                 0.262816   \n",
       "44975           0.140689                  0.011393                 0.013024   \n",
       "44980           0.422342                  0.425118                 0.440368   \n",
       "44981           0.906131                  0.905082                 0.904194   \n",
       "45402           0.555939                  0.593257                 0.596652   \n",
       "44994           0.215857                  0.225381                 0.226724   \n",
       "44957           0.332879                  0.295786                 0.382020   \n",
       "44970           0.609266                  0.632369                 0.632836   \n",
       "44959           0.362881                  0.331210                 0.347704   \n",
       "44960           0.104895                  0.112107                 0.155929   \n",
       "44963           0.716268                  0.740217                 0.749506   \n",
       "44976           0.215308                  0.200758                 0.203788   \n",
       "44977           0.492622                  0.505668                 0.508187   \n",
       "44983           0.368646                  0.348441                 0.344054   \n",
       "44964           0.437937                  0.412748                 0.433556   \n",
       "44965           0.882181                  0.901263                 0.904077   \n",
       "44978           0.220391                  0.147549                 0.160053   \n",
       "44969           0.012125                  0.033941                 0.104237   \n",
       "44972           0.754416                  0.770870                 0.769193   \n",
       "44971           0.823269                  0.823599                 0.817295   \n",
       "\n",
       "                                                                      \\\n",
       "      Sampled ResNet Gradient Sampled ResNet Uniform Tabular RidgeCV   \n",
       "44973                0.274106               0.273519        0.595158   \n",
       "44975                0.009447               0.010734        0.006491   \n",
       "44980                0.392726               0.457173        0.771311   \n",
       "44981                0.903146               0.903209        0.904478   \n",
       "45402                0.593615               0.615447        0.706690   \n",
       "44994                0.311644               0.256188        0.296725   \n",
       "44957                0.291586               0.346770        0.674484   \n",
       "44970                0.625500               0.627493        0.666021   \n",
       "44959                0.346756               0.360977        0.542088   \n",
       "44960                0.099897               0.114104        0.304327   \n",
       "44963                0.745673               0.763325        0.839762   \n",
       "44976                0.203216               0.206749        0.294862   \n",
       "44977                0.519461               0.522745        0.587720   \n",
       "44983                0.347415               0.347266        0.586507   \n",
       "44964                0.426783               0.439831        0.517322   \n",
       "44965                0.901693               0.895627        0.914663   \n",
       "44978                0.145443               0.156640        0.323560   \n",
       "44969                0.014478               0.033186        0.413739   \n",
       "44972                0.771494               0.775350        0.766536   \n",
       "44971                0.825090               0.822749        0.878211   \n",
       "\n",
       "                       RMSE_train  ...          t_feat  \\\n",
       "      1-Layer SampledNet Gradient  ... Tabular RidgeCV   \n",
       "44973                    0.594543  ...        0.000989   \n",
       "44975                    0.006807  ...        0.015274   \n",
       "44980                    0.761382  ...        0.000885   \n",
       "44981                    0.917619  ...        0.001368   \n",
       "45402                    0.636660  ...        0.000312   \n",
       "44994                    0.298746  ...        0.000326   \n",
       "44957                    0.689486  ...        0.000398   \n",
       "44970                    0.623745  ...        0.000282   \n",
       "44959                    0.587679  ...        0.000287   \n",
       "44960                    0.287332  ...        0.000273   \n",
       "44963                    0.839653  ...        0.000967   \n",
       "44976                    0.299714  ...        0.007894   \n",
       "44977                    0.579844  ...        0.001750   \n",
       "44983                    0.558920  ...        0.000539   \n",
       "44964                    0.527542  ...        0.002158   \n",
       "44965                    0.860496  ...        0.000879   \n",
       "44978                    0.316859  ...        0.001248   \n",
       "44969                    0.446160  ...        0.001039   \n",
       "44972                    0.789319  ...        0.000339   \n",
       "44971                    0.838350  ...        0.000371   \n",
       "\n",
       "                            t_fit                                       \\\n",
       "      1-Layer SampledNet Gradient 1-Layer SampledNet Uniform Rand Proj   \n",
       "44973                    1.348948                   1.153801  1.269893   \n",
       "44975                    6.640887                   6.861540  7.586293   \n",
       "44980                    0.684261                   0.643247  0.704401   \n",
       "44981                    0.683061                   0.706151  0.715020   \n",
       "45402                    0.357183                   0.384122  0.352507   \n",
       "44994                    0.169758                   0.177873  0.225159   \n",
       "44957                    0.226856                   0.258456  0.258957   \n",
       "44970                    0.169073                   0.210603  0.192638   \n",
       "44959                    0.196756                   0.218997  0.197776   \n",
       "44960                    0.207350                   0.186880  0.118883   \n",
       "44963                    4.087139                   4.113773  4.108301   \n",
       "44976                    4.386805                   4.412602  4.603976   \n",
       "44977                    1.704910                   1.693120  1.787471   \n",
       "44983                    1.362774                   1.146800  1.224869   \n",
       "44964                    1.739051                   1.677194  1.671669   \n",
       "44965                    0.198519                   0.223081  0.187666   \n",
       "44978                    0.694534                   0.678560  0.874726   \n",
       "44969                    1.015533                   0.987846  1.031700   \n",
       "44972                    0.350499                   0.256285  0.326093   \n",
       "44971                    0.501070                   0.504026  0.523274   \n",
       "\n",
       "                                                                             \\\n",
       "      Random Feature ODE Sampled EulerODE Gradient Sampled EulerODE Uniform   \n",
       "44973           1.649985                  0.974434                 1.013453   \n",
       "44975           6.671903                  6.953238                 6.668116   \n",
       "44980           0.695290                  0.679370                 0.641010   \n",
       "44981           0.633572                  0.672336                 0.689704   \n",
       "45402           0.336089                  0.387642                 0.345023   \n",
       "44994           0.186932                  0.184228                 0.133652   \n",
       "44957           0.265192                  0.199013                 0.242993   \n",
       "44970           0.164729                  0.173500                 0.174261   \n",
       "44959           0.196601                  0.179508                 0.181714   \n",
       "44960           0.161881                  0.210007                 0.240221   \n",
       "44963           4.026799                  4.126841                 4.138351   \n",
       "44976           4.608124                  4.527428                 4.443512   \n",
       "44977           1.697954                  1.691458                 1.699902   \n",
       "44983           1.124959                  1.133193                 1.126250   \n",
       "44964           1.867097                  1.771377                 1.780905   \n",
       "44965           0.241369                  0.219469                 0.224255   \n",
       "44978           0.734671                  0.756588                 0.702576   \n",
       "44969           1.030491                  0.933103                 0.993429   \n",
       "44972           0.305879                  0.240524                 0.244902   \n",
       "44971           0.500311                  0.485174                 0.499080   \n",
       "\n",
       "                                                                      \n",
       "      Sampled ResNet Gradient Sampled ResNet Uniform Tabular RidgeCV  \n",
       "44973                1.656375               1.336837        0.021568  \n",
       "44975                6.732856               6.719438        0.567887  \n",
       "44980                0.696140               0.718928        0.023043  \n",
       "44981                0.699537               0.759174        0.061516  \n",
       "45402                0.350022               0.421070        0.011551  \n",
       "44994                0.192889               0.188467        0.021471  \n",
       "44957                0.237008               0.225692        0.003265  \n",
       "44970                0.162065               0.250307        0.002859  \n",
       "44959                0.169238               0.247462        0.003169  \n",
       "44960                0.217899               0.166685        0.002824  \n",
       "44963                4.119126               4.205495        0.082731  \n",
       "44976                4.543556               4.638810        0.166540  \n",
       "44977                1.767682               1.771075        0.039875  \n",
       "44983                1.149540               1.192606        0.031689  \n",
       "44964                1.802348               1.829578        0.313549  \n",
       "44965                0.218693               0.203323        0.032085  \n",
       "44978                0.702984               0.709211        0.043122  \n",
       "44969                0.996159               0.998527        0.045086  \n",
       "44972                0.237412               0.289097        0.014406  \n",
       "44971                0.552105               0.529770        0.014268  \n",
       "\n",
       "[20 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ids_not_categorical = list(df_metadata.query(\"has_categorical == False\").index.values)\n",
    "dataset_ids_not_categorical = [int(x) for x in dataset_ids_not_categorical]\n",
    "run_all_experiments(dataset_ids_not_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-Layer SampledNet Gradient    0.582503\n",
       "1-Layer SampledNet Uniform     0.582828\n",
       "Rand Proj                      0.578715\n",
       "Random Feature ODE             0.445731\n",
       "Sampled EulerODE Gradient      0.434101\n",
       "Sampled EulerODE Uniform       0.447811\n",
       "Sampled ResNet Gradient        0.437458\n",
       "Sampled ResNet Uniform         0.446454\n",
       "Tabular RidgeCV                0.579533\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg = pd.read_pickle(\"OpenML_reg_PLACEHOLDER.pkl\")\n",
    "df_reg[\"RMSE_test\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-Layer SampledNet Gradient    6.90\n",
       "1-Layer SampledNet Uniform     7.45\n",
       "Rand Proj                      6.60\n",
       "Random Feature ODE             3.25\n",
       "Sampled EulerODE Gradient      3.20\n",
       "Sampled EulerODE Uniform       3.80\n",
       "Sampled ResNet Gradient        3.15\n",
       "Sampled ResNet Uniform         4.00\n",
       "Tabular RidgeCV                6.65\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg[\"RMSE_test\"].rank(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"RMSE_train\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"RMSE_train\"].rank(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"RMSE_test\"].rank(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
