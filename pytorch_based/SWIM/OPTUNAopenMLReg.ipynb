{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, tensor\n",
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "#from aeon.regression.sklearn import RotationForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from preprocessing.stream_transforms import normalize_mean_std_traindata, normalize_streams, augment_time, add_basepoint_zero\n",
    "from utils.utils import print_name, print_shape\n",
    "from models import ResNet, NeuralEulerODE, RidgeCVModule, E2EResNet, StagewiseRandFeatBoostRegression\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4177, 8)\n",
      "(4177, 1)\n",
      " 1/35 Processed dataset 44956: abalone\n",
      "(1503, 5)\n",
      "(1503, 1)\n",
      " 2/35 Processed dataset 44957: airfoil_self_noise\n",
      "(2043, 7)\n",
      "(2043, 1)\n",
      " 3/35 Processed dataset 44958: auction_verification\n",
      "(1030, 8)\n",
      "(1030, 1)\n",
      " 4/35 Processed dataset 44959: concrete_compressive_strength\n",
      "(45730, 9)\n",
      "(45730, 1)\n",
      " 5/35 Processed dataset 44963: physiochemical_protein\n",
      "(21263, 81)\n",
      "(21263, 1)\n",
      " 6/35 Processed dataset 44964: superconductivity\n",
      "(1059, 116)\n",
      "(1059, 1)\n",
      " 7/35 Processed dataset 44965: geographical_origin_of_music\n",
      "(1066, 10)\n",
      "(1066, 1)\n",
      " 8/35 Processed dataset 44966: solar_flare\n",
      "(11934, 14)\n",
      "(11934, 1)\n",
      " 9/35 Processed dataset 44969: naval_propulsion_plant\n",
      "(4898, 11)\n",
      "(4898, 1)\n",
      " 10/35 Processed dataset 44971: white_wine\n",
      "(1599, 11)\n",
      "(1599, 1)\n",
      " 11/35 Processed dataset 44972: red_wine\n",
      "(10000, 12)\n",
      "(10000, 1)\n",
      " 12/35 Processed dataset 44973: grid_stability\n",
      "(68784, 18)\n",
      "(68784, 1)\n",
      " 13/35 Processed dataset 44974: video_transcoding\n",
      "(72000, 48)\n",
      "(72000, 1)\n",
      " 14/35 Processed dataset 44975: wave_energy\n",
      "(48933, 21)\n",
      "(48933, 1)\n",
      " 15/35 Processed dataset 44976: sarcos\n",
      "(20640, 8)\n",
      "(20640, 1)\n",
      " 16/35 Processed dataset 44977: california_housing\n",
      "(8192, 21)\n",
      "(8192, 1)\n",
      " 17/35 Processed dataset 44978: cpu_activity\n",
      "(53940, 9)\n",
      "(53940, 1)\n",
      " 18/35 Processed dataset 44979: diamonds\n",
      "(8192, 8)\n",
      "(8192, 1)\n",
      " 19/35 Processed dataset 44980: kin8nm\n",
      "(8192, 32)\n",
      "(8192, 1)\n",
      " 20/35 Processed dataset 44981: pumadyn32nh\n",
      "(13932, 15)\n",
      "(13932, 1)\n",
      " 21/35 Processed dataset 44983: miami_housing\n",
      "(28155, 6)\n",
      "(28155, 1)\n",
      " 22/35 Processed dataset 44984: cps88wages\n",
      "(1156, 5)\n",
      "(1156, 1)\n",
      " 23/35 Processed dataset 44987: socmob\n",
      "(21613, 21)\n",
      "(21613, 1)\n",
      " 24/35 Processed dataset 44989: kings_county\n",
      "(10692, 9)\n",
      "(10692, 1)\n",
      " 25/35 Processed dataset 44990: brazilian_houses\n",
      "(24624, 43)\n",
      "(24624, 1)\n",
      " 26/35 Processed dataset 44992: fps_benchmark\n",
      "(22272, 11)\n",
      "(22272, 1)\n",
      " 27/35 Processed dataset 44993: health_insurance\n",
      "(19178, 28)\n",
      "(19178, 1)\n",
      " 28/35 Processed dataset 45012: fifa\n",
      "(1232, 14)\n",
      "(1232, 1)\n",
      " 29/35 Processed dataset 41021: Moneyball\n",
      "(768, 8)\n",
      "(768, 1)\n",
      " 30/35 Processed dataset 44960: energy_efficiency\n",
      "(517, 12)\n",
      "(517, 1)\n",
      " 31/35 Processed dataset 44962: forest_fires\n",
      "(649, 30)\n",
      "(649, 1)\n",
      " 32/35 Processed dataset 44967: student_performance_por\n",
      "(908, 6)\n",
      "(908, 1)\n",
      " 33/35 Processed dataset 44970: QSAR_fish_toxicity\n",
      "(804, 17)\n",
      "(804, 1)\n",
      " 34/35 Processed dataset 44994: cars\n",
      "(3107, 6)\n",
      "(3107, 1)\n",
      " 35/35 Processed dataset 45402: space_ga\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>n_features</th>\n",
       "      <th>%_unique_y</th>\n",
       "      <th>n_unique_y</th>\n",
       "      <th>has_categorical</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41021</th>\n",
       "      <td>Moneyball</td>\n",
       "      <td>1232</td>\n",
       "      <td>15</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>374</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44956</th>\n",
       "      <td>abalone</td>\n",
       "      <td>4177</td>\n",
       "      <td>9</td>\n",
       "      <td>0.006703</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44957</th>\n",
       "      <td>airfoil_self_noise</td>\n",
       "      <td>1503</td>\n",
       "      <td>6</td>\n",
       "      <td>0.968729</td>\n",
       "      <td>1456</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44958</th>\n",
       "      <td>auction_verification</td>\n",
       "      <td>2043</td>\n",
       "      <td>8</td>\n",
       "      <td>0.998042</td>\n",
       "      <td>2039</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44959</th>\n",
       "      <td>concrete_compressive_strength</td>\n",
       "      <td>1030</td>\n",
       "      <td>9</td>\n",
       "      <td>0.910680</td>\n",
       "      <td>938</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44960</th>\n",
       "      <td>energy_efficiency</td>\n",
       "      <td>768</td>\n",
       "      <td>9</td>\n",
       "      <td>0.764323</td>\n",
       "      <td>587</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44962</th>\n",
       "      <td>forest_fires</td>\n",
       "      <td>517</td>\n",
       "      <td>13</td>\n",
       "      <td>0.485493</td>\n",
       "      <td>251</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44963</th>\n",
       "      <td>physiochemical_protein</td>\n",
       "      <td>45730</td>\n",
       "      <td>10</td>\n",
       "      <td>0.347759</td>\n",
       "      <td>15903</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44964</th>\n",
       "      <td>superconductivity</td>\n",
       "      <td>21263</td>\n",
       "      <td>82</td>\n",
       "      <td>0.141419</td>\n",
       "      <td>3007</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44965</th>\n",
       "      <td>geographical_origin_of_music</td>\n",
       "      <td>1059</td>\n",
       "      <td>117</td>\n",
       "      <td>0.029273</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44966</th>\n",
       "      <td>solar_flare</td>\n",
       "      <td>1066</td>\n",
       "      <td>11</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44967</th>\n",
       "      <td>student_performance_por</td>\n",
       "      <td>649</td>\n",
       "      <td>31</td>\n",
       "      <td>0.026194</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44969</th>\n",
       "      <td>naval_propulsion_plant</td>\n",
       "      <td>11934</td>\n",
       "      <td>15</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44970</th>\n",
       "      <td>QSAR_fish_toxicity</td>\n",
       "      <td>908</td>\n",
       "      <td>7</td>\n",
       "      <td>0.910793</td>\n",
       "      <td>827</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44971</th>\n",
       "      <td>white_wine</td>\n",
       "      <td>4898</td>\n",
       "      <td>12</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44972</th>\n",
       "      <td>red_wine</td>\n",
       "      <td>1599</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44973</th>\n",
       "      <td>grid_stability</td>\n",
       "      <td>10000</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44974</th>\n",
       "      <td>video_transcoding</td>\n",
       "      <td>68784</td>\n",
       "      <td>19</td>\n",
       "      <td>0.159339</td>\n",
       "      <td>10960</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44975</th>\n",
       "      <td>wave_energy</td>\n",
       "      <td>72000</td>\n",
       "      <td>49</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>71993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44976</th>\n",
       "      <td>sarcos</td>\n",
       "      <td>48933</td>\n",
       "      <td>22</td>\n",
       "      <td>0.233258</td>\n",
       "      <td>11414</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44977</th>\n",
       "      <td>california_housing</td>\n",
       "      <td>20640</td>\n",
       "      <td>9</td>\n",
       "      <td>0.186143</td>\n",
       "      <td>3842</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44978</th>\n",
       "      <td>cpu_activity</td>\n",
       "      <td>8192</td>\n",
       "      <td>22</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>56</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44979</th>\n",
       "      <td>diamonds</td>\n",
       "      <td>53940</td>\n",
       "      <td>10</td>\n",
       "      <td>0.215091</td>\n",
       "      <td>11602</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44980</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8192</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>8191</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44981</th>\n",
       "      <td>pumadyn32nh</td>\n",
       "      <td>8192</td>\n",
       "      <td>33</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>8191</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44983</th>\n",
       "      <td>miami_housing</td>\n",
       "      <td>13932</td>\n",
       "      <td>16</td>\n",
       "      <td>0.151522</td>\n",
       "      <td>2111</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44984</th>\n",
       "      <td>cps88wages</td>\n",
       "      <td>28155</td>\n",
       "      <td>7</td>\n",
       "      <td>0.212040</td>\n",
       "      <td>5970</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44987</th>\n",
       "      <td>socmob</td>\n",
       "      <td>1156</td>\n",
       "      <td>6</td>\n",
       "      <td>0.312284</td>\n",
       "      <td>361</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44989</th>\n",
       "      <td>kings_county</td>\n",
       "      <td>21613</td>\n",
       "      <td>22</td>\n",
       "      <td>0.186369</td>\n",
       "      <td>4028</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44990</th>\n",
       "      <td>brazilian_houses</td>\n",
       "      <td>10692</td>\n",
       "      <td>10</td>\n",
       "      <td>0.537879</td>\n",
       "      <td>5751</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44992</th>\n",
       "      <td>fps_benchmark</td>\n",
       "      <td>24624</td>\n",
       "      <td>44</td>\n",
       "      <td>0.108634</td>\n",
       "      <td>2675</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44993</th>\n",
       "      <td>health_insurance</td>\n",
       "      <td>22272</td>\n",
       "      <td>12</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>75</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44994</th>\n",
       "      <td>cars</td>\n",
       "      <td>804</td>\n",
       "      <td>18</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>798</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45012</th>\n",
       "      <td>fifa</td>\n",
       "      <td>19178</td>\n",
       "      <td>29</td>\n",
       "      <td>0.006935</td>\n",
       "      <td>133</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45402</th>\n",
       "      <td>space_ga</td>\n",
       "      <td>3107</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999356</td>\n",
       "      <td>3105</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     name  n_obs  n_features  %_unique_y  \\\n",
       "dataset_id                                                                 \n",
       "41021                           Moneyball   1232          15    0.303571   \n",
       "44956                             abalone   4177           9    0.006703   \n",
       "44957                  airfoil_self_noise   1503           6    0.968729   \n",
       "44958                auction_verification   2043           8    0.998042   \n",
       "44959       concrete_compressive_strength   1030           9    0.910680   \n",
       "44960                   energy_efficiency    768           9    0.764323   \n",
       "44962                        forest_fires    517          13    0.485493   \n",
       "44963              physiochemical_protein  45730          10    0.347759   \n",
       "44964                   superconductivity  21263          82    0.141419   \n",
       "44965        geographical_origin_of_music   1059         117    0.029273   \n",
       "44966                         solar_flare   1066          11    0.007505   \n",
       "44967             student_performance_por    649          31    0.026194   \n",
       "44969              naval_propulsion_plant  11934          15    0.004274   \n",
       "44970                  QSAR_fish_toxicity    908           7    0.910793   \n",
       "44971                          white_wine   4898          12    0.001429   \n",
       "44972                            red_wine   1599          12    0.003752   \n",
       "44973                      grid_stability  10000          13    1.000000   \n",
       "44974                   video_transcoding  68784          19    0.159339   \n",
       "44975                         wave_energy  72000          49    0.999903   \n",
       "44976                              sarcos  48933          22    0.233258   \n",
       "44977                  california_housing  20640           9    0.186143   \n",
       "44978                        cpu_activity   8192          22    0.006836   \n",
       "44979                            diamonds  53940          10    0.215091   \n",
       "44980                              kin8nm   8192           9    0.999878   \n",
       "44981                         pumadyn32nh   8192          33    0.999878   \n",
       "44983                       miami_housing  13932          16    0.151522   \n",
       "44984                          cps88wages  28155           7    0.212040   \n",
       "44987                              socmob   1156           6    0.312284   \n",
       "44989                        kings_county  21613          22    0.186369   \n",
       "44990                    brazilian_houses  10692          10    0.537879   \n",
       "44992                       fps_benchmark  24624          44    0.108634   \n",
       "44993                    health_insurance  22272          12    0.003367   \n",
       "44994                                cars    804          18    0.992537   \n",
       "45012                                fifa  19178          29    0.006935   \n",
       "45402                            space_ga   3107           7    0.999356   \n",
       "\n",
       "            n_unique_y  has_categorical  \n",
       "dataset_id                               \n",
       "41021              374             True  \n",
       "44956               28             True  \n",
       "44957             1456            False  \n",
       "44958             2039             True  \n",
       "44959              938            False  \n",
       "44960              587            False  \n",
       "44962              251             True  \n",
       "44963            15903            False  \n",
       "44964             3007            False  \n",
       "44965               31            False  \n",
       "44966                8             True  \n",
       "44967               17             True  \n",
       "44969               51            False  \n",
       "44970              827            False  \n",
       "44971                7            False  \n",
       "44972                6            False  \n",
       "44973            10000            False  \n",
       "44974            10960             True  \n",
       "44975            71993            False  \n",
       "44976            11414            False  \n",
       "44977             3842            False  \n",
       "44978               56            False  \n",
       "44979            11602             True  \n",
       "44980             8191            False  \n",
       "44981             8191            False  \n",
       "44983             2111            False  \n",
       "44984             5970             True  \n",
       "44987              361             True  \n",
       "44989             4028             True  \n",
       "44990             5751             True  \n",
       "44992             2675             True  \n",
       "44993               75             True  \n",
       "44994              798            False  \n",
       "45012              133             True  \n",
       "45402             3105            False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the collection with ID 353\n",
    "collection = openml.study.get_suite(353)\n",
    "dataset_ids = collection.data\n",
    "metadata_list = []\n",
    "\n",
    "# Fetch and process each dataset\n",
    "for i, dataset_id in enumerate(dataset_ids):\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        target=dataset.default_target_attribute\n",
    "    )\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)[..., None]\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    # Determine if the dataset has categorical features\n",
    "    has_categorical = any(categorical_indicator)\n",
    "    \n",
    "    # Extract the required metadata\n",
    "    metadata = {\n",
    "        'dataset_id': dataset.id,\n",
    "        'name': dataset.name,\n",
    "        'n_obs': int(dataset.qualities['NumberOfInstances']),\n",
    "        'n_features': int(dataset.qualities['NumberOfFeatures']),\n",
    "        '%_unique_y': len(np.unique(y))/len(y),\n",
    "        'n_unique_y': len(np.unique(y)),\n",
    "        'has_categorical': has_categorical\n",
    "    }\n",
    "    \n",
    "    metadata_list.append(metadata)\n",
    "    print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset.id}: {dataset.name}\")\n",
    "\n",
    "# Create a DataFrame from the metadata list\n",
    "df_metadata = pd.DataFrame(metadata_list).sort_values('%_unique_y', ascending=False).set_index(\"dataset_id\").sort_index()\n",
    "df_metadata.sort_values('%_unique_y', ascending=True)\n",
    "\n",
    "# Display the metadata DataFrame\n",
    "df_metadata.loc[44962, \"has_categorical\"] = True\n",
    "df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ids_no_categorical = list(df_metadata.query(\"has_categorical == False\").index.values)\n",
    "dataset_ids_no_categorical = sorted([int(x) for x in dataset_ids_no_categorical])\n",
    "len(dataset_ids_no_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_load_openml_dataset(dataset_id, \n",
    "                        normalize_X:bool = True,\n",
    "                        normalize_y:bool = True,\n",
    "                        ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # Fetch dataset from OpenML by its ID\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    df, _, categorical_indicator, attribute_names = dataset.get_data()\n",
    "    y = np.array(df.pop(dataset.default_target_attribute)).astype(np.float32)\n",
    "    X = np.array(df).astype(np.float32)\n",
    "\n",
    "    #normalize\n",
    "    if normalize_X:\n",
    "        X = X - X.mean(axis=0, keepdims=True)\n",
    "        X = X / (X.std(axis=0, keepdims=True) + 1e-5)\n",
    "        X = np.clip(X, -3, 3)\n",
    "    if normalize_y:\n",
    "        y = y - y.mean()\n",
    "        y = y / (y.std() + 1e-5)\n",
    "        y = np.clip(y, -3, 3)\n",
    "\n",
    "    return (X, y)\n",
    "\n",
    "#dataset_id = 44971  # Replace with the dataset ID you want\n",
    "dataset_id = 44971 #44970\n",
    "X, y = np_load_openml_dataset(dataset_id, False, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna\n",
    "\n",
    "The procedure is the following: Take in tabular dataset X shape (N, D) and y shape (N, d). \n",
    "Create a 5 fold (stratified? how does this work with regression targets) cross validation.\n",
    "\n",
    "From each 80% train set, run a specified optuna objective which itself uses an inner 5-foldCV,\n",
    "to obtain hyperparameters. \n",
    "\n",
    "Use these hyperparams to train on the full 80% train set, and test on the 20% test set.\n",
    "\n",
    "Repeat for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_seed = 42\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "\n",
    "def objective_xgboost_cv_reg(\n",
    "        trial, \n",
    "        X_train: np.ndarray, \n",
    "        y_train: np.ndarray, \n",
    "        k_folds: int,\n",
    "        cv_seed: int,\n",
    "        ):\n",
    "    params = {\n",
    "        \"random_state\": 42,\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 10.0, log=True),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "    }\n",
    "\n",
    "    inner_cv = KFold(n_splits=k_folds, shuffle=True, random_state=cv_seed)\n",
    "    rmse_list = []\n",
    "\n",
    "    for inner_train_idx, inner_valid_idx in inner_cv.split(X_train):\n",
    "        X_inner_train, X_inner_valid = X_train[inner_train_idx], X_train[inner_valid_idx]\n",
    "        y_inner_train, y_inner_valid = y_train[inner_train_idx], y_train[inner_valid_idx]\n",
    "\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(X_inner_train, y_inner_train)\n",
    "\n",
    "        preds = model.predict(X_inner_valid)\n",
    "        rmse = root_mean_squared_error(y_inner_valid, preds)\n",
    "        rmse_list.append(rmse)\n",
    "\n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_xgboost_kfoldcv(\n",
    "        X: np.ndarray, \n",
    "        y: np.ndarray, \n",
    "        k_folds: int = 5, \n",
    "        cv_seed: int = 42,\n",
    "        n_optuna_trials: int = 50,\n",
    "    ):\n",
    "    \"\"\"Evaluates an XGBoost model using k-fold cross-validation.\n",
    "    Hyperparameters are tuned with Optuna using an inner k-fold CV.\n",
    "    The model is then trained on the whole fold train set and evaluated \n",
    "    on the fold test set.\n",
    "\n",
    "    Returns the train RMSE, test RMSE, chosen params, training times, and test set inference times\n",
    "    for each fold.\n",
    "    \"\"\"\n",
    "    outer_cv = KFold(n_splits=k_folds, shuffle=True, random_state=cv_seed)\n",
    "    outer_train_rmse_scores = []\n",
    "    outer_test_rmse_scores = []\n",
    "    chosen_params = []\n",
    "    fit_times = []\n",
    "    transform_times = []\n",
    "\n",
    "    for train_idx, test_idx in outer_cv.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        #hyperparameter tuning with Optuna\n",
    "        study = optuna.create_study(direction=\"minimize\", )\n",
    "        objective = lambda trial: objective_xgboost_cv_reg(trial, X_train, y_train, k_folds, cv_seed)\n",
    "        study.optimize(objective, n_trials=n_optuna_trials)\n",
    "\n",
    "        #fit model with optimal hyperparams\n",
    "        t0 = time.perf_counter()\n",
    "        model = xgb.XGBRegressor(**study.best_params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        #predict and evaluate\n",
    "        t1 = time.perf_counter()\n",
    "        preds_train = model.predict(X_train)\n",
    "        rmse_train = root_mean_squared_error(y_train, preds_train)\n",
    "        preds_test = model.predict(X_test)\n",
    "        rmse_test = root_mean_squared_error(y_test, preds_test)\n",
    "        t2 = time.perf_counter()\n",
    "\n",
    "        outer_train_rmse_scores.append(rmse_train)\n",
    "        outer_test_rmse_scores.append(rmse_test)\n",
    "        chosen_params.append(study.best_params.copy())\n",
    "        fit_times.append(t1-t0)\n",
    "        transform_times.append(t2-t1)\n",
    "\n",
    "\n",
    "    return (np.array(outer_train_rmse_scores),\n",
    "            np.array(outer_test_rmse_scores),\n",
    "            chosen_params,\n",
    "            np.array(fit_times),\n",
    "            np.array(transform_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-23 16:21:36,416] A new study created in memory with name: no-name-3fed73c0-2e7c-4ac2-a76e-ad454218f97f\n",
      "[I 2024-11-23 16:21:36,970] Trial 0 finished with value: 0.24816958606243134 and parameters: {'lambda': 2.602558873138932, 'learning_rate': 0.20856213756415415, 'n_estimators': 253, 'max_depth': 7, 'subsample': 0.6254345847349718, 'colsample_bytree': 0.6985599798630221}. Best is trial 0 with value: 0.24816958606243134.\n",
      "[I 2024-11-23 16:21:37,310] Trial 1 finished with value: 0.6025902032852173 and parameters: {'lambda': 0.03896510883216185, 'learning_rate': 0.016584704653584373, 'n_estimators': 133, 'max_depth': 8, 'subsample': 0.6686722986166862, 'colsample_bytree': 0.5254499468821247}. Best is trial 0 with value: 0.24816958606243134.\n",
      "[I 2024-11-23 16:21:37,421] A new study created in memory with name: no-name-bfeed2c9-d97a-40f1-8414-832fcf2b6c41\n",
      "[I 2024-11-23 16:21:37,706] Trial 0 finished with value: 0.3610062003135681 and parameters: {'lambda': 0.7647218975959239, 'learning_rate': 0.02829412046929518, 'n_estimators': 249, 'max_depth': 4, 'subsample': 0.9541414576045811, 'colsample_bytree': 0.9317424005005898}. Best is trial 0 with value: 0.3610062003135681.\n",
      "[I 2024-11-23 16:21:38,234] Trial 1 finished with value: 0.3100542426109314 and parameters: {'lambda': 0.04006088660291853, 'learning_rate': 0.10922985130306125, 'n_estimators': 109, 'max_depth': 10, 'subsample': 0.9794250868382514, 'colsample_bytree': 0.6271267886035236}. Best is trial 1 with value: 0.3100542426109314.\n",
      "[I 2024-11-23 16:21:38,334] A new study created in memory with name: no-name-c4229c3d-2102-40f1-8334-fb1fd763c46f\n",
      "[I 2024-11-23 16:21:39,399] Trial 0 finished with value: 0.2442656010389328 and parameters: {'lambda': 0.0037967032330438167, 'learning_rate': 0.03570192057444542, 'n_estimators': 226, 'max_depth': 10, 'subsample': 0.5908851492887253, 'colsample_bytree': 0.9218561994272187}. Best is trial 0 with value: 0.2442656010389328.\n",
      "[I 2024-11-23 16:21:39,807] Trial 1 finished with value: 0.2410956174135208 and parameters: {'lambda': 2.076169892719885, 'learning_rate': 0.2497722601612211, 'n_estimators': 224, 'max_depth': 6, 'subsample': 0.9563702179506413, 'colsample_bytree': 0.9197870764997941}. Best is trial 1 with value: 0.2410956174135208.\n",
      "[I 2024-11-23 16:21:39,884] A new study created in memory with name: no-name-617089ec-47d9-4bf1-9691-abc9cb3ed191\n",
      "[I 2024-11-23 16:21:40,186] Trial 0 finished with value: 0.2894238829612732 and parameters: {'lambda': 0.24358088218883045, 'learning_rate': 0.1204431782308184, 'n_estimators': 99, 'max_depth': 9, 'subsample': 0.9039923696766272, 'colsample_bytree': 0.719238465453732}. Best is trial 0 with value: 0.2894238829612732.\n",
      "[I 2024-11-23 16:21:40,372] Trial 1 finished with value: 0.28830188512802124 and parameters: {'lambda': 2.457794387912405, 'learning_rate': 0.07318034751688561, 'n_estimators': 65, 'max_depth': 8, 'subsample': 0.9131049499556777, 'colsample_bytree': 0.9117058456176644}. Best is trial 1 with value: 0.28830188512802124.\n",
      "[I 2024-11-23 16:21:40,415] A new study created in memory with name: no-name-395eb5b3-24cd-496a-b10d-82295732bfd0\n",
      "[I 2024-11-23 16:21:40,545] Trial 0 finished with value: 0.4254605770111084 and parameters: {'lambda': 0.16656391656427555, 'learning_rate': 0.1835589420875354, 'n_estimators': 91, 'max_depth': 4, 'subsample': 0.810889762451982, 'colsample_bytree': 0.5415058140694654}. Best is trial 0 with value: 0.4254605770111084.\n",
      "[I 2024-11-23 16:21:40,853] Trial 1 finished with value: 0.34054070711135864 and parameters: {'lambda': 0.0625587894638664, 'learning_rate': 0.038386876671209436, 'n_estimators': 132, 'max_depth': 7, 'subsample': 0.5802433046146598, 'colsample_bytree': 0.7542964689865052}. Best is trial 1 with value: 0.34054070711135864.\n",
      "[I 2024-11-23 16:21:40,929] A new study created in memory with name: no-name-afa73b5e-7306-4e07-8ba0-4f95fa143a65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/2 Processed dataset 44957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-23 16:21:41,745] Trial 0 finished with value: 0.30283084511756897 and parameters: {'lambda': 4.39561835804349, 'learning_rate': 0.017625826053495358, 'n_estimators': 291, 'max_depth': 6, 'subsample': 0.9883916082293243, 'colsample_bytree': 0.6993587354448407}. Best is trial 0 with value: 0.30283084511756897.\n",
      "[I 2024-11-23 16:21:42,082] Trial 1 finished with value: 0.27498066425323486 and parameters: {'lambda': 1.4800796813968342, 'learning_rate': 0.08115209041513519, 'n_estimators': 232, 'max_depth': 4, 'subsample': 0.9845188546443302, 'colsample_bytree': 0.8935350211764244}. Best is trial 1 with value: 0.27498066425323486.\n",
      "[I 2024-11-23 16:21:42,183] A new study created in memory with name: no-name-f592c126-946b-4f81-b11d-2acd23ccfe48\n",
      "[I 2024-11-23 16:21:42,748] Trial 0 finished with value: 0.3172334134578705 and parameters: {'lambda': 0.9328108245910985, 'learning_rate': 0.0761017209854222, 'n_estimators': 77, 'max_depth': 9, 'subsample': 0.6577082518839107, 'colsample_bytree': 0.602791146250485}. Best is trial 0 with value: 0.3172334134578705.\n",
      "[I 2024-11-23 16:21:43,660] Trial 1 finished with value: 0.35008788108825684 and parameters: {'lambda': 6.474861088875585, 'learning_rate': 0.016473727200287117, 'n_estimators': 206, 'max_depth': 8, 'subsample': 0.5005038975982242, 'colsample_bytree': 0.9742680253221498}. Best is trial 0 with value: 0.3172334134578705.\n",
      "[I 2024-11-23 16:21:43,794] A new study created in memory with name: no-name-91a039fe-9c30-4e7a-a63a-6a8dcacc985d\n",
      "[I 2024-11-23 16:21:43,957] Trial 0 finished with value: 0.5621130466461182 and parameters: {'lambda': 0.001810582381438054, 'learning_rate': 0.022704146128415568, 'n_estimators': 50, 'max_depth': 6, 'subsample': 0.8796354052783839, 'colsample_bytree': 0.578551514781357}. Best is trial 0 with value: 0.5621130466461182.\n",
      "[I 2024-11-23 16:21:44,258] Trial 1 finished with value: 0.2869260907173157 and parameters: {'lambda': 0.09492839923221155, 'learning_rate': 0.13631862980277795, 'n_estimators': 180, 'max_depth': 3, 'subsample': 0.8514534568209945, 'colsample_bytree': 0.8752519570371482}. Best is trial 1 with value: 0.2869260907173157.\n",
      "[I 2024-11-23 16:21:44,314] A new study created in memory with name: no-name-9745cb3f-c3d2-472e-a6ff-683ac0e7d314\n",
      "[I 2024-11-23 16:21:44,799] Trial 0 finished with value: 0.27396467328071594 and parameters: {'lambda': 0.003418063650310395, 'learning_rate': 0.143702963789714, 'n_estimators': 299, 'max_depth': 4, 'subsample': 0.6960356592362027, 'colsample_bytree': 0.9001508722130476}. Best is trial 0 with value: 0.27396467328071594.\n",
      "[I 2024-11-23 16:21:45,165] Trial 1 finished with value: 0.2926443815231323 and parameters: {'lambda': 1.2688120478113507, 'learning_rate': 0.0857378345092089, 'n_estimators': 78, 'max_depth': 8, 'subsample': 0.5087126580323322, 'colsample_bytree': 0.694770035662146}. Best is trial 0 with value: 0.27396467328071594.\n",
      "[I 2024-11-23 16:21:45,262] A new study created in memory with name: no-name-5a06a890-6df0-4dee-a2b9-3c392205f858\n",
      "[I 2024-11-23 16:21:46,525] Trial 0 finished with value: 0.276772141456604 and parameters: {'lambda': 1.1363074846750052, 'learning_rate': 0.08806048381966036, 'n_estimators': 177, 'max_depth': 10, 'subsample': 0.6107215587917074, 'colsample_bytree': 0.8711511111053575}. Best is trial 0 with value: 0.276772141456604.\n",
      "[I 2024-11-23 16:21:46,813] Trial 1 finished with value: 0.29699283838272095 and parameters: {'lambda': 0.08105860137190338, 'learning_rate': 0.05066107666583061, 'n_estimators': 234, 'max_depth': 3, 'subsample': 0.8073955992444242, 'colsample_bytree': 0.7379616662750667}. Best is trial 0 with value: 0.276772141456604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/2 Processed dataset 44959\n",
      "44957\n",
      "(array([0.084, 0.058, 0.07 , 0.167, 0.208], dtype=float32), array([0.24 , 0.242, 0.231, 0.309, 0.35 ], dtype=float32), [{'lambda': 2.602558873138932, 'learning_rate': 0.20856213756415415, 'n_estimators': 253, 'max_depth': 7, 'subsample': 0.6254345847349718, 'colsample_bytree': 0.6985599798630221}, {'lambda': 0.04006088660291853, 'learning_rate': 0.10922985130306125, 'n_estimators': 109, 'max_depth': 10, 'subsample': 0.9794250868382514, 'colsample_bytree': 0.6271267886035236}, {'lambda': 2.076169892719885, 'learning_rate': 0.2497722601612211, 'n_estimators': 224, 'max_depth': 6, 'subsample': 0.9563702179506413, 'colsample_bytree': 0.9197870764997941}, {'lambda': 2.457794387912405, 'learning_rate': 0.07318034751688561, 'n_estimators': 65, 'max_depth': 8, 'subsample': 0.9131049499556777, 'colsample_bytree': 0.9117058456176644}, {'lambda': 0.0625587894638664, 'learning_rate': 0.038386876671209436, 'n_estimators': 132, 'max_depth': 7, 'subsample': 0.5802433046146598, 'colsample_bytree': 0.7542964689865052}], array([0.104, 0.095, 0.071, 0.038, 0.061]), array([0.007, 0.005, 0.004, 0.003, 0.004]))\n",
      "44959\n",
      "(array([0.142, 0.096, 0.144, 0.089, 0.063], dtype=float32), array([0.277, 0.335, 0.276, 0.232, 0.242], dtype=float32), [{'lambda': 1.4800796813968342, 'learning_rate': 0.08115209041513519, 'n_estimators': 232, 'max_depth': 4, 'subsample': 0.9845188546443302, 'colsample_bytree': 0.8935350211764244}, {'lambda': 0.9328108245910985, 'learning_rate': 0.0761017209854222, 'n_estimators': 77, 'max_depth': 9, 'subsample': 0.6577082518839107, 'colsample_bytree': 0.602791146250485}, {'lambda': 0.09492839923221155, 'learning_rate': 0.13631862980277795, 'n_estimators': 180, 'max_depth': 3, 'subsample': 0.8514534568209945, 'colsample_bytree': 0.8752519570371482}, {'lambda': 0.003418063650310395, 'learning_rate': 0.143702963789714, 'n_estimators': 299, 'max_depth': 4, 'subsample': 0.6960356592362027, 'colsample_bytree': 0.9001508722130476}, {'lambda': 1.1363074846750052, 'learning_rate': 0.08806048381966036, 'n_estimators': 177, 'max_depth': 10, 'subsample': 0.6107215587917074, 'colsample_bytree': 0.8711511111053575}], array([0.095, 0.129, 0.051, 0.091, 0.324]), array([0.005, 0.004, 0.004, 0.005, 0.006]))\n",
      "                                               RMSE_test  \\\n",
      "                                                 XGBoost   \n",
      "44957  [0.2402587, 0.24241394, 0.2314812, 0.30912963,...   \n",
      "44959  [0.27749225, 0.33525988, 0.27638143, 0.2324987...   \n",
      "\n",
      "                                              RMSE_train  \\\n",
      "                                                 XGBoost   \n",
      "44957  [0.0838222, 0.058214106, 0.0700473, 0.16652176...   \n",
      "44959  [0.14165348, 0.095980756, 0.14441806, 0.088690...   \n",
      "\n",
      "                                             hyperparams  \\\n",
      "                                                 XGBoost   \n",
      "44957  [{'lambda': 2.602558873138932, 'learning_rate'...   \n",
      "44959  [{'lambda': 1.4800796813968342, 'learning_rate...   \n",
      "\n",
      "                                                   t_fit  \\\n",
      "                                                 XGBoost   \n",
      "44957  [0.10358378999808338, 0.09466833999977098, 0.0...   \n",
      "44959  [0.09510767100073281, 0.12942490099885617, 0.0...   \n",
      "\n",
      "                                             t_inference  \n",
      "                                                 XGBoost  \n",
      "44957  [0.0069292770022002514, 0.004645170000003418, ...  \n",
      "44959  [0.004776092002430232, 0.0036519019995466806, ...  \n"
     ]
    }
   ],
   "source": [
    "def run_all_openMLreg_xgboost(\n",
    "        dataset_ids: List,\n",
    "        name_save: str = \"XGBoost_OpenML_reg.pkl\",\n",
    "        k_folds: int = 5, \n",
    "        cv_seed: int = 42,\n",
    "        n_optuna_trials: int = 2,\n",
    "        ):\n",
    "    # Fetch and process each dataset\n",
    "    experiments = {}\n",
    "    for i, dataset_id in enumerate(dataset_ids):\n",
    "        X, y = np_load_openml_dataset(dataset_id)\n",
    "        results = evaluate_xgboost_kfoldcv(X, y, k_folds, cv_seed, n_optuna_trials)\n",
    "        experiments[dataset_id] = results\n",
    "        print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset_id}\")\n",
    "\n",
    "    # Save results\n",
    "    attributes = [\"RMSE_train\", \"RMSE_test\", \"hyperparams\", \"t_fit\", \"t_inference\"]\n",
    "    data_list = []\n",
    "    for dataset_name, results in experiments.items():\n",
    "        dataset_data = {}\n",
    "        print(dataset_name)\n",
    "        print(results)\n",
    "        for i, attrib in enumerate(attributes):\n",
    "            dataset_data[(attrib, \"XGBoost\")] = [results[i]]\n",
    "        data_list.append(pd.DataFrame(dataset_data, index=[dataset_name]))\n",
    "\n",
    "    # Combine all datasets into a single DataFrame\n",
    "    df = pd.concat(data_list)\n",
    "    df = df.sort_index(axis=1)\n",
    "    print(df)\n",
    "    df.to_pickle(name_save)\n",
    "\n",
    "run_all_openMLreg_xgboost(dataset_ids_no_categorical[0:2], \"XGBoost_OpenML_reg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or do i want a json/big array?     results[rmse_test][model][dataset][fold]. could work minus the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44957</th>\n",
       "      <td>[0.0838222, 0.058214106, 0.0700473, 0.16652176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44959</th>\n",
       "      <td>[0.14165348, 0.095980756, 0.14441806, 0.088690...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 XGBoost\n",
       "44957  [0.0838222, 0.058214106, 0.0700473, 0.16652176...\n",
       "44959  [0.14165348, 0.095980756, 0.14441806, 0.088690..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg = pd.read_pickle(\"XGBoost_OpenML_reg.pkl\")\n",
    "df_reg[\"RMSE_train\"]#.mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44957</th>\n",
       "      <td>[0.2402587, 0.24241394, 0.2314812, 0.30912963,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44959</th>\n",
       "      <td>[0.27749225, 0.33525988, 0.27638143, 0.2324987...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 XGBoost\n",
       "44957  [0.2402587, 0.24241394, 0.2314812, 0.30912963,...\n",
       "44959  [0.27749225, 0.33525988, 0.27638143, 0.2324987..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg[\"RMSE_test\"]#.mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_load_openml_dataset(\n",
    "        dataset_id, \n",
    "        normalize_X:bool = True,\n",
    "        normalize_y:bool = True,\n",
    "        device: str = \"cpu\",\n",
    "        ) -> Tuple[Tensor, Tensor]:\n",
    "    X, y = np_load_openml_dataset(dataset_id, normalize_X, normalize_y)\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "    y = torch.from_numpy(y).to(device)\n",
    "\n",
    "    if y.dim() == 1:\n",
    "        y = y.unsqueeze(1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GradientRandFeatBoostRegression\n",
    "\n",
    "###################################################################  |\n",
    "#####  Boilerplate code for tabular PyTorch model evaluation  #####  |\n",
    "#####  with Optuna hyperparameter tuning inner kfoldcv        #####  |\n",
    "###################################################################  V\n",
    "\n",
    "\n",
    "def get_pytorch_optuna_cv_rmse_objective(\n",
    "        trial,\n",
    "        ModelClass: Callable,\n",
    "        get_optuna_params: Callable,\n",
    "        X_train: Tensor, \n",
    "        y_train: Tensor, \n",
    "        k_folds: int,\n",
    "        cv_seed: int,\n",
    "        ):\n",
    "    \"\"\"The objective to be minimized in Optuna's 'study.optimize(objective, n_trials)' function.\"\"\"\n",
    "    \n",
    "    params = get_optuna_params(trial)\n",
    "\n",
    "    inner_cv = KFold(n_splits=k_folds, shuffle=True, random_state=cv_seed)\n",
    "    rmse_list = []\n",
    "    for inner_train_idx, inner_valid_idx in inner_cv.split(X_train):\n",
    "        X_inner_train, X_inner_valid = X_train[inner_train_idx], X_train[inner_valid_idx]\n",
    "        y_inner_train, y_inner_valid = y_train[inner_train_idx], y_train[inner_valid_idx]\n",
    "\n",
    "        model = ModelClass(**params)\n",
    "        model.fit(X_inner_train, y_inner_train)\n",
    "\n",
    "        preds = model(X_inner_valid)\n",
    "        rmse = torch.sqrt(nn.functional.mse_loss(y_inner_valid, preds))\n",
    "        rmse_list.append(rmse.item())\n",
    "\n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_pytorch_model_kfoldcv(\n",
    "        ModelClass : Callable,\n",
    "        get_optuna_params : Callable,\n",
    "        X: Tensor,\n",
    "        y: Tensor,\n",
    "        k_folds: int,\n",
    "        cv_seed: int,\n",
    "        n_optuna_trials: int,\n",
    "        device: Literal[\"cpu\", \"cuda\"],\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Evaluates a PyTorch model using k-fold cross-validation,\n",
    "    with an inner Optuna hyperparameter tuning loop for each fold.\n",
    "    The model is then trained on the whole fold train set and evaluated\n",
    "    on the fold test set.\n",
    "\n",
    "    Inner and outer kFoldCV use the same number of folds.\n",
    "    \"\"\"\n",
    "    outer_cv = KFold(n_splits=k_folds, shuffle=True, random_state=cv_seed)\n",
    "    outer_train_rmse_scores = []\n",
    "    outer_test_rmse_scores = []\n",
    "    chosen_params = []\n",
    "    fit_times = []\n",
    "    transform_times = []\n",
    "\n",
    "    for train_idx, test_idx in outer_cv.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        #hyperparameter tuning with Optuna\n",
    "        study = optuna.create_study(direction=\"minimize\", )\n",
    "        objective = lambda trial: get_pytorch_optuna_cv_rmse_objective(\n",
    "            trial, ModelClass, get_optuna_params, X_train, y_train, k_folds, cv_seed\n",
    "            )\n",
    "        study.optimize(objective, n_trials=n_optuna_trials)\n",
    "\n",
    "        #fit model with optimal hyperparams\n",
    "        t0 = time.perf_counter()\n",
    "        print(\"best params\", study.best_params)\n",
    "        model = ModelClass(**study.best_params).to(device)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        #predict and evaluate\n",
    "        t1 = time.perf_counter()\n",
    "        preds_train = model(X_train)\n",
    "        rmse_train = torch.sqrt(nn.functional.mse_loss(y_train, preds_train))\n",
    "        preds_test = model(X_test)\n",
    "        rmse_test = torch.sqrt(nn.functional.mse_loss(y_test, preds_test))\n",
    "        t2 = time.perf_counter()\n",
    "\n",
    "        outer_train_rmse_scores.append(rmse_train.item())\n",
    "        outer_test_rmse_scores.append(rmse_test.item())\n",
    "        chosen_params.append(study.best_params.copy())\n",
    "        fit_times.append(t1-t0)\n",
    "        transform_times.append(t2-t1)\n",
    "    \n",
    "    return (np.array(outer_train_rmse_scores),\n",
    "            np.array(outer_test_rmse_scores),\n",
    "            chosen_params,\n",
    "            np.array(fit_times),\n",
    "            np.array(transform_times))\n",
    "\n",
    "    \n",
    "\n",
    "##############################################################  |\n",
    "##### Create \"evalute_MODELHERE\" function for each model #####  |\n",
    "##############################################################  V\n",
    "\n",
    "\n",
    "def evaluate_GRFBoost(\n",
    "        X: Tensor,\n",
    "        y: Tensor,\n",
    "        k_folds: int,\n",
    "        cv_seed: int,\n",
    "        n_optuna_trials: int,\n",
    "        device: Literal[\"cpu\", \"cuda\"],\n",
    "        ):\n",
    "    ModelClass = GradientRandFeatBoostRegression\n",
    "    get_optuna_params = lambda trial : {\n",
    "        \"seed\": trial.suggest_int(\"seed\", 42, 42),                              # Fixed value\n",
    "        \"hidden_dim\": trial.suggest_int(\"hidden_dim\", X.size(1), 128, log=True),\n",
    "        \"bottleneck_dim\": trial.suggest_int(\"bottleneck_dim\", 64, 128, log=True),\n",
    "        \"out_dim\": trial.suggest_int(\"out_dim\", y.size(1), y.size(1)),          # Fixed value\n",
    "        \"n_layers\": trial.suggest_int(\"n_layers\", 1, 50, log=True),\n",
    "        \"l2_reg\": trial.suggest_float(\"l2_reg\", 1e-6, 0.1, log=True),\n",
    "        \"boost_lr\": trial.suggest_float(\"boost_lr\", 0.1, 1.0, log=True),\n",
    "        \"feature_type\": trial.suggest_categorical(\"feature_type\", [\"SWIM\"]),    # Fixed value\n",
    "        \"upscale\": trial.suggest_categorical(\"upscale\", [\"dense\"]),             # Fixed value\n",
    "    }\n",
    "\n",
    "    return evaluate_pytorch_model_kfoldcv(\n",
    "        ModelClass, get_optuna_params,\n",
    "        X, y, k_folds, cv_seed, n_optuna_trials, device,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how i will actually run the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_openMLreg_with_model(\n",
    "        dataset_ids: List,\n",
    "        evaluate_model_func: Callable,\n",
    "        name_save: str, #\"GRFBoost_OpenML_reg.pkl\",\n",
    "        k_folds: int = 5,\n",
    "        cv_seed: int = 42,\n",
    "        n_optuna_trials: int = 2,\n",
    "        device: Literal[\"cpu\", \"cuda\"] = \"cuda\",\n",
    "        ):\n",
    "    # Fetch and process each dataset\n",
    "    experiments = {}\n",
    "    for i, dataset_id in enumerate(dataset_ids):\n",
    "        X, y = pytorch_load_openml_dataset(dataset_id)\n",
    "        results = evaluate_model_func(\n",
    "            X, y, k_folds, cv_seed, n_optuna_trials, device\n",
    "            )\n",
    "        experiments[dataset_id] = results\n",
    "        print(f\" {i+1}/{len(dataset_ids)} Processed dataset {dataset_id}\")\n",
    "    \n",
    "    # Save results\n",
    "    attributes = [\"RMSE_train\", \"RMSE_test\", \"hyperparams\", \"t_fit\", \"t_inference\"]\n",
    "    data_list = []\n",
    "    for dataset_name, results in experiments.items():\n",
    "        dataset_data = {}\n",
    "        for i, attrib in enumerate(attributes):\n",
    "            dataset_data[(attrib, \"GRFBoost\")] = [results[i]]\n",
    "        data_list.append(pd.DataFrame(dataset_data, index=[dataset_name]))\n",
    "\n",
    "    # Combine all datasets into a single DataFrame\n",
    "    df = pd.concat(data_list)\n",
    "    df = df.sort_index(axis=1)\n",
    "    print(df)\n",
    "    df.to_pickle(name_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-23 18:13:15,693] A new study created in memory with name: no-name-ef04ed0e-32ae-40e2-9365-3c3a903504f5\n",
      "[I 2024-11-23 18:13:15,981] Trial 0 finished with value: 0.5036354780197143 and parameters: {'hidden_dim': 6, 'bottleneck_dim': 151, 'n_layers': 9, 'l2_reg': 0.03237018578943198, 'boost_lr': 0.11095071061899496}. Best is trial 0 with value: 0.5036354780197143.\n",
      "[I 2024-11-23 18:13:17,304] Trial 1 finished with value: 0.4271220028400421 and parameters: {'hidden_dim': 10, 'bottleneck_dim': 150, 'n_layers': 44, 'l2_reg': 0.0020083719022068363, 'boost_lr': 0.8269997726713386}. Best is trial 1 with value: 0.4271220028400421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params {'hidden_dim': 10, 'bottleneck_dim': 150, 'n_layers': 44, 'l2_reg': 0.0020083719022068363, 'boost_lr': 0.8269997726713386}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "GradientRandFeatBoostRegression.__init__() missing 1 required positional argument: 'generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_all_openMLreg_with_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_ids_no_categorical\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluate_GRFBoost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGRFBoost_OpenML_reg.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[58], line 14\u001b[0m, in \u001b[0;36mrun_all_openMLreg_with_model\u001b[0;34m(dataset_ids, evaluate_model_func, name_save, k_folds, cv_seed, n_optuna_trials, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, dataset_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset_ids):\n\u001b[1;32m     13\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m pytorch_load_openml_dataset(dataset_id)\n\u001b[0;32m---> 14\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_seed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_optuna_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     experiments[dataset_id] \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Processed dataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[57], line 128\u001b[0m, in \u001b[0;36mevaluate_GRFBoost\u001b[0;34m(X, y, k_folds, cv_seed, n_optuna_trials, device)\u001b[0m\n\u001b[1;32m    116\u001b[0m ModelClass \u001b[38;5;241m=\u001b[39m GradientRandFeatBoostRegression\n\u001b[1;32m    117\u001b[0m get_optuna_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m trial : {\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mGenerator()\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m),\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m, X\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m512\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupscale\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    127\u001b[0m             }\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate_pytorch_model_kfoldcv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mModelClass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_optuna_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_seed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_optuna_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[57], line 78\u001b[0m, in \u001b[0;36mevaluate_pytorch_model_kfoldcv\u001b[0;34m(ModelClass, get_optuna_params, X, y, k_folds, cv_seed, n_optuna_trials, device)\u001b[0m\n\u001b[1;32m     76\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest params\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n\u001b[0;32m---> 78\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModelClass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     79\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m#predict and evaluate\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: GradientRandFeatBoostRegression.__init__() missing 1 required positional argument: 'generator'"
     ]
    }
   ],
   "source": [
    "run_all_openMLreg_with_model(\n",
    "    dataset_ids_no_categorical[0:2], \n",
    "    evaluate_GRFBoost, \n",
    "    \"GRFBoost_OpenML_reg.pkl\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
