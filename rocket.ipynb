{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Set, Any, Optional, Tuple, Literal, Callable\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.lax as lax\n",
    "from jaxtyping import Array, Float, Int, PRNGKeyArray\n",
    "import aeon\n",
    "\n",
    "# from features.sig_trp import SigVanillaTensorizedRandProj, SigRBFTensorizedRandProj\n",
    "# from features.sig import SigTransform, LogSigTransform\n",
    "# from features.base import TimeseriesFeatureTransformer, TabularTimeseriesFeatures, RandomNoInformation\n",
    "# from features.sig_neural import RandomizedSignature\n",
    "from utils import print_name, print_shape\n",
    "\n",
    "jax.config.update('jax_platform_name', 'cpu') # Used to set the platform (cpu, gpu, etc.)\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.transformations.collection.convolution_based import Rocket, MultiRocket\n",
    "\n",
    "\n",
    "class RocketTransform:\n",
    "    def __init__(self, prng_key = jax.random.PRNGKey(999)):\n",
    "        self.prng_key = prng_key\n",
    "\n",
    "    def rocket_features(\n",
    "            self, \n",
    "            X: Float[Array, \"batch  time  dim\"],\n",
    "        ) -> Float[Array, \"batch  n_features\"]:\n",
    "        pass\n",
    "\n",
    "    def init_biases_and_ridge_weights(\n",
    "            self, \n",
    "            X_train: Float[Array, \"batch  time  dim\"]\n",
    "        ):\n",
    "        \"\"\"Biases are initialized to be the quantiles of the random convolutions of the training data,\n",
    "        and the ridge weights are initialized via efficient ridge leave-one-out CV.\n",
    "        \n",
    "\n",
    "        Args:\n",
    "            X_train (Float[Array, \"batch  time  dim\"]): Training data.\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use equinox to write my modules\n",
    "# training loop with optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7317003  -0.2416127 ]\n",
      " [ 0.00615408  0.60030797]]\n",
      "[[ 0.72179029 -0.2486082 ]\n",
      " [ 0.0119348   0.60579233]]\n",
      "False\n",
      "\n",
      "\n",
      "[[-0.11314843 -0.12268077]\n",
      " [-0.05167956  0.00792035]]\n",
      "[[ 0.74107915 -0.24782069]\n",
      " [ 0.09816106  0.70934334]]\n",
      "False\n",
      "\n",
      "\n",
      "[[-0.03255501  0.01003426]\n",
      " [ 0.01521384 -0.00229101]]\n",
      "[[ 0.71679987 -0.24961516]\n",
      " [ 0.11030181  0.71682938]]\n",
      "False\n",
      "\n",
      "\n",
      "[[ 9.44456995e-05 -1.05956018e-03]\n",
      " [-1.41740687e-03 -2.61345864e-04]]\n",
      "[[ 0.71332502 -0.24974785]\n",
      " [ 0.11000816  0.71740739]]\n",
      "False\n",
      "\n",
      "\n",
      "[[ 4.43172394e-05  1.57129760e-04]\n",
      " [ 2.61033928e-04 -9.76931409e-05]]\n",
      "[[ 0.71297997 -0.24974343]\n",
      " [ 0.11012502  0.71744964]]\n",
      "False\n",
      "\n",
      "\n",
      "[[ 1.32186612e-05 -3.50973769e-06]\n",
      " [ 7.39902977e-06  4.59126003e-06]]\n",
      "[[ 0.71296687 -0.24974504]\n",
      " [ 0.11011793  0.71744927]]\n",
      "False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import iisignature\n",
    "\n",
    "from features.sig_trp import SigVanillaTensorizedRandProj\n",
    "\n",
    "N=2\n",
    "T=100\n",
    "D=3\n",
    "prng_key, trp_key = jax.random.split(jax.random.PRNGKey(0))\n",
    "\n",
    "def test_approx_against_iisignature_trunc_level(trunc_level):\n",
    "    # test specfic arguments\n",
    "    n_features = 100000\n",
    "    max_batch = N\n",
    "    concat_levels=False\n",
    "\n",
    "    #input brownian motions\n",
    "    X, Y = jnp.cumsum(jax.random.normal(prng_key, (2, N, T, D)), axis=2) / np.sqrt(T* D)\n",
    "\n",
    "    #compare\n",
    "    trp = SigVanillaTensorizedRandProj(trp_key, n_features, trunc_level, max_batch, concat_levels).fit(X)\n",
    "    X_out_trp = trp.transform(X) # / np.sqrt(n_features)\n",
    "    Y_out_trp = trp.transform(Y) # / np.sqrt(n_features)\n",
    "    dot_trp = jnp.dot(X_out_trp, Y_out_trp.T)\n",
    "\n",
    "    X_out_sig = iisignature.sig(np.array(X), trunc_level)\n",
    "    Y_out_sig = iisignature.sig(np.array(Y), trunc_level)\n",
    "    dot_sig = np.dot(X_out_sig, Y_out_sig.T)\n",
    "\n",
    "    print(dot_trp)\n",
    "    print(dot_sig)\n",
    "    print(np.allclose(np.array(dot_trp), dot_sig, atol=1e-3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def test_approx_against_iisignature():\n",
    "    for i in range(1, 7):\n",
    "        test_approx_against_iisignature_trunc_level(i)\n",
    "\n",
    "test_approx_against_iisignature()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
